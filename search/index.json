[{"content":" 学而不能致用的人是一头背着书的牛马。蠢驴是否知道它背上背着的是一堆书而不是一捆柴？—— 本杰明·富兰克林\n前言 2025年2月底，我回顾了前五年学习工作经历以及技术发展趋势后，在编程语言方面树立以Python与C++为主的编程技能，Java、Rust、Go等其他语言为辅，这样我需要推动自己将Pyhon和C++的技能尽可能达到精通，熟记这两门语言核心知识。正如我在最近阅读的《富兰克林自传》中所看到，富兰克林早期以印刷技能作为自己的谋生手段，而近三年我也以编程技能作为自己的谋生手段，未来路还很长，不能止步于此，需要不断学习其他领域与学科知识，学以致用，不能成为芒格口中的“铁锤人”。\nPython语言大概是在我五六年前开始正式作为工作语言，当时以《Head First Python》书籍入门，在读研期间通过阅读与实践深度学习相关项目，如Numpy、Pytorch、mmdetection、mmocr等，对Python语言有了更深的应用理解。最近通过阅读《流畅的Python》第2版，对该语言进行系统性地回顾与熟记；此次阅读Requests源码，一是对最近学习的一个总结与应用，二是给自己未来通过Python实现更大更复杂项目打下坚实的基础。\n谁适合阅读这篇文章？ 如何更好地阅读本篇文章？ 项目简介 这里直接引用官方对Requests的相关介绍，我们在后面源码解析中会逐步展开代码中是如何实现这些功能的。\nA simple, yet elegant, HTTP library. Requests是一个简单而优雅的 HTTP 库。\nSupported Features \u0026amp; Best–Practices 支持的功能和最佳实践\nRequests is ready for the demands of building robust and reliable HTTP–speaking applications, for the needs of today.\nRequests已准备好满足构建强大且可靠的 HTTP 应用程序的需求，以满足当今时代的需求。\nKeep-Alive \u0026amp; Connection Pooling 保持连接和连接池 International Domains \u0026amp; URLs 国际域名和 URL Sessions with Cookie Persistence 具有Cookie 持久性的会话机制 Browser-style SSL Verification 浏览器风格的 SSL 验证 Basic/Digest Authentication 基本身份验证和摘要身份认证 Familiar dict–like Cookies 熟悉的类似dict的 Cookies Automatic Content Decompression and Decoding 内容自动解压缩和解码 Muti-part File Uploads 多部分文件上传 SOCKS Proxy Support 支持 SOCKS 代理 Connection Timeouts 连接超时 Streaming Downloads 流式下载 Automatic honoring of .netrc 自动遵循.netrc配置 Chunked HTTP Requests 分块 HTTP 请求 项目结构 我们再来看一下Requests的项目的顶层结构，并简单介绍一下各个目录与文件的作用。 这里采用eza -a -T -L 1 --group-directories-first命令查看项目目录结构。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 . ├── .git # Git 版本控制系统的目录，包含项目的版本历史和配置 ├── .github # GitHub 相关的配置文件和工作流，如持续集成（CI）配置等 ├── docs # 文档目录，包含使用指南、API 文档等 ├── ext # 外部扩展或依赖项，现已逐步弃用 ├── src # 源码目录，包含主要的接口和功能实现代码 ├── tests # 测试目录，包括单元测试与集成测试代码，覆盖请求发送、异常处理、Cookie 管理等关键功能。 ├── .coveragerc ├── .git-blame-ignore-revs ├── .gitignore ├── .pre-commit-config.yaml # Git钩子配置文件，在提交代码前自动执行，用于代码规范检查、格式化等 ├── .readthedocs.yaml # Read the Docs 平台用于配置项目构建过程的配置文件 ├── AUTHORS.rst ├── HISTORY.md ├── LICENSE ├── Makefile # 自动化任务的文件，如构建、测试 ├── MANIFEST.in ├── NOTICE ├── pyproject.toml ├── README.md ├── requirements-dev.txt ├── setup.cfg ├── setup.py # 安装和打包配置文件，定义项目的元数据（如名称、版本、依赖项）并支持 pip install 和 setuptools 进行管理。 └── tox.ini 上面项目组织结构中，我们可以学习到一个广泛遵循的约定，即将项目的源码、测试、文档等内容分别放置在不同的目录中，以便于管理和维护。通常将源代码放在 src/ 目录，测试代码放在 tests/ 目录，文档资料放在 docs/ 目录，并使用 LICENSE 文件声明开源许可。\n其他文件是一些Python项目工具的配置文件，如 pyproject.toml、setup.py、requirements-dev.txt、tox.ini 等，关于这些项目构建和运行的配置文件，平时在使用到这些工具时多多留意就好啦~\n源码解析 本想寻找两三个简单实用的示例，无意间查看源码目录的src/requests/__init__.py文件，发现已经有两个示例了，我们在这里直接运行它们。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 (common-env) ➜ requests git:(main) python Python 3.12.9 | packaged by Anaconda, Inc. | (main, Feb 6 2025, 12:55:12) [Clang 14.0.6 ] on darwin Type \u0026#34;help\u0026#34;, \u0026#34;copyright\u0026#34;, \u0026#34;credits\u0026#34; or \u0026#34;license\u0026#34; for more information. \u0026gt;\u0026gt;\u0026gt; import requests \u0026gt;\u0026gt;\u0026gt; r = requests.get(\u0026#39;https://www.python.org\u0026#39;) \u0026gt;\u0026gt;\u0026gt; r.status_code 200 \u0026gt;\u0026gt;\u0026gt; payload = dict(key1=\u0026#39;value1\u0026#39;, key2=\u0026#39;value2\u0026#39;) \u0026gt;\u0026gt;\u0026gt; r = requests.post(\u0026#39;https://httpbin.org/post\u0026#39;, data=payload) \u0026gt;\u0026gt;\u0026gt; print(r.text) { \u0026#34;args\u0026#34;: {}, \u0026#34;data\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;files\u0026#34;: {}, \u0026#34;form\u0026#34;: { \u0026#34;key1\u0026#34;: \u0026#34;value1\u0026#34;, \u0026#34;key2\u0026#34;: \u0026#34;value2\u0026#34; }, \u0026#34;headers\u0026#34;: { \u0026#34;Accept\u0026#34;: \u0026#34;*/*\u0026#34;, \u0026#34;Accept-Encoding\u0026#34;: \u0026#34;gzip, deflate\u0026#34;, \u0026#34;Content-Length\u0026#34;: \u0026#34;23\u0026#34;, \u0026#34;Content-Type\u0026#34;: \u0026#34;application/x-www-form-urlencoded\u0026#34;, \u0026#34;Host\u0026#34;: \u0026#34;httpbin.org\u0026#34;, \u0026#34;User-Agent\u0026#34;: \u0026#34;python-requests/2.32.3\u0026#34;, \u0026#34;X-Amzn-Trace-Id\u0026#34;: \u0026#34;Root=1-67d7be38-6126bbec2e56917a24eda1a3\u0026#34; }, \u0026#34;json\u0026#34;: null, \u0026#34;origin\u0026#34;: \u0026#34;45.86.73.64\u0026#34;, \u0026#34;url\u0026#34;: \u0026#34;https://httpbin.org/post\u0026#34; } 下面正式开始对Requests源码进行解析，从src/requests/__init__.py文件开始。\n__init__.py文件 以下截取文件代码中的核心部分，省略部分使用三行# ...表示。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 # ... # ... # ... from . import packages, utils from .__version__ import ( __author__, __author_email__, __build__, __cake__, __copyright__, __description__, __license__, __title__, __url__, __version__, ) from .api import delete, get, head, options, patch, post, put, request from .exceptions import ( ConnectionError, ConnectTimeout, FileModeWarning, HTTPError, JSONDecodeError, ReadTimeout, RequestException, Timeout, TooManyRedirects, URLRequired, ) from .models import PreparedRequest, Request, Response from .sessions import Session, session from .status_codes import codes logging.getLogger(__name__).addHandler(NullHandler()) # FileModeWarnings go off per the default. warnings.simplefilter(\u0026#34;default\u0026#34;, FileModeWarning, append=True) 我们知道在Python中，__init__.py文件的作用包含以下三点：\n标记包目录：文件存在即表示该目录是一个Python包，允许导入子模块（空文件也可）。 初始化包：包被导入时自动执行，用于（1）定义包级变量/函数（如版本号、工具函数）；（2）批量导入子模块，简化外部调用，如from . import submodule。 控制导入行为：（1）通过__all__指定from package import *时导出的模块列表；（2）隐藏内部实现，仅暴露特定接口。 具体到上面展示的Requests中__init__.py文件核心代码，主要包含了：\n导入子模块，如packages、utils； 导入版本信息，如__version__； 导入API接口，如delete、get、head、options、patch、post、put、request； 导入异常类，如ConnectionError、ConnectTimeout、HTTPError、JSONDecodeError等； 导入请求和响应模型类，如PreparedRequest、Request、Response； 导入会话管理类，如Session、session； 导入状态码类，如codes； 进行日志模块的初始化。 在阅读和解析其他模块源码之前，我们先来看下Requests核心模块的架构设计。其源码目录结构如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 (common-env) ➜ requests git:(main) ✗ lz src/requests src/requests ├── __init__.py ├── __version__.py ├── _internal_utils.py ├── adapters.py ├── api.py ├── auth.py ├── certs.py ├── compat.py ├── cookies.py ├── exceptions.py ├── help.py ├── hooks.py ├── models.py ├── packages.py ├── sessions.py ├── status_codes.py ├── structures.py └── utils.py Requests的核心模块主要包含api.py、sessions.py、adapters.py、models.py、utils.py、status_codes.py，下面通过PlantUML图展示Requests的核心模块架构设计。\napi.py模块 在查看api.py模块源码之前，我们将通过运行测试用例并逐步跟踪代码执行流程，这样可以更好地理解代码的执行逻辑。\n理解 tests/ 目录结构 将该目录下文件按照功能分类，方便查找和阅读。\n核心功能测试： test_requests.py 适配器与底层传输：test_adapters.py, test_lowlevel.py 工具与辅助功能：test_utils.py, utils.py 数据结构与内部类：test_structures.py 钩子与扩展功能：test_hooks.py 测试基础设施：testserver/, test_testserver.py, certs/ 兼容性与环境验证：compat.py 帮助与文档：test_help.py 包与安装验证：test_packages.py 测试框架配置：conftest.py, __init__.py 安装测试依赖 运行下面命令安装测试依赖，包含 pytest 测试框架和 pytest-httpbin 本地 HTTP 服务模拟。\n1 2 uv pip install -e .[socks] # 包含 socks 代理等可选依赖 uv ip install pytest pytest-httpbin # 测试框架和本地 HTTP 服务模拟 运行测试用例并进入调试模式 这里我们选择运行test_HTTP_200_OK_GET_ALTERNATIVE测试方法，调试程序会在进入方法后暂停，方便我们跟踪代码执行流程。\n1 pytest tests/test_requests.py -k test_HTTP_200_OK_GET_ALTERNATIVE --trace 接下来使用 n（下一步）、s（进入函数）等命令跟踪代码。\napi.py模块源码解析 本章我们重点关注api.py模块，尤其是其中比较常用的requests.get()和requests.post()方法，上面示例的测试用例函数test_HTTP_200_OK_GET_ALTERNATIVE中使用了requests.Request()和requests.Session()方法，我们在这里先不做详细展开。\n我在test_requests.py文件中找到了test_HTTP_200_OK_GET_WITH_PARAMS测试用例，作为项目源码入手的起点，我们将逐步调试并解析这个测试用例。\n此外，通过命令行中调试代码虽然方便，但是面对现代大型Python项目，采用IDE提供的调试工具更加方便。因此，创建以下VS Code调试配置文件。\n.vscode/launch.json具体内容如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 { \u0026#34;version\u0026#34;: \u0026#34;0.2.0\u0026#34;, \u0026#34;configurations\u0026#34;: [ { \u0026#34;name\u0026#34;: \u0026#34;Debug Tests\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;debugpy\u0026#34;, \u0026#34;request\u0026#34;: \u0026#34;launch\u0026#34;, \u0026#34;module\u0026#34;: \u0026#34;pytest\u0026#34;, \u0026#34;args\u0026#34;: [\u0026#34;tests/test_requests.py::TestRequests::test_HTTP_200_OK_GET_WITH_PARAMS\u0026#34;], \u0026#34;cwd\u0026#34;: \u0026#34;${workspaceFolder}\u0026#34;, // 指定工作目录 \u0026#34;justMyCode\u0026#34;: false, // 允许跟踪 Requests 源码 } ] } 同时，配置.vscode/settings.json文件，指定 Python 解释器路径。这样，按下 F5 键即可在 VS Code 中调试test_HTTP_200_OK_GET_WITH_PARAMS测试用例。\n注意：在这里我踩了一个坑，一开始配置的.vscode/launch.json文件中configurations的args参数写成了\u0026quot;args\u0026quot;: [\u0026quot;tests/test_requests.py::test_HTTP_200_OK_GET_WITH_PARAMS\u0026quot;, \u0026quot;--trace\u0026quot;]，导致调试时一直提示找不到测试用例，后来将测试类TestRequests::加上即可。分析我犯的错误的原因，主要有两个：\n（1）利用人工智能文件编辑提示功能，自动生成了tests/test_requests.py:test_HTTP_200_OK_GET_ALTERNATIVE，我想当然得用test_HTTP_200_OK_GET_WITH_PARAMS将其替换；\n（2）没有熟悉pytest的用法，尤其是区分pytest test_sample.py::TestMath::test_add和pytest test_sample.py -k test_add的区别，前者需指定测试类和测试方法，后者可以模糊匹配测试方法。\n配置完后，可以在测试代码旁打断点，再按 F5 键开始调试，这样就可以在 VS Code 中逐步调试测试用例代码了。如下图：\n现在我们整体阅读api.py源码文件，可以看到get()、options()、head()、post()、put()、patch()、delete()方法通过传递不同的method参数调用def request(method, url, **kwargs)实现功能，这里我们对HTTP协议的这些方法简要介绍：\nget: 发送GET请求，用于获取资源，参数通过URL查询字符串（params）传递。 options: 发送OPTIONS请求，用于探测服务器支持的HTTP方法。 head: 发送HEAD请求，仅获取响应头（默认禁用重定向allow_redirects=False）。 post: 发送POST请求，提交数据（支持data或json参数），通常用于创建资源或提交表单。 put: 发送PUT请求，替换或创建完整资源（支持data参数，需显式传递全部字段）。 patch: 发送PATCH请求，部分更新资源（支持data参数，仅传递需修改的字段）。 delete: 发送DELETE请求，删除指定资源，无请求体（可通过**kwargs自定义参数）。 api.py模块源码比较简单，主要是对请求方法的封装，下面我们直接看request()核心方法的实现。\n1 2 3 4 5 6 def request(method, url, **kwargs): # By using the \u0026#39;with\u0026#39; statement we are sure the session is closed, thus we # avoid leaving sockets open which can trigger a ResourceWarning in some # cases, and look like a memory leak in others. with sessions.Session() as session: return session.request(method=method, url=url, **kwargs) 使用with语句创建一个临时 Session 会话对象，自动调用 Session.__enter__() 方法，该方法返回对象本身，绑定到目标变量session上。函数内部通过该会话调用 session.request() 发起 HTTP 请求，并在请求完成后with 语句自动调用Session.__exit__()方法，关闭会话，避免资源泄露，如连接未释放、内存泄露等。通过上下文管理器的方式，无需显式关闭session.close()，简洁可靠。\n对于api.py源码解析就到此为止，下面我们将重点分析Session类的实现，了解其如何管理请求会话、连接池、Cookie等。\nsessions.py模块源码解析 1 2 3 4 5 6 7 8 9 10 11 12 # self.adapters = OrderedDict() def mount(self, prefix, adapter): \u0026#34;\u0026#34;\u0026#34;Registers a connection adapter to a prefix. Adapters are sorted in descending order by prefix length. \u0026#34;\u0026#34;\u0026#34; self.adapters[prefix] = adapter keys_to_move = [k for k in self.adapters if len(k) \u0026lt; len(prefix)] for key in keys_to_move: self.adapters[key] = self.adapters.pop(key) 该函数将一个自定义的适配器（adapter）绑定到指定的前缀（如 \u0026lsquo;https://\u0026rsquo;）。1）注册连接适配器：self.adapters[prefix] = adapter。2）重新排序：将比当前 prefix 短的键移到后面，确保按前缀长度从长到短排序，这样查找时优先匹配更具体的前缀。\n参考资料 Requests: HTTP for Humans™ requests源码精读 requests模块源码阅读总结 知识点记忆 提示词：模块、包。在Python中，模块是一个单独的 .py 文件，包是一个包含多个模块的文件夹，且必须有 __init__.py 文件。 提示词：主流工具。构建、打包和分发工具setuptools、测试框架pytest、代码格式化工具black、自动排序导入工具isort、代码静态分析工具flake8、自动化测试环境管理工具tox、文档生成工具Sphinx。 遍历字典：字典的遍历默认是遍历 键（keys），可以使用dict.items()方法遍历键值对。 字典pop()方法：pop()方法用于从字典中删除指定键及其对应的值，并返回被删除的值。 ","date":"2025-03-16T11:29:31+08:00","image":"http://localhost:1313/posts/%E8%A7%A3%E5%89%96requests%E4%BB%8Epython%E5%B0%8F%E7%99%BD%E5%88%B0%E6%BA%90%E7%A0%81%E7%8C%8E%E6%89%8B%E7%9A%84%E8%BF%9B%E9%98%B6%E4%B9%8B%E8%B7%AF/cover_hu_ff26c92e18ba6378.jpg","permalink":"http://localhost:1313/posts/%E8%A7%A3%E5%89%96requests%E4%BB%8Epython%E5%B0%8F%E7%99%BD%E5%88%B0%E6%BA%90%E7%A0%81%E7%8C%8E%E6%89%8B%E7%9A%84%E8%BF%9B%E9%98%B6%E4%B9%8B%E8%B7%AF/","title":"解剖Requests：从Python小白到源码猎手的进阶之路"},{"content":"\n前言 正文 阅读分类 基础阅读、检视阅读、分析阅读、主题阅读\n避坑指南 拒绝自我感动：以“解决问题数量”与“项目实践”而非“笔记数量”评估体系有效性； 避免信息过载：避免过度关注工具的使用，而忽视了知识的消化； 拒绝工具完美主义：拒绝追求100%自动化，保留必要手动加工； 拒绝工具癖好：不要为了工具的使用而使用工具，保持简单； 拒绝知识体系混乱：持续优化精简，避免体系熵增。 ","date":"2025-01-31T09:12:11+08:00","permalink":"http://localhost:1313/posts/%E6%9E%84%E5%BB%BA%E5%8F%AF%E5%A4%8D%E7%94%A8%E7%9A%84%E7%9F%A5%E8%AF%86%E5%BC%95%E6%93%8E%E6%88%91%E7%9A%84%E7%BB%88%E8%BA%AB%E5%AD%A6%E4%B9%A0%E4%BD%93%E7%B3%BB%E8%AE%BE%E8%AE%A1/","title":"构建可复用的知识引擎：我的终身学习体系设计"},{"content":"第1章 微习惯的惊人力量 针对一个章节的问题\n这章内容的核心信息是什么？ 它是否回答了某个问题，或者提供了某个观点？ 本章核心信息是人们很容易低估微小习惯的力量和价值；不同于我们期望进步是线性的，实际上微小习惯带来的改变像是指数变化，存在一个潜能蓄积期，当时间积累到一个临界点，才会跨入一个新境界。\n目标分解出来的部分哪怕有1%向好的微变化，在各部分改进都汇集起来后，整体上会有显著提高，所谓“不积跬步，无以至千里”。\n此外，作者在本章指出我们应该设立目标，从而指引大方向，但是需要忘记目标，专注于微习惯形成体系。\n作为上面观点的支撑，作者强调了目标的有害的一面：\n1）目标本身不是区分赢家和输家的唯一标准；\n2）达成目标不是我们改变生活的结果，真正需要改变的是导致这些结果的体系（微习惯），这些体系（微习惯）塑造了自己；\n3）目标优先心态的问题是：你一直在延迟享受快乐，总是寄希望于下一个里程碑的实现，这样会把自我禁锢在一种狭隘的幸福观中，正确做法是在过程中享受快乐；\n4）长远进步与目标存在冲突，当你所有的努力都集中在一个特定的目标上时，一旦目标实现，推动你努力的动力也就失去了依托，这就是为什么许多人在完成预定目标后又恢复了旧习惯。\n作者为什么要强调这个核心信息？ 它在整章或整本书中的作用是什么？ 作者在本章中通过不同的角度不同的案例来强调微小习惯带来的改变是惊人的，本章作为整本书的基本原理，提出一个“微习惯”的概念，并解释和解决了我们在达成目标时存在的一些思想上的错误认知，作者给出的良药是符合长期主义的改变体系，而不是仅仅达成短期目标。\n有没有案例、故事或数据支撑这个观点？它说明了什么？ 这些例子是否具有说服力？是否可以类比到我的场景中？ 通过戴夫·布雷斯福德带领的英国职业自行车队制定“聚合微小进步”战略的案例、飞机航线微调飞行角度的案例、冰块随着温度逐渐上升逐渐融化的案例、凿石头的案例来支撑核心信息。\n这些案例具有强大的说服力，类比到自己身上，通过养成阅读习惯、每天学习英语三分钟微习惯、正念思考等，积累微小好习惯，达成掌控习惯。\n我对这个观点的理解是什么？是否认同？ 如果不认同，我的理由是什么？有没有其他可能的解释？ 作者第一章提出一种看似较新的概念“微习惯”，但是实际上“习惯”就能涵盖微小习惯，但是“习惯”二字从小一直被灌输，已经把耳朵磨出茧来了，无法读者引起反思，所以提出新的概念，以引起读者重新审视和反思.\n我非常认同作者的观点，并且作者在思想上清除了每个人可能遇到的问题，尤其是惊醒了我目前犯得错误，过于关注目标，忽视了微习惯对于自身的改变与享受过程，目标只是方向上的里程碑与指引，享受过程与自身的提升才是最重要的。\n这解释我当下的困扰，总是觉得看重学历目标，而忽视了整个教育体制设立追求学历目标是指引了一个大方向，在完成学历的过程中，对自我的改变与习惯的养成才是最重要的。\n我们应该学习分辨习惯的好与坏，哪些习惯是应该尽早养成，以及以开放积极心态去寻找他人更好的习惯。\n反思之前的思想，认识到目标的优点，忽略了目标的缺点，看待事物的两面。\n这段内容和之前的内容有什么关联？ 是否为之前的观点提供了进一步说明，还是在补充新的信息？ 书籍第一章，通过案例引出作者的观点，总领整本书籍的核心观点。\n第2章你的习惯如何塑造你的身份（反之亦然） 针对一个章节的问题\n这章内容的核心信息是什么？ 它是否回答了某个问题，或者提供了某个观点？ 本章核心信息是 作者提出我们难以改变习惯的两种原因：\n（1）没有找对试图改变的东西；\n（2）试图以错误的方式改变自己的习惯。\n本章主要讨论前者，行为改变有三个层次，可以表示为三层同心⭕️，最外层是结果的改变，内层是过程的改变，核心是身份的改变。过程的改变这一层次才涉及自身习惯和体系的改变。\n作者强调正确改变的东西是核心的身份改变与内层的过程改变（习惯）。\n行为是身份的表征，反过来行为汇聚的习惯不断强化身份的认同。\n马克思从社会属性提出“人的本质在其现实性上是一切社会关系的总和”，借用类似表达，可以认为从个人属性上讲“人的本质在时空维度上是一切行为习惯的总和”\n目标不是阅读一本书，而是成为读者。目标不是跑马拉松，而是成为跑步者。目标不是学习一种乐器，而是成为音乐家。目标不是减肥，而是成为一个健康者。\n重点始终是成为那种类型的人，用今天的行为习惯强化你自己的身份，而不是获得某种特定的结果。\n作者为什么要强调这个点？ 它在整章或整本书中的作用是什么？ 作者深层分析我们难以改变习惯的原因之一：没有找到试图改变的东西，对于想要改变习惯的人，但是错误地将自己的注意力关注在想要达成的目标，而不是想要成为那种类型的人，进而提出需要思想上对自我核心身份进行转变与对内层的行为习惯进行改变。\n第一章聚焦在微小习惯的重要性，解决了是什么，本章解决了怎么做以及需要改变什么东西。\n有没有案例、故事或数据支撑这个观点？它说明了什么？ 这些例子是否具有说服力？是否可以类比到我的场景中？ 作者使用两个人拒绝抽烟的言语，“不用了，谢谢，我正在戒烟。​”与“不，谢谢，我不吸烟了”来表明大多数人在着手自我提高时甚至不考虑改变身份。\n此外，作者使用企业家布莱恩·克拉克的案例，他通过掏钱保养自己的指甲，并且被他人和自己认同自己的指甲非常健康且有魅力，从而改掉了咬指甲的坏习惯。你越是以自己身份的某一方面为傲，你就越有动力保持与之相关的习惯。\n一种是对待自我，首先要进行身份的转变，从我要成为什么类型的人，变成我是什么类型的人，我的行为习惯应该符合这样的人的身份。\n另一种是对待他人，如果你想要改变他人习惯或者行为，可以朝着自己希望的方向去夸赞他人，称赞他们的行为，甚至是身份，比如“你办事我很放心”到“我知道你是一个靠谱且专业的人”，在无形中影响他人。\n我对这个观点的理解是什么？是否认同？ 如果不认同，我的理由是什么？有没有其他可能的解释？ 非常认同作者的观点，回想自己的行为模式，当自己想成为什么人，总需要一个外在认可。\n根据本章内容，首先自己在思想上要建立身份认同，比如我已经在博客个人介绍中增加了一名终身学习者（读者、写作者、算法应用与研究员）这样的身份认同，这样我不是在做非常多的事情使得自己可能成为这样的人，而且我是一名终身学习者（读者、写作者、算法应用与研究员）我需要做符合我身份的行为习惯。\n这章内容和之前的内容有什么关联？ 是否为之前的观点提供了进一步说明，还是在补充新的信息？ 这章节所表达的最外层结果的改变，即是目标的达成，作者否认基于结果或者目标的改变，是对第一章中“忘记目标，专注于微习惯形成体系”进一步说明，现代社会中公司与个人，所谓的结果导向、目标导向过于关注于目标了，关注过程，目标是副产物。\n","date":"2025-01-28T20:32:25+08:00","image":"http://localhost:1313/posts/%E4%B9%A6%E7%B1%8D%E7%B2%BE%E7%AE%80%E4%B8%8E%E5%86%99%E4%BD%9C%E5%AE%9E%E8%B7%B5%E8%AE%A1%E5%88%92%E4%B9%8B%E9%98%85%E8%AF%BB%E6%8E%8C%E6%8E%A7%E4%B9%A0%E6%83%AF/cover_hu_89746b4d7fef6ee5.jpg","permalink":"http://localhost:1313/posts/%E4%B9%A6%E7%B1%8D%E7%B2%BE%E7%AE%80%E4%B8%8E%E5%86%99%E4%BD%9C%E5%AE%9E%E8%B7%B5%E8%AE%A1%E5%88%92%E4%B9%8B%E9%98%85%E8%AF%BB%E6%8E%8C%E6%8E%A7%E4%B9%A0%E6%83%AF/","title":"书籍精简与写作实践计划之阅读《掌控习惯》"},{"content":"前言 谁适合阅读这篇文章？ 具备 C++ 基础：对线程池和网络编程有一定了解，希望进一步深入相关技术。 热衷于 C++14 的应用：对现代 C++ 特性感兴趣，并追求更高的代码性能和效率。 对 Web 服务器实现感兴趣：想要理解 Web 服务器的核心原理和实现细节，从源码到原理全方位掌握。 如何更好地阅读本篇文章？ 针对希望通过本篇文章了解 WebServer 实现原理的读者：\n建议使用 Snipaste 等贴图工具，将代码片段或原理示意图固定在电脑屏幕的显眼位置。这样在阅读源码解析时，可以随时对照代码或参考原理图，帮助更直观地理解 WebServer 的设计思路和实现细节。\n针对希望深入研究源码并亲自动手实践的读者：\n强烈推荐使用 VS Code 等现代化 IDE，并确保安装支持 C++14 的编译器。参考GDB 调试秘籍：像高手一样排查问题，通过逐步调试代码的方式，深入分析其运行过程。这样的实践方法不仅能加深对源码的理解，还能有效提升调试技能和对程序逻辑的掌控能力。\n项目简介 该项目是用 C++14 实现的高性能WEB服务器，经过 webbenchh 压力测试可以实现上万的QPS，通过该项目达到以下目的：\n阅读源码提升自己编程水平； 进一步理解 HTTP 协议； 熟悉 C++14 相关工具； 熟悉线程池； 理解 IO 复用技术 Epoll； 熟悉定时器的设计与实现； 熟悉异步日志系统的设计； 项目目录结构 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 . ├── code 源代码 │ ├── buffer │ ├── config │ ├── http │ ├── log │ ├── timer │ ├── pool │ ├── server │ └── main.cpp ├── test 单元测试 │ ├── Makefile │ └── test.cpp ├── resources 静态资源 │ ├── index.html │ ├── image │ ├── video │ ├── js │ └── css ├── bin 可执行文件 │ └── server ├── log 日志文件 ├── webbench-1.5 压力测试 ├── build │ └── Makefile ├── Makefile ├── LICENSE └── readme.md 项目启动 配置数据库 1 2 3 4 5 6 7 8 9 10 11 12 13 // 建立yourdb库 create database webserver; // 创建user表 USE webserver; CREATE TABLE user( username char(50) NULL, password char(50) NULL )ENGINE=InnoDB; // 添加数据 INSERT INTO user(username, password) VALUES(\u0026#39;zhangsan\u0026#39;, \u0026#39;123456\u0026#39;); INSERT INTO user(username, password) VALUES(\u0026#39;lisi\u0026#39;, \u0026#39;123456\u0026#39;); 数据库中数据如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 mysql\u0026gt; USE webserver; Reading table information for completion of table and column names You can turn off this feature to get a quicker startup with -A Database changed mysql\u0026gt; SHOW tables; +---------------------+ | Tables_in_webserver | +---------------------+ | user | +---------------------+ 1 row in set (0.00 sec) mysql\u0026gt; SELECT * FROM user; +----------+----------+ | username | password | +----------+----------+ | zhangsan | 123456 | | lisi | 123456 | +----------+----------+ 2 rows in set (0.00 sec) 编译运行 1 2 make ./bin/server 压力测试 1 2 3 4 ./webbench-1.5/webbench -c 100 -t 10 http://ip:port/ ./webbench-1.5/webbench -c 1000 -t 10 http://ip:port/ ./webbench-1.5/webbench -c 5000 -t 10 http://ip:port/ ./webbench-1.5/webbench -c 10000 -t 10 http://ip:port/ 测试结果如下：\n功能介绍 利用IO复用技术Epoll与线程池实现多线程的Reactor高并发模型； 利用正则与状态机解析HTTP请求报文，实现处理静态资源的请求； 利用标准库容器封装char，实现自动增长的缓冲区； 基于小根堆实现的定时器，关闭超时的非活动连接； 利用单例模式与阻塞队列实现异步的日志系统，记录服务器运行状态； 利用RAII机制实现了数据库连接池，减少数据库连接建立与关闭的开销，同时实现了用户注册登录功能。 时序图 上面时序图展示了 WebServer 从服务启动时进行资源初始化、客户端发送一个 HTTP 请求到 WebServer 服务器、监听套接字的 Epoller 接受到 TCP 连接请求并进行分发的过程。\n1 2 3 4 5 6 7 8 9 10 11 12 13 #include \u0026lt;unistd.h\u0026gt; #include \u0026#34;server/webserver.h\u0026#34; int main() { /* 守护进程 后台运行 */ //daemon(1, 0); WebServer server( 1316, 3, 60000, false, /* 端口 ET模式 timeoutMs 优雅退出 */ 3306, \u0026#34;root\u0026#34;, \u0026#34;123456\u0026#34;, \u0026#34;webserver\u0026#34;, /* Mysql配置 */ 12, 6, true, 1, 1024); /* 连接池数量 线程池数量 日志开关 日志等级 日志异步队列容量 */ server.Start(); } 上面代码为 WebServer 服务器实例化时资源加载和实例启动源码，该阶段完成上面时序图 Resource initialization 框标的过程。\n编译运行后，当我们启动时，首先通过上面代码启动服务，这时一个 HTTP 服务器开始对外服务，我们可以在游览器中访问地址：http://127.0.0.1:1316 ，打开如下界面。\n通过游览器访问时，这里游览器给服务器发送了一个处于应用层 HTTP 协议的 GET 请求，上面时序图绿色箭头代表客户端用户主动发起请求路径为 / 的请求，该请求会被 Linux 内核提供给应用程序的同时监听多个文件描述符的事件通知机制 epoll 响应，那么为什么 epoll 会处理这样的网络请求呢？\n在 Resource initialization 资源初始化阶段，就在 WebServer::InitSocket_() 函数中通过 socket 传输层编程设置一个绑定到协议为 TCP 且端口为 1316 上的网络监听套接字 listenFd_ ，通过调用 listen(listenFd_, 6) 该监听套接字一直处于监听状态；而且，通过 epoller_-\u0026gt;AddFd(listenFd_, listenEvent_ | EPOLLIN) 调用，将该套接字添加到多路复用机制 epoll 的注册事件中，该过程的代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 bool WebServer::InitSocket_() { int ret; struct sockaddr_in addr; if(port_ \u0026gt; 65535 || port_ \u0026lt; 1024) { LOG_ERROR(\u0026#34;Port:%d error!\u0026#34;, port_); return false; } addr.sin_family = AF_INET; addr.sin_addr.s_addr = htonl(INADDR_ANY); addr.sin_port = htons(port_); struct linger optLinger = { 0 }; if(openLinger_) { /* 优雅关闭: 直到所剩数据发送完毕或超时 */ optLinger.l_onoff = 1; optLinger.l_linger = 1; } listenFd_ = socket(AF_INET, SOCK_STREAM, 0); if(listenFd_ \u0026lt; 0) { LOG_ERROR(\u0026#34;Create socket error!\u0026#34;, port_); return false; } ret = setsockopt(listenFd_, SOL_SOCKET, SO_LINGER, \u0026amp;optLinger, sizeof(optLinger)); if(ret \u0026lt; 0) { close(listenFd_); LOG_ERROR(\u0026#34;Init linger error!\u0026#34;, port_); return false; } int optval = 1; /* 端口复用 */ /* 只有最后一个套接字会正常接收数据。 */ ret = setsockopt(listenFd_, SOL_SOCKET, SO_REUSEADDR, (const void*)\u0026amp;optval, sizeof(int)); if(ret == -1) { LOG_ERROR(\u0026#34;set socket setsockopt error !\u0026#34;); close(listenFd_); return false; } ret = bind(listenFd_, (struct sockaddr *)\u0026amp;addr, sizeof(addr)); if(ret \u0026lt; 0) { LOG_ERROR(\u0026#34;Bind Port:%d error!\u0026#34;, port_); close(listenFd_); return false; } ret = listen(listenFd_, 6); if(ret \u0026lt; 0) { LOG_ERROR(\u0026#34;Listen port:%d error!\u0026#34;, port_); close(listenFd_); return false; } ret = epoller_-\u0026gt;AddFd(listenFd_, listenEvent_ | EPOLLIN); if(ret == 0) { LOG_ERROR(\u0026#34;Add listen error!\u0026#34;); close(listenFd_); return false; } SetFdNonblock(listenFd_); LOG_INFO(\u0026#34;Server port:%d\u0026#34;, port_); return true; } 接着上面，用户发起请求，此时，Linux 内核唤醒起工作在设置了超时阻塞的 epoller_-\u0026gt;Wait(timeMS) ，并且返回事件个数。这里，我们看到设置了超时阻塞等待，因为可能达到超时时间，没有任何事件发生，此时，通过外层 while 循环进入到下一轮循环中，并且当获取最小设置的超时间，继续在 epoller_ 上等待事件发生。该过程如下面代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 void WebServer::Start() { int timeMS = -1; /* epoll wait timeout == -1 无事件将阻塞 */ if(!isClose_) { LOG_INFO(\u0026#34;========== Server start ==========\u0026#34;); } while(!isClose_) { if(timeoutMS_ \u0026gt; 0) { timeMS = timer_-\u0026gt;GetNextTick(); } int eventCnt = epoller_-\u0026gt;Wait(timeMS); for(int i = 0; i \u0026lt; eventCnt; i++) { /* 处理事件 */ int fd = epoller_-\u0026gt;GetEventFd(i); uint32_t events = epoller_-\u0026gt;GetEvents(i); if(fd == listenFd_) { DealListen_(); } else if(events \u0026amp; (EPOLLRDHUP | EPOLLHUP | EPOLLERR)) { assert(users_.count(fd) \u0026gt; 0); CloseConn_(\u0026amp;users_[fd]); } else if(events \u0026amp; EPOLLIN) { assert(users_.count(fd) \u0026gt; 0); DealRead_(\u0026amp;users_[fd]); } else if(events \u0026amp; EPOLLOUT) { assert(users_.count(fd) \u0026gt; 0); DealWrite_(\u0026amp;users_[fd]); } else { LOG_ERROR(\u0026#34;Unexpected event\u0026#34;); } } } } 拿到事件个数，通过循环遍历事件，进行处理事件。这里，通过 int fd = epoller_-\u0026gt;GetEventFd(i); uint32_t events = epoller_-\u0026gt;GetEvents(i); 代码获取具体事件发生哪个文件描述符上和对应的事件类型。具体参考：[[Linux 服务器编程-IO模式]]\n在这里，我们可以通过工具 gdb 进行调试，通过断点来观察当发起请求时的事件类型。运行下面命令：\n1 $ gdb ./bin/server # 进入调试 在这里，采用条件断点，当有具体事件返回时，才暂停运行，如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 Type \u0026#34;apropos word\u0026#34; to search for commands related to \u0026#34;word\u0026#34;... Reading symbols from ./bin/server... (gdb) b code/server/webserver.cpp:85 if eventCnt \u0026gt; 0 Breakpoint 1 at 0x5123e: file ../code/server/webserver.cpp, line 85. (gdb) r Starting program: /home/andy/Workplace/cpp_advance/cpp14/WebServer/bin/server warning: Error disabling address space randomization: Operation not permitted [Thread debugging using libthread_db enabled] Using host libthread_db library \u0026#34;/lib/x86_64-linux-gnu/libthread_db.so.1\u0026#34;. [New Thread 0x7f62a5409640 (LWP 2889)] [New Thread 0x7f62a4c08640 (LWP 2890)] [New Thread 0x7f62a4407640 (LWP 2891)] [New Thread 0x7f62a3c06640 (LWP 2892)] [New Thread 0x7f62a3405640 (LWP 2893)] [New Thread 0x7f62a2c04640 (LWP 2894)] [New Thread 0x7f62a2403640 (LWP 2895)] 此时，我们刷新游览器，重新发起请求，如下，可以看到成功返回在 socket 监听套接字上的事件，事件类型为 EPOLLIN，表示对应的文件描述符可以读。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 Thread 1 \u0026#34;server\u0026#34; hit Breakpoint 1, WebServer::Start (this=0x7ffd64d41970) at ../code/server/webserver.cpp:85 85 for(int i = 0; i \u0026lt; eventCnt; i++) { (gdb) p eventCnt $1 = 1 (gdb) n 87 int fd = epoller_-\u0026gt;GetEventFd(i); (gdb) n 88 uint32_t events = epoller_-\u0026gt;GetEvents(i); (gdb) n 89 if(fd == listenFd_) { (gdb) n 90 DealListen_(); (gdb) p events \u0026amp; EPOLLIN $2 = 1 下面代码我们来看看当第一次发起请求时，客户端是如何与服务端建立并保持一个计时连接，并且如何处理一个 HTTP 的资源请求的。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 void WebServer::AddClient_(int fd, sockaddr_in addr) { assert(fd \u0026gt; 0); users_[fd].init(fd, addr); if(timeoutMS_ \u0026gt; 0) { timer_-\u0026gt;add(fd, timeoutMS_, std::bind(\u0026amp;WebServer::CloseConn_, this, \u0026amp;users_[fd])); } epoller_-\u0026gt;AddFd(fd, EPOLLIN | connEvent_); SetFdNonblock(fd); LOG_INFO(\u0026#34;Client[%d] in!\u0026#34;, users_[fd].GetFd()); } void WebServer::DealListen_() { struct sockaddr_in addr; socklen_t len = sizeof(addr); do { int fd = accept(listenFd_, (struct sockaddr *)\u0026amp;addr, \u0026amp;len); if(fd \u0026lt;= 0) { return;} else if(HttpConn::userCount \u0026gt;= MAX_FD) { SendError_(fd, \u0026#34;Server busy!\u0026#34;); LOG_WARN(\u0026#34;Clients is full!\u0026#34;); return; } AddClient_(fd, addr); } while(listenEvent_ \u0026amp; EPOLLET); } 上面代码可以看到，当客户端与服务端建立连接后，会通过 accept(listenFd_, (struct sockaddr *)\u0026amp;addr, \u0026amp;len) 在服务端返回一个新的 socket 套接字，即文件描述符 fd，此时，在传输层上已经建立了 TCP 稳定连接；之后服务端生成一个表示连接的对象 HttpConn ，存入 users_ 字典中；表示一个连接对象的 HttpConn 中，保存了上面新的套接字 fd_、客户端地址 addr_以及该连接的状态 isClose_；之后，通过 epoller_-\u0026gt;AddFd(fd, EPOLLIN | connEvent_) 将这个新的套接字也加入到 epoll 事件监听中，WebServer::DealListen_() 在没有其他客户端试图建立连接时，通过语句 if(fd \u0026lt;= 0) { return;} 返回到 WebServer::Start() 函数的外层循环中。此时，客户端因为首次发起连接，服务端成功与客户端建立连接，并且监听相应的新的网络套接字。\n由于首次发起连接时，客户端向服务端发送数据包，该数据包还未被读取，此时，新的 socket 套接字 fd 处于可读状态 EPOLLIN，因此在 WebServer::Start() 函数的外层循环 while(!isClose_) 执行到 int eventCnt = epoller_-\u0026gt;Wait(timeMS) 语句时，会立即返回事件数，如果没有其他客户端发起连接，那么只有刚才成功建立连接的客户端，那么此时，事件数为 1，并且该事件发生在建立 TCP 连接的套接字 fd 上且事件为 EPOLLIN，此时，调用 DealRead_(\u0026amp;users_[fd]) 处理该请求并且处理 HTTP 协议的信息后，构造客户端请求对应的 HTTP 资源，并且通过 epoller_-\u0026gt;ModFd(client-\u0026gt;GetFd(), connEvent_ | EPOLLOUT) 使得 epoll 机制在套接字 fd 上同时监听是否可写的状态。下面代码展示了该过程：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 void WebServer::DealRead_(HttpConn* client) { assert(client); ExtentTime_(client); threadpool_-\u0026gt;AddTask(std::bind(\u0026amp;WebServer::OnRead_, this, client)); } void WebServer::OnRead_(HttpConn* client) { assert(client); int ret = -1; int readErrno = 0; ret = client-\u0026gt;read(\u0026amp;readErrno); if(ret \u0026lt;= 0 \u0026amp;\u0026amp; readErrno != EAGAIN) { CloseConn_(client); return; } OnProcess(client); } void WebServer::OnProcess(HttpConn* client) { if(client-\u0026gt;process()) { epoller_-\u0026gt;ModFd(client-\u0026gt;GetFd(), connEvent_ | EPOLLOUT); } else { epoller_-\u0026gt;ModFd(client-\u0026gt;GetFd(), connEvent_ | EPOLLIN); } } bool HttpConn::process() { request_.Init(); if(readBuff_.ReadableBytes() \u0026lt;= 0) { return false; } else if(request_.parse(readBuff_)) { LOG_DEBUG(\u0026#34;%s\u0026#34;, request_.path().c_str()); response_.Init(srcDir, request_.path(), request_.IsKeepAlive(), 200); } else { response_.Init(srcDir, request_.path(), false, 400); } response_.MakeResponse(writeBuff_); /* 响应头 */ iov_[0].iov_base = const_cast\u0026lt;char*\u0026gt;(writeBuff_.Peek()); iov_[0].iov_len = writeBuff_.ReadableBytes(); iovCnt_ = 1; /* 文件 */ if(response_.FileLen() \u0026gt; 0 \u0026amp;\u0026amp; response_.File()) { iov_[1].iov_base = response_.File(); iov_[1].iov_len = response_.FileLen(); iovCnt_ = 2; } LOG_DEBUG(\u0026#34;filesize:%d, %d to %d\u0026#34;, response_.FileLen() , iovCnt_, ToWriteBytes()); return true; } 与上面情况类似，当 DealRead_(\u0026amp;users_[fd]) 执行结束后，并且结束内层循环后，下一轮外层外层循环 while(!isClose_) 执行到 int eventCnt = epoller_-\u0026gt;Wait(timeMS) 语句时，会立即返回事件数，此时，如果没有其他客户端发起连接，只有刚才成功建立连接的客户端，那么此时，事件数为 1，并且该事件发生在建立 TCP 连接的套接字 fd 上且事件为 EPOLLOUT，此时，执行调用 DealWrite_(\u0026amp;users_[fd]) 将上面构建的构造客户端请求对应的 HTTP 资源，即 HttpConn 中的 response_ 内容发送给客户端。下面代码展示了该过程：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 void WebServer::DealWrite_(HttpConn* client) { assert(client); ExtentTime_(client); threadpool_-\u0026gt;AddTask(std::bind(\u0026amp;WebServer::OnWrite_, this, client)); } void WebServer::OnWrite_(HttpConn* client) { assert(client); int ret = -1; int writeErrno = 0; ret = client-\u0026gt;write(\u0026amp;writeErrno); if(client-\u0026gt;ToWriteBytes() == 0) { /* 传输完成 */ if(client-\u0026gt;IsKeepAlive()) { OnProcess(client); return; } } else if(ret \u0026lt; 0) { if(writeErrno == EAGAIN) { /* 继续传输 */ epoller_-\u0026gt;ModFd(client-\u0026gt;GetFd(), connEvent_ | EPOLLOUT); return; } } CloseConn_(client); } 关键技术 IO复用技术 Epoll 具体参考 [[Linux 服务器编程-IO模式#epoll]]\n线程池 简介 线程池（Thread Pool）是一种基于池化思想管理线程的工具，经常出现在多线程服务器中，如MySQL。\n线程过多会带来额外的开销，其中包括创建销毁线程的开销、调度线程的开销等等，同时也降低了计算机的整体性能。线程池维护多个线程，等待监督管理者分配可并发执行的任务。这种做法，一方面避免了处理任务时创建销毁线程开销的代价，另一方面避免了线程数量膨胀导致的过分调度问题，保证了对内核的充分利用。\n而本文描述的是一种简单的线程池实现方案，更复杂的线程池实现方法，请参考下面的资料学习。\n参考资料 Java线程池实现原理及其在美团业务中的实践 - 美团技术团队 2w字长文深度解析线程池 代码解析 为了方便理解代码，在这里我先通过下面示意图，简单描述该版本的线程池大概机制。\n下面代码实现了一个如上图线程池，整个线程池是个生产者消费者模型，该线程池一开始创建 threadCount 个固定线程，这些线程作为消费者，当线程被唤醒时，从任务队列中获取任务，执行任务；而生产者通过 AddTask(F\u0026amp;\u0026amp; task) 方法将生产的任务添加到任务缓冲队列中。可以看到，整个TaskQueue 任务队列作为临界资源被多个线程异步访问，为了保障多个线程能够安全访问 TaskQueue 中 std::queue\u0026lt;std::function\u0026lt;void()\u0026gt;\u0026gt; tasks 队列 变量时，每次操作都需要通过互斥量 std::mutex mtx 进行加锁后再进行访问。\n注：这里笔者将源码中 Pool 结构体改名成 TaskQueue，代表的含义更为合适。\n可以先阅读下面源码，后面给出源码相关问题及回答。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 /* * @File : threadpool.h * @Author : mark * @Date : 2020-06-15 * @copyleft Apache 2.0 */ #ifndef THREADPOOL_H #define THREADPOOL_H #include \u0026lt;mutex\u0026gt; #include \u0026lt;condition_variable\u0026gt; #include \u0026lt;queue\u0026gt; #include \u0026lt;thread\u0026gt; #include \u0026lt;functional\u0026gt; class ThreadPool { public: explicit ThreadPool(size_t threadCount = 8): task_queue_(std::make_shared\u0026lt;TaskQueue\u0026gt;()) { assert(threadCount \u0026gt; 0); for(size_t i = 0; i \u0026lt; threadCount; i++) { std::thread([task_queue = task_queue_] { std::unique_lock\u0026lt;std::mutex\u0026gt; locker(task_queue-\u0026gt;mtx); while(true) { if(!task_queue-\u0026gt;tasks.empty()) { auto task = std::move(task_queue-\u0026gt;tasks.front()); task_queue-\u0026gt;tasks.pop(); locker.unlock(); task(); locker.lock(); } else if(task_queue-\u0026gt;isClosed) break; else task_queue-\u0026gt;cond.wait(locker); } }).detach(); } } ThreadPool() = default; ThreadPool(ThreadPool\u0026amp;\u0026amp;) = default; ~ThreadPool() { if(static_cast\u0026lt;bool\u0026gt;(task_queue_)) { { std::lock_guard\u0026lt;std::mutex\u0026gt; locker(task_queue_-\u0026gt;mtx); task_queue_-\u0026gt;isClosed = true; } task_queue_-\u0026gt;cond.notify_all(); } } template\u0026lt;class F\u0026gt; void AddTask(F\u0026amp;\u0026amp; task) { { std::lock_guard\u0026lt;std::mutex\u0026gt; locker(task_queue_-\u0026gt;mtx); task_queue_-\u0026gt;tasks.emplace(std::forward\u0026lt;F\u0026gt;(task)); } task_queue_-\u0026gt;cond.notify_one(); } private: struct TaskQueue { std::mutex mtx; std::condition_variable cond; bool isClosed; std::queue\u0026lt;std::function\u0026lt;void()\u0026gt;\u0026gt; tasks; }; std::shared_ptr\u0026lt;TaskQueue\u0026gt; task_queue_; }; #endif //THREADPOOL_H 为什么该线程池所有的实现在 threadpool.h 中完成？\n上面源码为线程池的头文件 threadpool.h，而且该线程池没有对应的 threadpool.cpp 实现代码文件，这种在类中实现方法的方式，使得类中方法都是缺省内联的，这样在编译的时候把函数调用的部分直接换成函数代码，而不是进行函数调用，这适用于函数代码少的时候，可以避免调用带来栈空间的消耗，也可以减少一定的调用时间。\nexplicit 修饰的构造函数如何理解？\n通过将构造函数声明为explicit（显式）的方式可以抑制隐式转换。也就是说，explicit构造函数必须显式调用。按默认规定，只用传一个参数的构造函数也定义了一个隐式转换。具体参考：C++ explicit关键字详解\nstd::make_shared 作用是什么？在什么场景下使用？\n如有可能，第一次创建内存资源时，请使用 make_shared 函数创建 shared_ptr。 make_shared 异常安全。 它使用同一调用为控制块和资源分配内存，这会减少构造开销。 如果不使用 make_shared，则必须先使用显式 new 表达式来创建对象，然后才能将其传递到 shared_ptr 构造函数。具体参考：如何：创建和使用 shared_ptr 实例\nvoid detach() 作用？\n拆离相关联的线程。 操作系统负责释放终止的线程资源。具体参考：thread类-detach\nstd::unique_lock 作用及应用场景？\n表示可进行实例化以创建管理 mutex 锁定和解锁的对象的模板。uniqie_lock 是个类模板，它的功能跟 lock_quard 类似，但比 lock_quard 更灵活。在工作中，一般用 lock_quard （推荐使用）就足够了，但在一些特殊的场景下会用到 uniqie_lock。 lock_quard 取代了 mutex 的 lock() 和 unlock()，在 lock_quard 的构造函数中上锁，在析构函数中解锁，这点其实在 uniqie_lock 中也是一样的。uniqie_lock 在使用上比 lock_quard 灵活，但代价就是效率会低一点，并且内存占用量也会相对高一些。具体参考：unique_lock详解 和 unique_lock 类\nstd::mutex 作用及应用场景？\nMutex 又称互斥量，C++ 11中与 Mutex 相关的类（包括锁类型）和函数都声明在 \u0026lt;mutex\u0026gt; 头文件中，所以如果你需要使用 std::mutex，就必须包含 \u0026lt;mutex\u0026gt; 头文件。std::mutex 是C++11 中最基本的互斥量，std::mutex 对象提供了独占所有权的特性——即不支持递归地对 std::mutex 对象上锁，而 std::recursive_lock 则可以递归地对互斥量对象上锁。具体参考：C++11 并发指南三(std::mutex 详解)\nstd::move 与 std::forward 作用及应用场景？\nstd::forward 比 std::move 逻辑略复杂，std::move 是无条件把参数转换为右值，而 std::forward 在特定情况下才会这样做：仅当参数是用右值初始化时，才会把它转换为右值。它的意义是使外面的函数调用选择接受右值的版本，实际的移动工作是由外面的函数进行的；使用std::forward来转发参数一般被称为完美转发 (也叫精确传递)。具体参考：C++ 理解std::forward完美转发。这里，使用 std::move 将 pool-\u0026gt;tasks.front() 装换为右值，从而使得 std::function 类型的 task 调用 function\u0026amp; operator= (function\u0026amp;\u0026amp; rhs); 构造函数，避免资源重复申请创建。详细讨论参考：知乎std::move回答\nThreadPool(ThreadPool\u0026amp;\u0026amp;) = default; 该构造函数是什么含义？\n此语句代表显式默认构造函数，而且该构造函数为移动构造函数，移动构造函数是特殊成员函数，它将现有对象数据的所有权移交给新变量，而不复制原始数据。 它采用 rvalue 引用作为其第一个参数，以后的任何参数都必须具有默认值。 **移动构造函数在传递大型对象时可以显著提高程序的效率。**具体参考：显式默认设置的函数和已删除的函数 | Microsoft Learn 和 移动构造函数 (C++) | Microsoft Learn\n代码 task_queue_-\u0026gt;tasks.emplace(std::forward\u0026lt;F\u0026gt;(task)); 语句如何理解？\n首先，task_queue_-\u0026gt;tasks 的类型是 std::queue\u0026lt;std::function\u0026lt;void()\u0026gt;\u0026gt;，成员函数 emplace，会在当前的最后一个元素之后，即队列的末尾添加了一个新元素。 这个新元素会采用元素类的构造函数够赞，并且将 std::forward\u0026lt;F\u0026gt;(task)) 作为其构造函数的参数；另外，此处，std::forward\u0026lt;F\u0026gt; 将输入的参数原封不动地传递到下一个函数中，如果输入的参数是左值，那么传递给下一个函数的参数的也是左值；如果输入的参数是右值，那么传递给下一个函数的参数的也是右值。那么，当 task 参数是右值时，完美转发后，将会调用移动构造函数 function( function\u0026amp;\u0026amp; other ); 进行构造。此处，还需更深入理解。可以参考书籍《深入理解C++11：C++11新特性解析与应用》\n基于小根堆实现的定时器 小根堆 堆（Heap）是计算机科学中的一种特别的完全二叉树。若是满足以下特性，即可称为堆：“给定堆中任意节点P和C，若P是C的母节点，那么P的值会小于等于（或大于等于）C的值”。若母节点的值恒小于等于子节点的值，此堆称为最小堆（min heap）；反之，若母节点的值恒大于等于子节点的值，此堆称为最大堆（max heap）。在堆中最顶端的那一个节点，称作根节点（root node），根节点本身没有母节点（parent node）。参考：堆 - 维基百科\n根据上面定义可知，小根堆（min heap）的根节点总是小于等于其他任意节点。\n那么，这里为什么要用小根堆实现定时器呢？\n首先，定时器和我们大家常用的闹钟类似，记录到时时间，由于，服务器会保持大量的连接，因此，对于每个连接都需要记录一个定期时间（expires），这里采用 C++ 中任何一个容器就可以了；但是，考虑到我们采用定时器是为了将那些已经超时的连接关闭，对于一个记录大量倒计时的记录来说，必然是那些定期时间时间较小的连接，首先到达超时时间，这意味着这些连接距离上次连接活动已经过去了较长时间，因此，我们每次要获取这些定期时间记录中最小记录，判断是否超时，如果小于当前时间，代表已经超时，那么关闭这个 TCP 连接，重复上面至获取的定期时间大于当前时间；另外，由于在 WebServer::Start() 中存在 epoller_-\u0026gt;Wait(timeMS) ，这表明主线程会进入超时阻塞中，主动放弃 CPU ，当有事件发生或者到达超时时间才会被操作系统内核主动唤醒，那么，这里的参数 timeMS 如果设置过大，将会导致无法及时关闭超时连接，造成网络连接资源浪费；如果该参数设置过小，将会导致频繁唤醒主线程，导致 CPU 资源浪费。综上，我们每次获取全部连接定时器中剩余时间最短的时间，将此时间设置为 timeMS ，这样，就能及时关闭超时连接，也不会造成资源浪费。\n源码解析 下面我们根据源码分析该定时器功能。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 /* * @File : heaptimer.h * @Author : mark * @Date : 2020-06-17 * @copyleft Apache 2.0 */ #ifndef HEAP_TIMER_H #define HEAP_TIMER_H #include \u0026lt;queue\u0026gt; #include \u0026lt;unordered_map\u0026gt; #include \u0026lt;time.h\u0026gt; #include \u0026lt;algorithm\u0026gt; #include \u0026lt;arpa/inet.h\u0026gt; #include \u0026lt;functional\u0026gt; #include \u0026lt;assert.h\u0026gt; #include \u0026lt;chrono\u0026gt; #include \u0026#34;../log/log.h\u0026#34; typedef std::function\u0026lt;void()\u0026gt; TimeoutCallBack; typedef std::chrono::high_resolution_clock Clock; typedef std::chrono::milliseconds MS; typedef Clock::time_point TimeStamp; struct TimerNode { int id; // 网络套接字描述符 TimeStamp expires; // 到期时间戳 TimeoutCallBack cb; // 到期回调函数 bool operator\u0026lt;(const TimerNode\u0026amp; t) { // TimerNode 小于运算符 return expires \u0026lt; t.expires; } }; class HeapTimer { public: // 构造函数，并初始化当前vector容器容量为64 HeapTimer() { heap_.reserve(64); } ~HeapTimer() { clear(); } // 调整网络套接描述符id的连接超时时间为 timeOut void adjust(int id, int timeOut); // 添加网络套接描述符id的连接超时时间为 timeOut，并设置超时回调函数 void add(int id, int timeOut, const TimeoutCallBack\u0026amp; cb); // 删除指定id结点，并触发回调函数 void doWork(int id); // 清空堆 void clear(); // 清除超时节点 void tick(); // 清楚堆顶节点 void pop(); // 获取最近到期超时连接的剩余时间ms int GetNextTick(); private: // 删除节点 void del_(size_t i); // 节点向上调整 void siftup_(size_t i); // 节点向下调整 bool siftdown_(size_t index, size_t n); // 交换两个节点 void SwapNode_(size_t i, size_t j); // 用 vector 实现的小根堆 std::vector\u0026lt;TimerNode\u0026gt; heap_; // 记录网络套接描述符到 TimerNode 在 heap_ 中的位置映射关系 std::unordered_map\u0026lt;int, size_t\u0026gt; ref_; }; #endif //HEAP_TIMER_H HeapTimer 实现：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 /* * @File : heaptimer.cpp * @Author : mark * @Date : 2020-06-17 * @copyleft Apache 2.0 */ #include \u0026#34;heaptimer.h\u0026#34; void HeapTimer::siftup_(size_t i) { assert(i \u0026gt;= 0 \u0026amp;\u0026amp; i \u0026lt; heap_.size()); size_t j = (i - 1) / 2; while(j \u0026gt;= 0) { if(heap_[j] \u0026lt; heap_[i]) { break; } SwapNode_(i, j); i = j; j = (i - 1) / 2; } } void HeapTimer::SwapNode_(size_t i, size_t j) { assert(i \u0026gt;= 0 \u0026amp;\u0026amp; i \u0026lt; heap_.size()); assert(j \u0026gt;= 0 \u0026amp;\u0026amp; j \u0026lt; heap_.size()); std::swap(heap_[i], heap_[j]); ref_[heap_[i].id] = i; ref_[heap_[j].id] = j; } bool HeapTimer::siftdown_(size_t index, size_t n) { assert(index \u0026gt;= 0 \u0026amp;\u0026amp; index \u0026lt; heap_.size()); assert(n \u0026gt;= 0 \u0026amp;\u0026amp; n \u0026lt;= heap_.size()); size_t i = index; size_t j = i * 2 + 1; while(j \u0026lt; n) { if(j + 1 \u0026lt; n \u0026amp;\u0026amp; heap_[j + 1] \u0026lt; heap_[j]) j++; if(heap_[i] \u0026lt; heap_[j]) break; SwapNode_(i, j); i = j; j = i * 2 + 1; } return i \u0026gt; index; } void HeapTimer::add(int id, int timeout, const TimeoutCallBack\u0026amp; cb) { assert(id \u0026gt;= 0); size_t i; if(ref_.count(id) == 0) { /* 新节点：堆尾插入，调整堆 */ i = heap_.size(); ref_[id] = i; heap_.push_back({id, Clock::now() + MS(timeout), cb}); siftup_(i); } else { /* 已有结点：调整堆 */ i = ref_[id]; heap_[i].expires = Clock::now() + MS(timeout); heap_[i].cb = cb; if(!siftdown_(i, heap_.size())) { siftup_(i); } } } void HeapTimer::doWork(int id) { /* 删除指定id结点，并触发回调函数 */ if(heap_.empty() || ref_.count(id) == 0) { return; } size_t i = ref_[id]; TimerNode node = heap_[i]; node.cb(); del_(i); } void HeapTimer::del_(size_t index) { /* 删除指定位置的结点 */ assert(!heap_.empty() \u0026amp;\u0026amp; index \u0026gt;= 0 \u0026amp;\u0026amp; index \u0026lt; heap_.size()); /* 将要删除的结点换到队尾，然后调整堆 */ size_t i = index; size_t n = heap_.size() - 1; assert(i \u0026lt;= n); if(i \u0026lt; n) { SwapNode_(i, n); if(!siftdown_(i, n)) { siftup_(i); } } /* 队尾元素删除 */ ref_.erase(heap_.back().id); heap_.pop_back(); } void HeapTimer::adjust(int id, int timeout) { /* 调整指定id的结点 */ assert(!heap_.empty() \u0026amp;\u0026amp; ref_.count(id) \u0026gt; 0); heap_[ref_[id]].expires = Clock::now() + MS(timeout);; siftdown_(ref_[id], heap_.size()); } void HeapTimer::tick() { /* 清除超时结点 */ if(heap_.empty()) { return; } while(!heap_.empty()) { TimerNode node = heap_.front(); if(std::chrono::duration_cast\u0026lt;MS\u0026gt;(node.expires - Clock::now()).count() \u0026gt; 0) { break; } node.cb(); pop(); } } void HeapTimer::pop() { assert(!heap_.empty()); del_(0); } void HeapTimer::clear() { ref_.clear(); heap_.clear(); } int HeapTimer::GetNextTick() { tick(); size_t res = -1; if(!heap_.empty()) { res = std::chrono::duration_cast\u0026lt;MS\u0026gt;(heap_.front().expires - Clock::now()).count(); if(res \u0026lt; 0) { res = 0; } } return res; } 异步日志系统 简介 系统日志是用来记录服务器的运行状态，以保证系统的正常运行，记录的信息如时间日期、客户端的读写操作、当前客户端连接数量、Error与Warn状况等，Webserver是采用单例模式与阻塞队列实现的异步的日志系统，如下为日志的记录情况：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 2023-01-28 04:17:37.625250 [info] : ========== Server init ========== 2023-01-28 04:17:37.625274 [info] : Port:1316, OpenLinger: false 2023-01-28 04:17:37.625281 [info] : Listen Mode: ET, OpenConn Mode: ET 2023-01-28 04:17:37.625283 [info] : LogSys level: 1 2023-01-28 04:17:37.625286 [info] : srcDir: /home/andy/Workplace/cpp_advance/cpp14/WebServer/resources/ 2023-01-28 04:17:37.625369 [info] : SqlConnPool num: 12, ThreadPool num: 6 2023-01-28 04:17:37.625376 [info] : ========== Server start ========== 2023-01-28 04:17:49.682366 [info] : Client[6](172.17.0.1:60549) in, userCount:1 2023-01-28 04:17:49.685458 [info] : Client[6] in! 2023-01-28 04:17:49.767379 [info] : Client[7](172.17.0.1:64133) in, userCount:2 2023-01-28 04:17:49.772650 [info] : Client[7] in! 2023-01-28 04:17:49.774038 [info] : Client[8](172.17.0.1:2694) in, userCount:3 2023-01-28 04:17:49.775470 [info] : Client[8] in! 2023-01-28 04:17:49.777246 [info] : Client[9](172.17.0.1:6278) in, userCount:4 2023-01-28 04:17:49.779328 [info] : Client[9] in! 2023-01-28 04:17:49.781121 [info] : Client[10](172.17.0.1:7302) in, userCount:5 2023-01-28 04:17:49.782755 [info] : Client[10] in! 2023-01-28 04:17:49.888415 [info] : Client[11](172.17.0.1:11398) in, userCount:6 2023-01-28 04:17:49.890183 [info] : Client[11] in! 2023-01-28 04:19:00.082966 [info] : Client[8] quit! 2023-01-28 04:19:00.086492 [info] : Client[8](172.17.0.1:2694) quit, UserCount:5 2023-01-28 04:19:00.087991 [info] : Client[9] quit! 2023-01-28 04:19:00.088420 [info] : Client[9](172.17.0.1:6278) quit, UserCount:4 2023-01-28 04:19:00.089962 [info] : Client[11] quit! 2023-01-28 04:19:00.091502 [info] : Client[11](172.17.0.1:11398) quit, UserCount:3 2023-01-28 04:19:00.092822 [info] : Client[10] quit! 2023-01-28 04:19:00.094522 [info] : Client[10](172.17.0.1:7302) quit, UserCount:2 2023-01-28 04:19:00.095606 [info] : Client[6] quit! 2023-01-28 04:19:00.096684 [info] : Client[6](172.17.0.1:60549) quit, UserCount:1 2023-01-28 04:19:00.316124 [info] : Client[7] quit! 源码解析 Log 类在被实例化时系统有且最多只有一个 Log 类的对象即单例模式，它是如何实现的呢?\n首先会将 Log 类的构造函数、拷贝构造函数和赋值运算符重载函数私有化，由此外界就不能直接创建Log类对象，这时我们需要一个静态 Log 类型的对象，以便系统使用同一的类对象，而外界想要获取静态 Log 类型的对象，就需要定义一个静态成员方法，因为只有静态成员方法才能访问静态成员变量，由此实现 Log 类的单例模式。\nLog 类及 Instance 函数的定义：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 class Log { public: void init(int level, const char* path = \u0026#34;./log\u0026#34;, const char* suffix =\u0026#34;.log\u0026#34;, int maxQueueCapacity = 1024); static Log* Instance(); static void FlushLogThread(); void write(int level, const char *format,...); void flush(); int GetLevel(); void SetLevel(int level); bool IsOpen() { return isOpen_; } private: Log(); void AppendLogLevelTitle_(int level); virtual ~Log(); void AsyncWrite_(); private: static const int LOG_PATH_LEN = 256; static const int LOG_NAME_LEN = 256; static const int MAX_LINES = 50000; const char* path_; const char* suffix_; int MAX_LINES_; int lineCount_; int toDay_; bool isOpen_; Buffer buff_; int level_; bool isAsync_; FILE* fp_; std::unique_ptr\u0026lt;BlockDeque\u0026lt;std::string\u0026gt;\u0026gt; deque_; std::unique_ptr\u0026lt;std::thread\u0026gt; writeThread_; std::mutex mtx_; }; Log* Log::Instance() { static Log inst; return \u0026amp;inst; } 系统中有4种类型的日志，分别是 LOG_DEBUG 、 LOG_INFO 、 LOG_WARN 与 LOG_ERROR ，它们共同使用 LOG_BASE，以level来区分不同级别的日志，以实现代码的复用。同时自己初始设置的日志等级可以控制不同级别的日志是否被记录，宏定义如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 // 语言设置为 C# 才会有颜色高亮 #define LOG_BASE(level, format, ...) \\ do {\\ Log* log = Log::Instance();\\ if (log-\u0026gt;IsOpen() \u0026amp;\u0026amp; log-\u0026gt;GetLevel() \u0026lt;= level) {\\ log-\u0026gt;write(level, format, ##__VA_ARGS__); \\ log-\u0026gt;flush();\\ }\\ } while(0); #define LOG_DEBUG(format, ...) do {LOG_BASE(0, format, ##__VA_ARGS__)} while(0); #define LOG_INFO(format, ...) do {LOG_BASE(1, format, ##__VA_ARGS__)} while(0); #define LOG_WARN(format, ...) do {LOG_BASE(2, format, ##__VA_ARGS__)} while(0); #define LOG_ERROR(format, ...) do {LOG_BASE(3, format, ##__VA_ARGS__)} while(0); 在 webserver.cpp 中，如果开启日志即 openLog = true 时，则会先调用 init() 去初始化日志信息，当 maxQueueSize \u0026gt; 0 时则会创建一个阻塞队列与写线程，值得注意的是日志系统是单线程模式，因为并不需要较高的并发量，写线程的回调函数则当阻塞队列不空时持续向 FILE* 类型的指针 fp_ 写入字符串，再使用 fflush(fp_) 刷新至文件中。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 void Log::init(int level = 1, const char* path, const char* suffix, int maxQueueSize) { isOpen_ = true; level_ = level; if(maxQueueSize \u0026gt; 0) { isAsync_ = true; if(!deque_) { unique_ptr\u0026lt;BlockDeque\u0026lt;std::string\u0026gt;\u0026gt; newDeque(new BlockDeque\u0026lt;std::string\u0026gt;(maxQueueSize)); deque_ = move(newDeque); std::unique_ptr\u0026lt;std::thread\u0026gt; NewThread(new thread(FlushLogThread)); writeThread_ = move(NewThread); } } else { isAsync_ = false; } lineCount_ = 0; time_t timer = time(nullptr); struct tm *sysTime = localtime(\u0026amp;timer); struct tm t = *sysTime; path_ = path; suffix_ = suffix; char fileName[LOG_NAME_LEN] = {0}; snprintf(fileName, LOG_NAME_LEN - 1, \u0026#34;%s/%04d_%02d_%02d%s\u0026#34;, path_, t.tm_year + 1900, t.tm_mon + 1, t.tm_mday, suffix_); toDay_ = t.tm_mday; { lock_guard\u0026lt;mutex\u0026gt; locker(mtx_); buff_.RetrieveAll(); if(fp_) { flush(); fclose(fp_); } fp_ = fopen(fileName, \u0026#34;a\u0026#34;); if(fp_ == nullptr) { mkdir(path_, 0777); fp_ = fopen(fileName, \u0026#34;a\u0026#34;); } assert(fp_ != nullptr); } } 当使用 LOG_DEBUG 、 LOG_INFO 、 LOG_WARN 与 LOG_ERROR 时，则会宏替换为 LOG_BASE ， LOG_BASE 继续宏替换至执行代码，然后依据日志开关与等级是否记录，如果记录则会调用 write() 函数，在 write() 函数中会制作日志记录如日志日期、日志行数、日志内容等至 buff_ 中，然后添加至阻塞队列中，在 AsyncWrite_() 函数的循环能继续向下执行，向 FILE* 类型的指针 fp_ 写入字符串，然后再调用 flush() 函数刷新至日志文件中，这是日志记录的整个过程，可结合上述的具体实现。而 write() 函数可自行查看源代码。\n总结与感悟 目前来说，好好完善并思考这个项目就可以达到对于 C++14、Linux 网络编程综合学习与训练的目的了，后面进阶还需要真正参与到工业生产代码中，在实践中认真学习与总结。 这种比较偏底层的网络编程，对于应用层来说已经有了很多成熟的软件库，大多数时候不用修改和优化。 源码阅读进阶 [[Redis 源码阅读]] linyacool/WebServer: A C++ High Performance Web Server chenshuo/muduo: Event-driven network library for multi-threaded Linux server in C++11 参考资料 WebServer 源码 C++ 语言文档 | Microsoft Learn C++ Linux轻量级WebServer 《深入理解C++11：C++11 新特性解析与应用》书籍 扩展知识 NanoLog：一个非常高性能的纳秒级c++日志记录系统，它提供了一个简单的类似print的API，在7纳秒的中位数延迟下实现了超过8000万条日志/秒。 args：C++实现的命令行参数解析器。 ","date":"2024-06-22T17:34:15+08:00","image":"http://localhost:1313/posts/%E9%AB%98%E6%95%88%E4%B9%8B%E7%BE%8Ec++14/webserver_cover_hu_b1276e92bd07efc6.jpg","permalink":"http://localhost:1313/posts/%E9%AB%98%E6%95%88%E4%B9%8B%E7%BE%8Ec++14/","title":"高效之美：C++14 WebServer 源码探秘"},{"content":"前言 笔者大概从五年前大二开始接触 vim 编辑器，当时有很多关于两款“史前”编辑器 Vim 和 Emacs 的争论，对于一些较早前的极客一般分为 Vim 党、 Emacs 党 和其他。 笔者自开始接触 Linux 系统就学习的 Vim ，一直使用到现在，几乎所有 IDE 、游览器和笔记系统Logseq都开启 vim 模式，也算是一个 Vim 党。然而，笔者无心参与 Vim 和 Emacs 两款编辑器之争；很明显，现代大型项目的开发，已经几乎必须采取像 idea、clion、vscode 这些优秀的 IDE ；当下，笔者更多地使用 Vim（终端界面）编写一些算法题，这样既减少成熟 IDE 自动的补全机制对于笔者自身的驯化（经常知道某些函数，然而自己拼不对，非常依赖IDE智能提示），又能让笔者对 Vim 操作和 shell 脚本编程更加熟练；此篇博客介绍笔者在终端界面下使用 Vim 编写算法题搭建的自动化编译运行环境。\n相关环境 系统：macOS Monterey 12.5.1\nvim：MacVim 8.2\n文件检测：fswatch 1.16.0\nVim 配置 参考此篇博客：2022 最新 Mac Vim 开发环境的部署与配置\n效果如下图（点击图片可以放大查看）：\nShell 脚本 通过 Shell 脚本来实现当自己编写程序时，保存完后，自动进行编译及运行。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 # fswatch.sh FILE_NAME=$1 fswatch -0 ./${FILE_NAME} | while read -d \u0026#34;\u0026#34; event; do echo \u0026#34;[TIME: `date +\u0026#34;%Y-%m-%d \\033[47;30m%H:%M:%S\\033[0m\u0026#34;`]\\033[0m This file ${event} has changed. \\033[0m\u0026#34; echo \u0026#34;[TIME: `date +\u0026#34;%Y-%m-%d \\033[47;30m%H:%M:%S\\033[0m\u0026#34;`]\\033[0m $ g++ -std=c++11 ${FILE_NAME} -o a.out\u0026#34; g++ -std=c++11 ${FILE_NAME} -o a.out if [ $? -eq 0 ]; then echo \u0026#34;[TIME: `date +\u0026#34;%Y-%m-%d \\033[47;30m%H:%M:%S\\033[0m\u0026#34;`]\\033[0m \\033[36m 编译通过！ \\033[0m\u0026#34; echo \u0026#34;\u0026#34; echo \u0026#34;[TIME: `date +\u0026#34;%Y-%m-%d \\033[47;30m%H:%M:%S\\033[0m\u0026#34;`]\\033[0m $ ./a.out\u0026#34; ./a.out if [ $? -eq 0 ]; then echo \u0026#34;[TIME: `date +\u0026#34;%Y-%m-%d \\033[47;30m%H:%M:%S\\033[0m\u0026#34;`]\\033[0m \\033[32m执行完成，通过! \\033[0m\u0026#34; echo \u0026#34;\u0026#34; fi fi done 通过在终端的另一个标签下执行：\n1 ./fswatch.sh template.cpp 这样，每次对 template.cpp 文件进行修改并保存时，会自动触发 fswatch.sh 中编写的脚本，完成对程序的自动编译和运行。 该脚本的效果如下图（点击可以查看大图）：\n这样便可以愉快的刷题了，哈哈，加油！！！\n问题 当在 Vim 进行一次保存时，fswatch 会触发两次，目前不清楚如何解决。\n","date":"2022-09-17T19:34:41+08:00","image":"http://localhost:1313/posts/vim-%E7%AE%97%E6%B3%95-%E5%88%B7%E9%A2%98%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/vim_cover_hu_4cf544ee35f126ba.jpg","permalink":"http://localhost:1313/posts/vim-%E7%AE%97%E6%B3%95-%E5%88%B7%E9%A2%98%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/","title":"Vim 与算法刷题：打造高效开发环境"},{"content":"前言 在阅读 c++ 实现的 WebServer 源码时，感觉其中线程池实现值得具体分析，此篇博客分析该源码中线程池实现部分。\n源码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 /* * @file : threadpool.h * @Author : mark * @Date : 2020-06-15 * @copyleft Apache 2.0 */ #ifndef THREADPOOL_H #define THREADPOOL_H #include \u0026lt;mutex\u0026gt; #include \u0026lt;condition_variable\u0026gt; #include \u0026lt;queue\u0026gt; #include \u0026lt;thread\u0026gt; #include \u0026lt;functional\u0026gt; class ThreadPool { public: explicit ThreadPool(size_t threadCount = 8): pool_(std::make_shared\u0026lt;Pool\u0026gt;()) { assert(threadCount \u0026gt; 0); for(size_t i = 0; i \u0026lt; threadCount; i++) { std::thread([pool = pool_] { std::unique_lock\u0026lt;std::mutex\u0026gt; locker(pool-\u0026gt;mtx); while(true) { if(!pool-\u0026gt;tasks.empty()) { auto task = std::move(pool-\u0026gt;tasks.front()); pool-\u0026gt;tasks.pop(); locker.unlock(); task(); locker.lock(); } else if(pool-\u0026gt;isClosed) break; else pool-\u0026gt;cond.wait(locker); } }).detach(); } } ThreadPool() = default; ThreadPool(ThreadPool\u0026amp;\u0026amp;) = default; ~ThreadPool() { if(static_cast\u0026lt;bool\u0026gt;(pool_)) { { std::lock_guard\u0026lt;std::mutex\u0026gt; locker(pool_-\u0026gt;mtx); pool_-\u0026gt;isClosed = true; } pool_-\u0026gt;cond.notify_all(); } } template\u0026lt;class F\u0026gt; void AddTask(F\u0026amp;\u0026amp; task) { { std::lock_guard\u0026lt;std::mutex\u0026gt; locker(pool_-\u0026gt;mtx); pool_-\u0026gt;tasks.emplace(std::forward\u0026lt;F\u0026gt;(task)); } pool_-\u0026gt;cond.notify_one(); } private: struct Pool { std::mutex mtx; std::condition_variable cond; bool isClosed; std::queue\u0026lt;std::function\u0026lt;void()\u0026gt;\u0026gt; tasks; }; std::shared_ptr\u0026lt;Pool\u0026gt; pool_; }; #endif //THREADPOOL_H 源码分析 为什么该线程池所有的实现在 threadpool.h 中完成？\n上面源码为线程池的头文件 threadpool.h，而且该线程池没有对应的 threadpool.cpp 实现代码文件，这种在类中实现方法的方式，使得类中方法都是缺省内联的，这样在编译的时候把函数调用的部分直接换成函数代码，而不是进行函数调用，这适用于函数代码少的时候，可以避免调用带来栈空间的消耗，也可以减少一定的调用时间。\nexplicit 修饰的构造函数如何理解？\n通过将构造函数声明为explicit（显式）的方式可以抑制隐式转换。也就是说，explicit构造函数必须显式调用。按默认规定，只用传一个参数的构造函数也定义了一个隐式转换。具体参考：C++ explicit关键字详解\nstd::make_shared 作用是什么？在什么场景下使用？\n如有可能，第一次创建内存资源时，请使用 make_shared 函数创建 shared_ptr。 make_shared 异常安全。 它使用同一调用为控制块和资源分配内存，这会减少构造开销。 如果不使用 make_shared，则必须先使用显式 new 表达式来创建对象，然后才能将其传递到 shared_ptr 构造函数。具体参考：如何：创建和使用 shared_ptr 实例\nvoid detach() 作用？\n拆离相关联的线程。 操作系统负责释放终止的线程资源。具体参考：thread类-detach\nstd::unique_lock 作用及应用场景？\n表示可进行实例化以创建管理 mutex 锁定和解锁的对象的模板。uniqie_lock 是个类模板，它的功能跟 lock_quard 类似，但比 lock_quard 更灵活。在工作中，一般用 lock_quard （推荐使用）就足够了，但在一些特殊的场景下会用到 uniqie_lock。 lock_quard 取代了 mutex 的 lock() 和 unlock()，在 lock_quard 的构造函数中上锁，在析构函数中解锁，这点其实在 uniqie_lock 中也是一样的。uniqie_lock 在使用上比 lock_quard 灵活，但代价就是效率会低一点，并且内存占用量也会相对高一些。具体参考：unique_lock详解 和 unique_lock 类\nstd::mutex 作用及应用场景？\nMutex 又称互斥量，C++ 11中与 Mutex 相关的类（包括锁类型）和函数都声明在 \u0026lt;mutex\u0026gt; 头文件中，所以如果你需要使用 std::mutex，就必须包含 \u0026lt;mutex\u0026gt; 头文件。std::mutex 是C++11 中最基本的互斥量，std::mutex 对象提供了独占所有权的特性——即不支持递归地对 std::mutex 对象上锁，而 std::recursive_lock 则可以递归地对互斥量对象上锁。具体参考：C++11 并发指南三(std::mutex 详解)\nstd::move 与 std::forward 作用及应用场景？\nstd::forward 比 std::move 逻辑略复杂，std::move 是无条件把参数转换为右值，而 std::forward 在特定情况下才会这样做：仅当参数是用右值初始化时，才会把它转换为右值。它的意义是使外面的函数调用选择接受右值的版本，实际的移动工作是由外面的函数进行的；使用std::forward来转发参数一般被称为完美转发 (也叫精确传递)。具体参考：C++ 理解std::forward完美转发。这里，使用 std::move 将 pool-\u0026gt;tasks.front() 装换为右值，从而使得 std::function 类型的task调用 function\u0026amp; operator= (function\u0026amp;\u0026amp; rhs); 构造函数，避免资源重复申请创建。详细讨论参考：知乎std::move回答\n","date":"2022-08-14T11:12:32+08:00","image":"http://localhost:1313/posts/webserverc++%E7%89%88%E4%BB%A3%E7%A0%81%E5%88%86%E6%9E%90%E4%B9%8B%E7%BA%BF%E7%A8%8B%E6%B1%A0/thread-pool_hu_e7ce68685ba42ba2.png","permalink":"http://localhost:1313/posts/webserverc++%E7%89%88%E4%BB%A3%E7%A0%81%E5%88%86%E6%9E%90%E4%B9%8B%E7%BA%BF%E7%A8%8B%E6%B1%A0/","title":"WebServer（C++版）代码分析之线程池"},{"content":"前言 笔者近几年使用 Python 语言来做深度学习、计算机视觉领域相关科研与工作，对于调试程序，使用较多的工具除了 JetBrains 家的各个 IDE 以外，就是使用 Python 自带的 pdb 模块来调试 Python 程序，命令行界面调试代码既灵活，而且速度也快，非常好用。最近，因为项目原因接触 c/c++ 代码更多一些，通过本篇博客对 GDB 学习并且记录相关常用命令。\nGDB是一个由GNU开源组织发布的、UNIX / LINUX操作系统下的、基于命令行的、功能强大的程序调试工具。 对于一名Linux下工作的c/c++程序员，gdb是必不可少的工具，另外，GDB可以调试Ada、C、 C++、 Asm、 Minimal、 D、 Fortran、 Objective-c、 Go、 Java、 Pascal等语言。标准的 GDB 是纯命令行式的，但也有一些基于它的图形化工具（比如 DDD、Data Display Debugger），但用好 GDB 命令行调试，还是我们的一项基本素质。\n本篇文章将简单地介绍 GDB 常见用法，更多内容通过本博客下面的参考资料学习。\nGDB 使用流程 启动 GDB 调试 学习 GDB 调试测试的代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 #include\u0026lt;stdio.h\u0026gt; int square(int x) { return x * x; } int get_num(int x) { int x_2 = square(x); return x_2; } int main(){ int a = 10; int b = get_num(a); } 通过下面命令编译 C++ 代码，注意需要使用 -g 参数，在编译生成的目标文件中加入源码信息，并启动 GDB 调试代码：\n1 2 3 gcc -g test.cpp -o test # 编译源文件 gdb test # 启动 gdb 开始调试代码 gdb -q test # -q 表示不打印gdb版本信息，界面较为干净； 查看源码 list(简写 l)： 查看源程序代码，默认显示10行，按回车键或继续输入l查看下10行。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 Reading symbols from test... (gdb) l 1 #include\u0026lt;stdio.h\u0026gt; 2 int square(int x) { 3 return x * x; 4 } 5 6 int get_num(int x) { 7 int x_2 = square(x); 8 return x_2; 9 } 10 (gdb) l 11 int main(){ 12 int a = 10; 13 int b = get_num(a); 14 } (gdb) l Line number 15 out of range; test.cpp has 14 lines. 运行程序 run(简写 r) ：运行程序直到遇到 结束或者遇到断点等待下一个命令：\n1 2 3 4 5 (gdb) c The program is not being run. (gdb) r Starting program: /data1/workplace/tmp/test [Inferior 1 (process 1044104) exited normally] 设置断点 break(简写 b) ：命令格式 b 行号，在某行设置断点： info breakpoints (简写 i b) ：显示断点信息。\nNum： 断点编号 Type：类型，breakpoint 或者 watchpoint Disp：断点执行一次之后是否有效 kep：有效 dis：无效 Enb： 当前断点是否有效 y：有效 n：无效 Address：内存地址 What：位置 1 2 3 4 5 6 (gdb) b 13 Breakpoint 1 at 0x555555555170: file test.cpp, line 13. (gdb) i b Num Type Disp Enb Address What 1 breakpoint keep y 0x0000555555555170 in main() at test.cpp:13 (gdb) 条件断点：\n1 (gdb) b ... if cond 具体参考：GDB条件断点详解\n单步执行 首先需要输入 run 启动程序，运行到第一个断点处，然后可以选择 step 单步调试（如果有函数调用则进入函数），next 单步跟踪程序（遇到函数调用，直接调用函数，不会进入函数体内），continue 继续运行到下一个断点处。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 (gdb) r Starting program: /data1/workplace/tmp/test Breakpoint 2, main () at test.cpp:12 12 int a = 10; (gdb) s Breakpoint 1, main () at test.cpp:13 13 int b = get_num(a); (gdb) s get_num (x=21845) at test.cpp:6 6 int get_num(int x) { (gdb) s 7 int x_2 = square(x); (gdb) n 8 return x_2; (gdb) l 8 3 return x * x; 4 } 5 6 int get_num(int x) { 7 int x_2 = square(x); 8 return x_2; 9 } 10 11 int main(){ 12 int a = 10; (gdb) 运行程序相关命令如下：\nrun：简记为 r ，其作用是运行程序，当遇到断点后，程序会在断点处停止运行，等待用户输入下一步的命令； continue （简写 c ）：继续执行，到下一个断点处（或运行结束）； next：（简写 n ），单步跟踪程序，当遇到函数调用时，也不进入此函数体；此命令同step 的主要区别是，step 遇到用户自定义的函数，将步进到函数中去运行，而 next 则直接调用函数，不会进入到函数体内。 step：（简写s）：单步调试如果有函数调用，则进入函数；与命令 n 不同，n 是不进入调用的函数的； until：当你厌倦了在一个循环体内单步跟踪时，这个命令可以运行程序直到退出循环体； until 行号： 运行至某行，不仅仅用来跳出循环； finish： 运行程序，直到当前函数完成返回，并打印函数返回时的堆栈地址和返回值及参数值等信息。 call 函数(参数)：调用程序中可见的函数，并传递“参数”，如：call gdb_test(55) 查看变量 print ：简记 p，打印变量或表达式的值； whatis ：查询变量或函数的类型； pt ：跟 whatis 作用类似，可能是 print type 的简写； display：在单步调试的时候很有用，使用 display 命令设置一个表达式后，它将在每次单步进行指令后，紧接着输出被设置的表达式及值； info dispaly，查看当前被设置的变量，然后可以用 undisplay num（变量对应的编号） 取消设置； 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 (gdb) p x $11 = 10 (gdb) whatis x type = int (gdb) whatis square type = int (int) (gdb) pt square type = int (int) (gdb) display x*x + 2 1: x*x + 2 = 102 (gdb) display 1: x*x + 2 = 102 (gdb) info display Auto-display expressions now in effect: Num Enb Expression 1: y x*x + 2 (gdb) 退出 GDB 使用 quit （简记 q ）命令退出即可。\nGDB 常用命令 下面列出最常用的GDB命令：\npt：查看变量的真实类型，不受 typedef 的影响； bt：显示当前调用堆栈； up/down：在函数调用栈里上下移动。或者使用frame 函数帧号跳转； fin：直接运行到函数结束； i b：查看所有的断点信息； delete：删除所有断点； delete breakpoint_list：删除某个序号处断点； i locals：查看当前堆栈页的所有变量； wh：启动“可视化调试”。这个是我最喜欢的命令，可以把屏幕分成上下两个窗口，上面显示源码，下面是 GDB 命令输出，不必再用“l”频繁地列出源码了，能够大大提高调试的效率； ctrl x + a ：退出或进入可视化模式； layout regs：显示源代码/汇编和寄存器窗口； layout split：显示源代码和汇编窗口； p *array@10：查看数组内容，这里10表示查看数组的大小； ptype：查看变量的类型，这里打印出变量的结构定义； set args config.txt：指定运行时的参数； GDB 多线程命令 info thread：查看被调试的线程； thread apply all bt：打印所有线程堆栈信息； thread \u0026lt;ID\u0026gt; ：切换调试的线程为指定ID的线程； break file.c:100 thread all：在file.c文件第100行处为所有经过这里的线程设置断点； set scheduler-locking off|on|step：在调试多线程程序时，默认除了被调试的线程在执行外，其他线程也都在运行，我们可以通过命令来控制这一切：off表示不锁定任何线程on表示只有当前调试的线程会继续运行，step表示在但不执行时只有当前线程会运行； thread apply \u0026lt;ID1\u0026gt; \u0026lt;ID2\u0026gt; \u0026lt;command\u0026gt;：让一个或者多个线程执行GDB命令command； 参考 GDB调试入门指南\ngdb调试多线程程序总结\nGDB学习笔记\n学习使用 GDB 调试代码\nlinux下gdb调试方法与技巧整理\n100个gdb小技巧\n","date":"2022-07-12T16:59:57+08:00","image":"http://localhost:1313/posts/gdb%E8%B0%83%E8%AF%95%E5%AD%A6%E4%B9%A0/gdb_cover_hu_6585bad08c3585f6.gif","permalink":"http://localhost:1313/posts/gdb%E8%B0%83%E8%AF%95%E5%AD%A6%E4%B9%A0/","title":"GDB调试秘籍：像高手一样排查问题"},{"content":"梯度下降法推导 什么是梯度？ 梯度的本意是一个向量（矢量），表示某一函数在该点处的方向导数沿着该方向取得最大值，即函数在该点处沿着该方向（此梯度的方向）变化最快，变化率最大（为该梯度的模）。\n通俗来说，梯度就是表示某一函数在该点处的方向导数沿着该方向取得（模）较大值，即函数在当前位置的导数。笔者理解：在高维空间中参数 $\\boldsymbol{\\theta}$ 和 $f(\\boldsymbol{\\theta})$ 形成超曲面上，当 $\\boldsymbol{\\theta}$ 移动相同的 $\\lVert\\nabla\\boldsymbol{\\theta}\\lVert$ 模值（超距离）时，沿着梯度的方向，可以使得 $f(\\boldsymbol{\\theta})$ 变化量（增加）最大。梯度表示为如下： $$ \\nabla f(\\boldsymbol{\\theta})=\\frac{\\partial f(\\boldsymbol{\\theta})}{\\partial \\boldsymbol{\\theta}} $$ 其中，$\\boldsymbol{\\theta}$为矢量（向量），大小为 $1 \\times n$；$f(\\boldsymbol{\\theta})$为标量，该函数称为目标函数，也叫做损失函数，有时候也用 $L$ 或者 $J$ 表示；$\\nabla f(\\boldsymbol{\\theta})$ 为矢量，大小为 $n \\times 1$。\n如果函数 $f(\\boldsymbol{\\theta})$ 是凸函数，那么就可以使用梯度下降算法进行优化。 $$ \\boldsymbol{\\theta} = \\boldsymbol{\\theta_0} - \\eta \\cdot \\nabla f(\\boldsymbol{\\theta_0}) $$ 其中，$\\boldsymbol{\\theta_0}$ 是自变量参数，代表当前参数位置坐标；$\\eta$ 是学习因子（学习率），用来调整下降时步进长度；$\\boldsymbol{\\theta}$ 是更新后的参数值，即通过一次梯度下降法之后的参数坐标位置。\n推导梯度下降法公式 我们对 $f(\\boldsymbol{\\theta})$ 进行一阶泰勒展开，如下： $$ f(\\boldsymbol{\\theta}) = f\\left(\\boldsymbol{\\theta_{0}}\\right)+\\left(\\boldsymbol{\\theta}-\\boldsymbol{\\theta_{0}}\\right) \\cdot \\nabla f\\left(\\boldsymbol{\\theta_{0}}\\right) + o\\left(\\boldsymbol{\\theta}-\\boldsymbol{\\theta_{0}}\\right) $$ 注意，上面等式当 $f(\\boldsymbol{\\theta})$ 在 $\\boldsymbol{\\theta_{0}}$ 可导时，恒成立；其中，$ o\\left(\\boldsymbol{\\theta}-\\boldsymbol{\\theta_{0}}\\right) $ 为余项（或者称为线性近似误差）。而且，这里只有 $\\left(\\boldsymbol{\\theta}-\\boldsymbol{\\theta_{0}}\\right) \\rightarrow 0$时，$o\\left(\\boldsymbol{\\theta}-\\boldsymbol{\\theta_{0}}\\right)$ 才为无穷小量，此时，可以用前两项近似 $f(\\boldsymbol{\\theta})$ 值，所以如果 $\\left(\\boldsymbol{\\theta}-\\boldsymbol{\\theta_{0}}\\right)$ 太大，误差会比较大。\n那么，当我们使用 $f\\left(\\boldsymbol{\\theta_{0}}\\right)+\\left(\\boldsymbol{\\theta}-\\boldsymbol{\\theta_{0}}\\right) \\cdot \\nabla f\\left(\\boldsymbol{\\theta_{0}}\\right)$ 来近似 $f(\\boldsymbol{\\theta})$时，我们需要计算 $\\nabla f\\left(\\boldsymbol{\\theta_{0}}\\right)$，即为目标函数在当前参数位置 $f(\\boldsymbol{\\theta_{0}})$ 处的梯度。 $$ f(\\boldsymbol{\\theta}) \\approx f\\left(\\boldsymbol{\\theta_{0}}\\right)+\\left(\\boldsymbol{\\theta}-\\boldsymbol{\\theta_{0}}\\right) \\cdot \\nabla f\\left(\\boldsymbol{\\theta_{0}}\\right) $$ 这里，$\\boldsymbol{\\theta}-\\boldsymbol{\\theta_{0}}$ 是一个微小量，我们令 $\\lVert\\boldsymbol{\\theta}-\\boldsymbol{\\theta_{0}}\\lVert$ 为 $\\eta$，$\\eta$ 为标量，令单位向量 $\\frac{\\boldsymbol{\\theta}-\\boldsymbol{\\theta_{0}}}{\\lVert\\boldsymbol{\\theta}-\\boldsymbol{\\theta_{0}}\\rVert}$ 为 $\\boldsymbol{v}$ 表示，则 $$ \\boldsymbol{\\theta}-\\boldsymbol{\\theta_{0}} = \\eta \\boldsymbol{v} $$ 代入到上面的表达式后： $$ f(\\boldsymbol{\\theta}) \\approx f\\left(\\boldsymbol{\\theta_{0}}\\right)+\\eta \\boldsymbol{v} \\cdot \\nabla f\\left(\\boldsymbol{\\theta_{0}}\\right) $$ 此处是重点！！! 局部下降的目的是希望每次 $\\boldsymbol{\\theta}$ 更新，都能让函数值 $f(\\boldsymbol{\\theta})$ 变小。也就是说，希望上式 $f(\\boldsymbol{\\theta})\u0026lt;f\\left(\\boldsymbol{\\theta_{0}}\\right)$。那么，希望下面式子每次更新都可以成立： $$ f(\\boldsymbol{\\theta})-f\\left(\\boldsymbol{\\theta_{0}}\\right) \\approx \\eta \\boldsymbol{v} \\cdot \\nabla f\\left(\\boldsymbol{\\theta_{0}}\\right)\u0026lt;0 $$ 因为 $\\eta$ 为标量，且一般设定为正值，所以可以忽略，不等式等价于： $$ \\boldsymbol{v} \\cdot \\nabla f\\left(\\boldsymbol{\\theta_{0}}\\right)\u0026lt;0 $$ 其中，$\\boldsymbol{v}$ 和 $\\nabla f\\left(\\boldsymbol{\\theta_{0}}\\right)$ 都是向量，$\\nabla f\\left(\\boldsymbol{\\theta_{0}}\\right)$ 是当前位置的梯度，$\\boldsymbol{v}$ 表示下一步前进的单位向量，是需要求解的, 从而就能根据 $\\boldsymbol{\\theta}-\\boldsymbol{\\theta_{0}}=\\eta \\boldsymbol{v}$ 确定 $\\boldsymbol{\\theta}$ 的值了。\n让我们来分析，当 $\\boldsymbol{v}$ 和 $\\nabla f\\left(\\boldsymbol{\\theta_{0}}\\right)$ 互为反向，即 $\\boldsymbol{v}$ 为当前梯度方向的负方向的时候，能让 $\\lvert \\boldsymbol{v} \\cdot \\nabla f\\left(\\boldsymbol{\\theta_{0}}\\right) \\rvert$ 最大，从而使得 $f(\\boldsymbol{\\theta})$ 最大程度地减小，也就保证了 $\\boldsymbol{v}$ 的方向是局部最大程度下降的方向。那么： $$ \\boldsymbol{v}=-\\frac{\\left(\\nabla f\\left(\\boldsymbol{\\theta_{0}}\\right)\\right)^{T}}{\\lVert\\nabla f\\left(\\boldsymbol{\\theta_{0}}\\right)\\lVert} $$ 再根据 $\\boldsymbol{\\theta}-\\boldsymbol{\\theta_{0}} = \\eta \\boldsymbol{v}$ 得到： $$ \\boldsymbol{\\theta} = \\boldsymbol{\\theta_{0}} - \\eta \\frac{\\left(\\nabla f\\left(\\boldsymbol{\\theta_{0}}\\right)\\right)^{T}}{\\lVert\\nabla f\\left(\\boldsymbol{\\theta_{0}}\\right)\\lVert} $$ 一般地，因为 $\\lVert\\nabla f\\left(\\boldsymbol{\\theta_{0}}\\right)\\lVert$ 是标量，可以并入到因子 $\\eta$ 中，即简化为 $$ \\boldsymbol{\\theta} = \\boldsymbol{\\theta_{0}} - \\eta^{\\prime} \\left(\\nabla f\\left(\\boldsymbol{\\theta_{0}}\\right)\\right)^{T} $$ 一般 $\\eta^{\\prime}$ 为学习率，是一个微小常量，通常取0.01，0.001，0.0001等值。\n梯度下降法分析 如果将 $f(\\boldsymbol{\\theta})$ 在 $\\boldsymbol{\\theta_{0}}$ 处进行二阶泰勒展开： $$ f(\\boldsymbol{\\theta}) = f\\left(\\boldsymbol{\\theta_{0}}\\right)+\\left(\\boldsymbol{\\theta}-\\boldsymbol{\\theta_{0}}\\right) \\cdot \\nabla f\\left(\\boldsymbol{\\theta_{0}}\\right) + \\frac{1}{2}\\left(\\boldsymbol{\\theta}-\\boldsymbol{\\theta_{0}}\\right)\\boldsymbol{H}\\left(\\boldsymbol{\\theta}-\\boldsymbol{\\theta_{0}}\\right)^{T} + o\\left(\\boldsymbol{\\theta}-\\boldsymbol{\\theta_{0}}\\right) $$ 其中，$\\boldsymbol{H}$ 为Hessian矩阵，其展开形式为：\n$$ H=\\left(\\begin{array}{cccc} \\frac{\\partial^{2}}{\\partial \\theta_{1} \\partial \\theta_{1}} f(\\boldsymbol{\\theta}) \u0026amp; \\frac{\\partial^{2}}{\\partial \\theta_{1} \\partial \\theta_{2}} f(\\boldsymbol{\\theta}) \u0026amp; \\cdots \u0026amp; \\frac{\\partial^{2}}{\\partial \\theta_{1} \\partial \\theta_{n}} f(\\boldsymbol{\\theta}) \\\\ \\frac{\\partial^{2}}{\\partial \\theta_{2} \\partial \\theta_{1}} f(\\boldsymbol{\\theta}) \u0026amp; \\frac{\\partial^{2}}{\\partial \\theta_{2} \\partial \\theta_{2}} f(\\boldsymbol{\\theta}) \u0026amp; \\cdots \u0026amp; \\frac{\\partial^{2}}{\\partial \\theta_{2} \\partial \\theta_{n}} f(\\boldsymbol{\\theta}) \\\\ \\vdots \u0026amp; \\vdots \u0026amp; \u0026amp; \\vdots \\\\ \\frac{\\partial^{2}}{\\partial \\theta_{n} \\partial \\theta_{1}} f(\\boldsymbol{\\theta}) \u0026amp; \\frac{\\partial^{2}}{\\partial \\theta_{n} \\partial \\theta_{2}} f(\\boldsymbol{\\theta}) \u0026amp; \\cdots \u0026amp; \\frac{\\partial^{2}}{\\partial \\theta_{n} \\partial \\theta_{n}} f(\\boldsymbol{\\theta}) \\end{array}\\right) $$\n我们将梯度下降法的迭代公式 $\\boldsymbol{\\theta} = \\boldsymbol{\\theta_{0}} - \\eta^{\\prime} \\left(\\nabla f\\left(\\boldsymbol{\\theta_{0}}\\right)\\right)^{T}$ 代入到二阶泰勒展开式中，并且忽略二阶余项误差，得到： $$ f(\\boldsymbol{\\theta})-f\\left(\\boldsymbol{\\theta_{0}}\\right) \\approx -\\eta^{\\prime}\\left(\\nabla f\\left(\\boldsymbol{\\theta_{0}}\\right)\\right)^{T} \\nabla f\\left(\\boldsymbol{\\theta_{0}}\\right)+\\frac{1}{2} \\eta^{\\prime2} \\left(\\nabla f\\left(\\boldsymbol{\\theta_{0}}\\right)\\right)^{T} \\boldsymbol{H}\\nabla f\\left(\\boldsymbol{\\theta_{0}}\\right) $$ 上面式子右边是梯度下降法一步迭代后引起目标函数 $f(\\boldsymbol{\\theta})$ 的变化量，每次迭代的变化量其实不一定是负的，使得 $f(\\boldsymbol{\\theta})$ 减小，也可能引起 $f(\\boldsymbol{\\theta})$ 增加。\n原因分析：\n理论分析来讲，当 $\\left(\\boldsymbol{\\theta}-\\boldsymbol{\\theta_{0}}\\right) \\rightarrow 0$时候，即当学习率 $\\eta^{\\prime}$ 足够小时，一阶展开余项 $o\\left(\\boldsymbol{\\theta}-\\boldsymbol{\\theta_{0}}\\right)$ 趋近于0，不会使得上式右边为负，也就可以保证迭代可以成功下降，但是，这样会导致达到极小值需要的迭代次数增加，使得学习过慢，增加计算和时间成本。 如果Hessian矩阵是负定的，可以保证 $\\frac{1}{2} \\eta^{\\prime2} \\nabla f\\left(\\boldsymbol{\\theta_{0}}\\right)^{T} \\boldsymbol{H}\\nabla f\\left(\\boldsymbol{\\theta_{0}}\\right)$ 项为负，那么也可以保证一次梯度下降迭代后，使得目标函数下降，关于Hessian矩阵的理解，可以参考Hessian矩阵和极值判断。 当学习率 $\\eta^{\\prime}$过大时，二阶余项误差变大，二阶泰勒展开的准确性也就不高了，因此可以用启发式寻找合适的学习率。【延伸阅读】 下面对于 $\\frac{1}{2} \\eta^{\\prime2} \\nabla f\\left(\\boldsymbol{\\theta_{0}}\\right)^{T} \\boldsymbol{H}\\nabla f\\left(\\boldsymbol{\\theta_{0}}\\right)$ 为正进行分析讨论。\n如果我们使上面式子右边小于0，即： $$ -\\eta^{\\prime}\\left(\\nabla f\\left(\\boldsymbol{\\theta_{0}}\\right)\\right)^{T} \\nabla f\\left(\\boldsymbol{\\theta_{0}}\\right)+\\frac{1}{2} \\eta^{\\prime2} \\left(\\nabla f\\left(\\boldsymbol{\\theta_{0}}\\right)\\right)^{T} \\boldsymbol{H}\\nabla f\\left(\\boldsymbol{\\theta_{0}}\\right) \u0026lt; 0 $$ 整理 $\\eta^{\\prime}$ 得到： $$ \\eta^{\\prime} \u0026lt; \\frac{\\left(\\nabla f\\left(\\boldsymbol{\\theta_{0}}\\right)\\right)^{T} \\nabla f\\left(\\boldsymbol{\\theta_{0}}\\right)}{\\left(\\nabla f\\left(\\boldsymbol{\\theta_{0}}\\right)\\right)^{T} \\boldsymbol{H} \\nabla f\\left(\\boldsymbol{\\theta_{0}}\\right)} $$ 那么，当学习率满足上面式子时（足够小），总可以梯度下降。不过上面式子也是在泰勒二阶展开下的近似分析。\n下面使用参数只有一维情况下的特例情况下，画图说明上面的情况：\n牛顿迭代法推导 通过上面泰勒展开式分析梯度下降法，我们可以知道梯度下降法仅使用梯度信息进行迭代下降，在大多数情况下效果还可以，并且由于目前神经网络中反向传播算法可以高效求解梯度，所以当前对于神经网络的优化普通采用梯度下降法。关于反向传播算法可以在我的神经网络之反向传播算法文章中了解。\n牛顿法迭代公式 二阶泰勒展开近似公式为： $$ f(\\boldsymbol{\\theta}) \\approx f\\left(\\boldsymbol{\\theta_{0}}\\right)+\\left(\\boldsymbol{\\theta}-\\boldsymbol{\\theta_{0}}\\right) \\cdot \\nabla f\\left(\\boldsymbol{\\theta_{0}}\\right) + \\frac{1}{2}\\left(\\boldsymbol{\\theta}-\\boldsymbol{\\theta_{0}}\\right)\\boldsymbol{H}\\left(\\boldsymbol{\\theta}-\\boldsymbol{\\theta_{0}}\\right)^{T} $$ 我们对式子右边求极值点，则可以得到：\n深度学习中常见的优化器 SGD Adam 参考 梯度下降法的推导\n相信我你没真明白牛顿法与梯度下降法\n优化理论——梯度下降法与牛顿法\n线性代数笔记12：二次型与函数极值\n牛顿法\n应用于最优化的牛顿法\nHessian矩阵和极值判断\n延伸阅读 论文 《A stochastic quasi-Newton method for large-scale optimization 》 《A Linearly-Convergent Stochastic L-BFGS Algorithm》 《A Multi-Batch L-BFGS Method for Machine Learning》 《Fast Exact Multiplication by the Hessian》 疑问 为什么神经网络每一层的学习率一样，应该是前面层学习率小，后面层学习率大。\n","date":"2022-06-23T11:17:44+08:00","image":"http://localhost:1313/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E4%BC%98%E5%8C%96%E6%96%B9%E6%B3%95/method_of_neural_network_optimization_hu_2351f24b646f3cb0.jpg","permalink":"http://localhost:1313/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E4%BC%98%E5%8C%96%E6%96%B9%E6%B3%95/","title":"机器学习中的优化方法"},{"content":"前言 OpenMMLab学习资料：OpenMMLab 模块化设计背后的功臣\n对于mmdetection的学习，可以直接阅读官方的文档，现在官方提供了中文文档，非常详细，点击mmdetection中文文档阅读。\n关于基于mmdetection框架实现Faster R-CNN算法，可以先阅读官方在知乎上发布的文章，轻松掌握 MMDetection 中常用算法(二)：Faster R-CNN|Mask R-CNN，本篇博客是对其进行从源码实现层面进行补充解读。\nmmdetection代码框架 通过下面命令拉取最新的代码\n1 git clone git@github.com:open-mmlab/mmdetection.git 代码仓库主分支为master分支，目前计算机视觉领域中目标检测算法正在快速发展，mmdetection也不断地实现新的算法，最新实现的算法查看CHANGELOG。\n如果觉得master代码更新比较频繁，影响自己基于mmdetection的算法实现，也可以基于最新发布的版本创建自己的分支，如下命令：\n1 git checkout -b newbranch v2.25.0 # 截止2022.06.19发布的最新稳定版 目前还是推荐直接使用master代码，并且要经常 git pull 拉取最新的代码，这样最新的一些组件也会更新，方便基于最新的组件搭建自己的网络算法。\n之前阅读的YOLO v4论文中，作者将目标检测抽象为下面几个部分，mmdetection的代码也是这样抽象的：\n下面代码分析基于mmdetection的源码当前最近commit: ca11860f4f3c3ca2ce8340e2686eeaec05b29111 ，时间 2022.06.20。\n下面是mmdetection代码框架的结构：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 . ├── CITATION.cff ├── LICENSE ├── MANIFEST.in ├── README.md ├── README_zh-CN.md ├── andy_README.md ├── configs # 存放所有的配置文件，可以自己写配置文件，也可以继承自_base_下的四种配置文件 ├── demo ├── docker ├── docs ├── mmdet # mmdeteetion的核心代码部分，其他工具都依赖于该部分的代码 ├── model-index.yml ├── pytest.ini ├── requirements ├── requirements.txt ├── resources ├── setup.cfg ├── setup.py ├── tests # 集成测试相关代码 └── tools # 提供训练、测试等工具代码 以下是configs目录下的配置文件说明：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 configs ├── _base_ │ ├── datasets # 数据集加载，不同的数据集格式获取数据代码。 │ ├── default_runtime.py # 默认的运行时配置文件，主要配置包括权重保存频率、日志频率，日志等级等信息。 │ ├── models # 不同的目标检测模型配置文件 │ └── schedules # 各种训练策略配置文件 ├── albu_example # ...其他目录文件：1）继承自上面的四种文件，并做一些针对性修改；2）可以自己写配置文件，配置所有参数。 │ ├── README.md │ └── mask_rcnn_r50_fpn_albu_1x_coco.py ├── atss │ ├── README.md │ ├── atss_r101_fpn_1x_coco.py │ ├── atss_r50_fpn_1x_coco.py │ └── metafile.yml ├── autoassign 以下是mmdet（核心代码）目录下的代码说明：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 mmdet ├── __init__.py # 判断配置的mmcv是否符合要求 ├── apis # 训练和测试相关依赖的函数，有随机种子生成、训练、单GPU测试、多GPU测试等 │ ├── __init__.py │ ├── inference.py │ ├── test.py │ └── train.py ├── core # 内核代码，包括锚框生成、边界框计算、结果评估、数据结构、掩码生成、可视化、钩子函数等等核心代码 │ ├── __init__.py │ ├── anchor │ ├── bbox │ ├── data_structures │ ├── evaluation │ ├── export │ ├── hook │ ├── mask │ ├── optimizers │ ├── post_processing │ ├── utils │ └── visualization ├── datasets # 数据加载器的具体实现，对应configs/datasets │ ├── __init__.py │ ├── api_wrappers │ ├── builder.py │ ├── cityscapes.py │ ├── coco.py │ ├── coco_panoptic.py │ ├── custom.py │ ├── dataset_wrappers.py │ ├── deepfashion.py │ ├── lvis.py │ ├── openimages.py │ ├── pipelines │ ├── samplers │ ├── utils.py │ ├── voc.py │ ├── wider_face.py │ └── xml_style.py ├── models # 不同模型的具体实现，分为不同的主干、颈部、头部、损失函数等等，对应 configs/models │ ├── __init__.py │ ├── backbones │ ├── builder.py │ ├── dense_heads │ ├── detectors │ ├── losses │ ├── necks │ ├── plugins │ ├── roi_heads │ ├── seg_heads │ └── utils ├── utils # 通用工具 │ ├── __init__.py │ ├── collect_env.py │ ├── compat_config.py │ ├── contextmanagers.py │ ├── logger.py │ ├── memory.py │ ├── misc.py │ ├── profiling.py │ ├── replace_cfg_vals.py │ ├── setup_env.py │ ├── split_batch.py │ ├── util_distribution.py │ ├── util_mixins.py │ └── util_random.py └── version.py # 记录mmdetection 的版本 以下是tools目录下的代码说明：\n1 2 3 4 5 6 7 8 9 10 11 12 tools ├── analysis_tools # 分析日志和预测效果 ├── dataset_converters # 数据集转换 ├── deployment # 部署工具 ├── dist_test.sh ├── dist_train.sh ├── misc # 杂项，下载数据集、打印配置信息等工具 ├── model_converters ├── slurm_test.sh ├── slurm_train.sh ├── test.py # 测试模型 └── train.py # 根据配置文件进行训练 Faster R-CNN 模型训练 1 2 3 4 5 6 7 8 9 10 11 12 13 14 data └── VOCdevkit ├── VOC2007 │ ├── Annotations │ ├── ImageSets │ ├── JPEGImages │ ├── SegmentationClass │ └── SegmentationObject └── VOC2012 ├── Annotations ├── ImageSets ├── JPEGImages ├── SegmentationClass └── SegmentationObject 根据官方文档，配置相关环境，下载VOC数据集（这里选择相对较小的VOC数据进行训练），并且组织好数据集目录结构，如上所示，然后就可以使用下面命令进行训练：\n1 python tools/train.py configs/pascal_voc/faster_rcnn_r50_fpn_1x_voc0712.py 笔者训练得到的结果是：mAP 78.8，该结果和官方给的代码结果差将近两个点，可能是训练时候的参数设置不一样导致的。\nFaster R-CNN 模型测试 使用下面命令进行测试：\n1 python tools/test.py configs/pascal_voc/faster_rcnn_r50_fpn_1x_voc0712.py checkpoints/faster_rcnn_r50_fpn_1x_voc0712_20220320_192712-54bef0f3.pth --eval mAP 这里的checkpoints目录下的模型文件是我下载mmdetection训练好的模型文件，可以替换成自己训练好的文件，进行测试。\nFaster R-CNN 配置文件解读 上面训练和测试使用的模型配置文件都是configs/pascal_voc/faster_rcnn_r50_fpn_1x_voc0712.py，内容如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 _base_ = [ \u0026#39;../_base_/models/faster_rcnn_r50_fpn.py\u0026#39;, \u0026#39;../_base_/datasets/voc0712.py\u0026#39;, \u0026#39;../_base_/default_runtime.py\u0026#39; ] model = dict(roi_head=dict(bbox_head=dict(num_classes=20))) # 修改类别个数 # optimizer optimizer = dict(type=\u0026#39;SGD\u0026#39;, lr=0.01, momentum=0.9, weight_decay=0.0001) optimizer_config = dict(grad_clip=None) # 不进行梯度截断 # learning policy # actual epoch = 3 * 3 = 9 lr_config = dict(policy=\u0026#39;step\u0026#39;, step=[3]) # runtime settings runner = dict( type=\u0026#39;EpochBasedRunner\u0026#39;, max_epochs=4) # actual epoch = 4 * 3 = 12 可以看到上面的配置文件，继承自三个配置文件，下面解读configs/_base_/models/faster_rcnn_r50_fpn.py模型配置文件，内容如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 # model settings model = dict( type=\u0026#39;FasterRCNN\u0026#39;, backbone=dict( type=\u0026#39;ResNet\u0026#39;, # 骨架网络类名 depth=50, # 表示使用 ResNet50 num_stages=4, # ResNet 系列包括 stem + 4个 stage 输出 # 表示本模块输出的特征图索引，(0, 1, 2, 3),表示4个 stage 输出都需要， # 其 stride 为 (4,8,16,32)，channel 为 (256, 512, 1024, 2048) out_indices=(0, 1, 2, 3), frozen_stages=1, # 表示固定 stem 加上第一个 stage 的权重，不进行训练 norm_cfg=dict(type=\u0026#39;BN\u0026#39;, requires_grad=True), # BN 层 norm_eval=True, # backbone 所有的 BN 层的均值和方差都直接采用全局预训练值，不进行更新 style=\u0026#39;pytorch\u0026#39;, # 默认采用 pytorch 模式 init_cfg=dict(type=\u0026#39;Pretrained\u0026#39;, checkpoint=\u0026#39;torchvision://resnet50\u0026#39;)), neck=dict( type=\u0026#39;FPN\u0026#39;, in_channels=[256, 512, 1024, 2048], # ResNet 模块输出的4个尺度特征图通道数 out_channels=256, # FPN 输出的每个尺度输出特征图通道 num_outs=5), # FPN 输出特征图个数，将最高层特征图再进行一个pooling操作，产生更高层特征图 rpn_head=dict( type=\u0026#39;RPNHead\u0026#39;, in_channels=256, # FPN 层输出特征图通道数 feat_channels=256, # 中间特征图通道数 anchor_generator=dict( type=\u0026#39;AnchorGenerator\u0026#39;, # 相当于 octave_base_scale，表示每个特征图的 base scales ??? # FPN 已经有多尺度操作，所以这里尺度只有一个8x8 scales=[8], # 然后通过控制不同的长宽比去产生不同比列的提议框 ratios=[0.5, 1.0, 2.0], # 每个特征图有 3 个高宽比例 strides=[4, 8, 16, 32, 64]), # 特征图对应的 stride，必须和特征图 stride 一致，不可以随意更改 ??? bbox_coder=dict( # 常用！ 对边界框回归的目标值进行一个编码 type=\u0026#39;DeltaXYWHBBoxCoder\u0026#39;, target_means=[.0, .0, .0, .0], target_stds=[1.0, 1.0, 1.0, 1.0]), loss_cls=dict( type=\u0026#39;CrossEntropyLoss\u0026#39;, use_sigmoid=True, loss_weight=1.0), loss_bbox=dict(type=\u0026#39;L1Loss\u0026#39;, loss_weight=1.0)), roi_head=dict( # roi_head会基于rpn_head产生的提议框，以及原图的特征图进行预测 type=\u0026#39;StandardRoIHead\u0026#39;, bbox_roi_extractor=dict( # 把提议框区域内的特征图从全图特征图中裁剪下来 type=\u0026#39;SingleRoIExtractor\u0026#39;, roi_layer=dict(type=\u0026#39;RoIAlign\u0026#39;, output_size=7, sampling_ratio=0), out_channels=256, featmap_strides=[4, 8, 16, 32]), bbox_head=dict( # 使用上面裁剪下来的特征送入 type=\u0026#39;Shared2FCBBoxHead\u0026#39;, # 2 个共享 FC 模块 in_channels=256, # 输入通道数，相等于 FPN 输出通道 fc_out_channels=1024, # 中间 FC 层节点个数 roi_feat_size=7, # RoIAlign 或 RoIPool 输出的特征图大小 num_classes=80, # 类别个数 bbox_coder=dict( # bbox 编解码策略？？？，除了参数外和 RPN 相同 type=\u0026#39;DeltaXYWHBBoxCoder\u0026#39;, target_means=[0., 0., 0., 0.], target_stds=[0.1, 0.1, 0.2, 0.2]), # 影响 bbox 分支的通道数，True 表示 4 通道输出，False 表示 4×num_classes 通道输出 reg_class_agnostic=False, loss_cls=dict( # 80类分类问题，没有使用sigmoid激活函数 type=\u0026#39;CrossEntropyLoss\u0026#39;, use_sigmoid=False, loss_weight=1.0), loss_bbox=dict(type=\u0026#39;L1Loss\u0026#39;, loss_weight=1.0))), # model training and testing settings train_cfg=dict( rpn=dict( assigner=dict( type=\u0026#39;MaxIoUAssigner\u0026#39;, # 最大 IoU 原则分配器 pos_iou_thr=0.7, # 正样本阈值 neg_iou_thr=0.3, # 负样本阈值 min_pos_iou=0.3, # 正样本阈值下限 ??? match_low_quality=True, ignore_iof_thr=-1), # 忽略 bboxes 的阈值，-1 表示不忽略 sampler=dict( type=\u0026#39;RandomSampler\u0026#39;, # 随机采样 num=256, # 产生1000个框，只采样256个进行训练，采样后每张图片的训练样本总数，不包括忽略样本 pos_fraction=0.5, # 正样本比例 neg_pos_ub=-1, # 正负样本比例，用于确定负样本采样个数上界 add_gt_as_proposals=False), # 是否加入 gt 作为 proposals 以增加高质量正样本数 allowed_border=-1, pos_weight=-1, debug=False), rpn_proposal=dict( nms_pre=2000, # nms之前 max_per_img=1000, # nms之后 nms=dict(type=\u0026#39;nms\u0026#39;, iou_threshold=0.7), min_bbox_size=0), rcnn=dict( assigner=dict( type=\u0026#39;MaxIoUAssigner\u0026#39;, pos_iou_thr=0.5, neg_iou_thr=0.5, min_pos_iou=0.5, match_low_quality=False, ignore_iof_thr=-1), sampler=dict( type=\u0026#39;RandomSampler\u0026#39;, num=512, pos_fraction=0.25, neg_pos_ub=-1, add_gt_as_proposals=True), pos_weight=-1, debug=False)), test_cfg=dict( rpn=dict( nms_pre=1000, max_per_img=1000, nms=dict(type=\u0026#39;nms\u0026#39;, iou_threshold=0.7), min_bbox_size=0), rcnn=dict( score_thr=0.05, nms=dict(type=\u0026#39;nms\u0026#39;, iou_threshold=0.5), max_per_img=100) # soft-nms is also supported for rcnn testing # e.g., nms=dict(type=\u0026#39;soft_nms\u0026#39;, iou_threshold=0.5, min_score=0.05) )) 下面对configs/_base_/datasets/voc0712.py数据集配置文件进行解读，其内容如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 _base_ = [ \u0026#39;../_base_/models/faster_rcnn_r50_fpn.py\u0026#39;, \u0026#39;../_base_/datasets/voc0712.py\u0026#39;, \u0026#39;../_base_/default_runtime.py\u0026#39; ] model = dict(roi_head=dict(bbox_head=dict(num_classes=20))) # 修改类别个数 data = dict( samples_per_gpu=8, # 修改GPU的batch_size，注意不能让其超过显存 workers_per_gpu=8, # 修改GPU的workers ) # optimizer optimizer = dict(type=\u0026#39;SGD\u0026#39;, lr=0.01, momentum=0.9, weight_decay=0.0001) optimizer_config = dict(grad_clip=None) # 不进行梯度截断 # learning policy # 有误 actual epoch = 3 * 3 = 9 lr_config = dict(policy=\u0026#39;step\u0026#39;, step=[8, 11]) # runtime settings runner = dict( type=\u0026#39;EpochBasedRunner\u0026#39;, max_epochs=12) # 有误 actual epoch = 4 * 3 = 12 笔者在源码基础上做了一些修改，将samples_per_gpu修改为8，workers_per_gpu修改为8，lr_config修改为dict(policy='step', step=[8, 11])，runner修改为dict(type='EpochBasedRunner', max_epochs=12)，注意实际训练时候batch_size为samples_per_gpu x gpus，我这里训练时候只用了一个GPU，所以batch_size为 8。\n训练代码解读 首先从tools里面的train.py入手，官方源码文件train.py。\n该python文件中main函数其实就做了四件事，这也是训练神经网络通用的步骤：\n设定和读取各种配置； 创建模型； 创建数据集； 将模型，数据集和配置传进训练函数，进行训练； 下面截取tools/train.py中main函数的代码片段进行解读，其内容如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 def main(): # 第一件事 args = parse_args() cfg = Config.fromfile(args.config) ... # 省略部分代码，该部分代码对训练时上下文进行设置和校验 # 第二件事　创建模型 # 第一个参数cfg.model # 模型配置里面必须要有一个种类type，包括经典的算法如Faster RCNN, MaskRCNN等 # 其次，还包含几个部分，如backbone, neck, head # backbone有深度，stage等信息，如resnet50对应着3,4,6,3四个重复stages # neck一般FPN(feature pyramid network)，需要指定num_outs几个输出之类的信息（之后会看到） # head 就是具体到上层rpn_head,　shared_head，　bbox_head之类的 model = build_detector( cfg.model, train_cfg=cfg.train_cfg, test_cfg=cfg.test_cfg) model.init_weights() # 初始化模型参数 # 第三件事 datasets = [build_dataset(cfg.data.train)] if len(cfg.workflow) == 2: #是否添加验证集 val_dataset = copy.deepcopy(cfg.data.val) val_dataset.pipeline = cfg.data.train.pipeline datasets.append(build_dataset(val_dataset)) if cfg.checkpoint_config is not None: # save mmdet version, config file content and class names in # checkpoints as meta data cfg.checkpoint_config.meta = dict( mmdet_version=__version__ + get_git_hash()[:7], CLASSES=datasets[0].CLASSES) # add an attribute for visualization convenience model.CLASSES = datasets[0].CLASSES # 第四件事 train_detector( model, datasets, cfg, distributed=distributed, validate=args.validate, logger=logger) 让我们继续阅读build_detector函数的代码片段，其内容如下，该代码在mmdect/models/builder.py中：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 # Copyright (c) OpenMMLab. All rights reserved. import warnings from mmcv.cnn import MODELS as MMCV_MODELS # mmdet中MODELS继承自该MMCV_MODELS from mmcv.utils import Registry MODELS = Registry(\u0026#39;models\u0026#39;, parent=MMCV_MODELS) BACKBONES = MODELS NECKS = MODELS ROI_EXTRACTORS = MODELS SHARED_HEADS = MODELS HEADS = MODELS LOSSES = MODELS DETECTORS = MODELS ... # 省略部分代码 def build_detector(cfg, train_cfg=None, test_cfg=None): \u0026#34;\u0026#34;\u0026#34;Build detector.\u0026#34;\u0026#34;\u0026#34; if train_cfg is not None or test_cfg is not None: warnings.warn( \u0026#39;train_cfg and test_cfg is deprecated, \u0026#39; \u0026#39;please specify them in model\u0026#39;, UserWarning) assert cfg.get(\u0026#39;train_cfg\u0026#39;) is None or train_cfg is None, \\ \u0026#39;train_cfg specified in both outer field and model field \u0026#39; assert cfg.get(\u0026#39;test_cfg\u0026#39;) is None or test_cfg is None, \\ \u0026#39;test_cfg specified in both outer field and model field \u0026#39; return DETECTORS.build( cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg)) 这里采用了Registry方式，即在mmdet/models/builder.py中实例化了一个Registry对象，该对象的父类是MMCV_MODELS，该类是mmcv中的一个类，其作用是用来管理多个模型，其中有一个build函数，该函数的作用是根据模型的配置信息，创建模型，并返回模型对象。\n下面代码来自mmcv，版本为1.5.2。\n从上面代码可以看到，mmdet中创建模型的函数build_model_from_cfg继承自mmcv/cnn/builder.py中的build_model_from_cfg函数，其内容如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 # Copyright (c) OpenMMLab. All rights reserved. from ..runner import Sequential from ..utils import Registry, build_from_cfg def build_model_from_cfg(cfg, registry, default_args=None): \u0026#34;\u0026#34;\u0026#34;Build a PyTorch model from config dict(s). Different from ``build_from_cfg``, if cfg is a list, a ``nn.Sequential`` will be built. Args: cfg (dict, list[dict]): The config of modules, is is either a config dict or a list of config dicts. If cfg is a list, a the built modules will be wrapped with ``nn.Sequential``. registry (:obj:`Registry`): A registry the module belongs to. default_args (dict, optional): Default arguments to build the module. Defaults to None. Returns: nn.Module: A built nn module. \u0026#34;\u0026#34;\u0026#34; if isinstance(cfg, list): modules = [ build_from_cfg(cfg_, registry, default_args) for cfg_ in cfg ] return Sequential(*modules) else: return build_from_cfg(cfg, registry, default_args) MODELS = Registry(\u0026#39;model\u0026#39;, build_func=build_model_from_cfg) 下面我们在mmcv/utils/registry.py中查看build_from_cfg代码，如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 def build_from_cfg(cfg, registry, default_args=None): \u0026#34;\u0026#34;\u0026#34;Build a module from config dict when it is a class configuration, or call a function from config dict when it is a function configuration. Example: \u0026gt;\u0026gt;\u0026gt; MODELS = Registry(\u0026#39;models\u0026#39;) \u0026gt;\u0026gt;\u0026gt; @MODELS.register_module() \u0026gt;\u0026gt;\u0026gt; class ResNet: \u0026gt;\u0026gt;\u0026gt; pass \u0026gt;\u0026gt;\u0026gt; resnet = build_from_cfg(dict(type=\u0026#39;Resnet\u0026#39;), MODELS) \u0026gt;\u0026gt;\u0026gt; # Returns an instantiated object \u0026gt;\u0026gt;\u0026gt; @MODELS.register_module() \u0026gt;\u0026gt;\u0026gt; def resnet50(): \u0026gt;\u0026gt;\u0026gt; pass \u0026gt;\u0026gt;\u0026gt; resnet = build_from_cfg(dict(type=\u0026#39;resnet50\u0026#39;), MODELS) \u0026gt;\u0026gt;\u0026gt; # Return a result of the calling function Args: cfg (dict): Config dict. It should at least contain the key \u0026#34;type\u0026#34;. registry (:obj:`Registry`): The registry to search the type from. default_args (dict, optional): Default initialization arguments. Returns: object: The constructed object. \u0026#34;\u0026#34;\u0026#34; if not isinstance(cfg, dict): raise TypeError(f\u0026#39;cfg must be a dict, but got {type(cfg)}\u0026#39;) if \u0026#39;type\u0026#39; not in cfg: # type必须在配置文件里 if default_args is None or \u0026#39;type\u0026#39; not in default_args: raise KeyError( \u0026#39;`cfg` or `default_args` must contain the key \u0026#34;type\u0026#34;, \u0026#39; f\u0026#39;but got {cfg}\\n{default_args}\u0026#39;) if not isinstance(registry, Registry): raise TypeError(\u0026#39;registry must be an mmcv.Registry object, \u0026#39; f\u0026#39;but got {type(registry)}\u0026#39;) if not (isinstance(default_args, dict) or default_args is None): raise TypeError(\u0026#39;default_args must be a dict or None, \u0026#39; f\u0026#39;but got {type(default_args)}\u0026#39;) args = cfg.copy() if default_args is not None: for name, value in default_args.items(): args.setdefault(name, value) obj_type = args.pop(\u0026#39;type\u0026#39;) # 取出type的值 if isinstance(obj_type, str): obj_cls = registry.get(obj_type) #　从注册器里面取出type，注册过才能用 if obj_cls is None: raise KeyError( f\u0026#39;{obj_type} is not in the {registry.name} registry\u0026#39;) elif inspect.isclass(obj_type) or inspect.isfunction(obj_type): obj_cls = obj_type else: raise TypeError( f\u0026#39;type must be a str or valid type, but got {type(obj_type)}\u0026#39;) try: # 根据配置参数实例化模型，就是type定义的那个类（FasterRCNN）的实例化，返回了这个类的对象。 # 后面会再分析具体模型类（FasterRCNN）的定义。 return obj_cls(**args) except Exception as e: # Normal TypeError does not print class name. raise type(e)(f\u0026#39;{obj_cls.__name__}: {e}\u0026#39;) mmcv源码查看，到此为止。\n本篇博客分析Faster R-CNN，该算法在mmdet中模型注册type为FasterRCNN，我们找到该类的实现，位置为mmdet/models/detectors/faster_rcnn.py，如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 @DETECTORS.register_module() class FasterRCNN(TwoStageDetector): \u0026#34;\u0026#34;\u0026#34;Implementation of `Faster R-CNN \u0026lt;https://arxiv.org/abs/1506.01497\u0026gt;`_\u0026#34;\u0026#34;\u0026#34; def __init__(self, backbone, rpn_head, roi_head, train_cfg, test_cfg, neck=None, pretrained=None, init_cfg=None): super(FasterRCNN, self).__init__( backbone=backbone, neck=neck, rpn_head=rpn_head, roi_head=roi_head, train_cfg=train_cfg, test_cfg=test_cfg, pretrained=pretrained, init_cfg=init_cfg) 那么核心功能肯定都在TwoStageDetector里了。看代码之前首先回顾一下一个经典的双阶段检测Faster R-CNN的流程。\n下面我们来分析下/mmdet/models/detectors/two_stage.py文件，如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 @DETECTORS.register_module() class TwoStageDetector(BaseDetector): \u0026#34;\u0026#34;\u0026#34;Base class for two-stage detectors. Two-stage detectors typically consisting of a region proposal network and a task-specific regression head. \u0026#34;\u0026#34;\u0026#34; def __init__(self, backbone, neck=None, rpn_head=None, roi_head=None, train_cfg=None, test_cfg=None, pretrained=None, init_cfg=None): super(TwoStageDetector, self).__init__(init_cfg) if pretrained: warnings.warn(\u0026#39;DeprecationWarning: pretrained is deprecated, \u0026#39; \u0026#39;please use \u0026#34;init_cfg\u0026#34; instead\u0026#39;) backbone.pretrained = pretrained self.backbone = build_backbone(backbone) if neck is not None: self.neck = build_neck(neck) if rpn_head is not None: rpn_train_cfg = train_cfg.rpn if train_cfg is not None else None rpn_head_ = rpn_head.copy() rpn_head_.update(train_cfg=rpn_train_cfg, test_cfg=test_cfg.rpn) self.rpn_head = build_head(rpn_head_) if roi_head is not None: # update train and test cfg here for now # TODO: refactor assigner \u0026amp; sampler rcnn_train_cfg = train_cfg.rcnn if train_cfg is not None else None roi_head.update(train_cfg=rcnn_train_cfg) roi_head.update(test_cfg=test_cfg.rcnn) roi_head.pretrained = pretrained self.roi_head = build_head(roi_head) self.train_cfg = train_cfg self.test_cfg = test_cfg @property def with_rpn(self): \u0026#34;\u0026#34;\u0026#34;bool: whether the detector has RPN\u0026#34;\u0026#34;\u0026#34; return hasattr(self, \u0026#39;rpn_head\u0026#39;) and self.rpn_head is not None @property def with_roi_head(self): \u0026#34;\u0026#34;\u0026#34;bool: whether the detector has a RoI head\u0026#34;\u0026#34;\u0026#34; return hasattr(self, \u0026#39;roi_head\u0026#39;) and self.roi_head is not None def extract_feat(self, img): \u0026#34;\u0026#34;\u0026#34;Directly extract features from the backbone+neck.\u0026#34;\u0026#34;\u0026#34; x = self.backbone(img) if self.with_neck: x = self.neck(x) return x def forward_dummy(self, img): \u0026#34;\u0026#34;\u0026#34;Used for computing network flops. See `mmdetection/tools/analysis_tools/get_flops.py` \u0026#34;\u0026#34;\u0026#34; outs = () # backbone x = self.extract_feat(img) # rpn if self.with_rpn: rpn_outs = self.rpn_head(x) outs = outs + (rpn_outs, ) proposals = torch.randn(1000, 4).to(img.device) # roi_head roi_outs = self.roi_head.forward_dummy(x, proposals) outs = outs + (roi_outs, ) return outs def forward_train(self, img, img_metas, gt_bboxes, gt_labels, gt_bboxes_ignore=None, gt_masks=None, proposals=None, **kwargs): \u0026#34;\u0026#34;\u0026#34; Args: img (Tensor): of shape (N, C, H, W) encoding input images. Typically these should be mean centered and std scaled. img_metas (list[dict]): list of image info dict where each dict has: \u0026#39;img_shape\u0026#39;, \u0026#39;scale_factor\u0026#39;, \u0026#39;flip\u0026#39;, and may also contain \u0026#39;filename\u0026#39;, \u0026#39;ori_shape\u0026#39;, \u0026#39;pad_shape\u0026#39;, and \u0026#39;img_norm_cfg\u0026#39;. For details on the values of these keys see `mmdet/datasets/pipelines/formatting.py:Collect`. gt_bboxes (list[Tensor]): Ground truth bboxes for each image with shape (num_gts, 4) in [tl_x, tl_y, br_x, br_y] format. gt_labels (list[Tensor]): class indices corresponding to each box gt_bboxes_ignore (None | list[Tensor]): specify which bounding boxes can be ignored when computing the loss. gt_masks (None | Tensor) : true segmentation masks for each box used if the architecture supports a segmentation task. proposals : override rpn proposals with custom proposals. Use when `with_rpn` is False. Returns: dict[str, Tensor]: a dictionary of loss components \u0026#34;\u0026#34;\u0026#34; x = self.extract_feat(img) losses = dict() # RPN forward and loss if self.with_rpn: proposal_cfg = self.train_cfg.get(\u0026#39;rpn_proposal\u0026#39;, self.test_cfg.rpn) rpn_losses, proposal_list = self.rpn_head.forward_train( x, img_metas, gt_bboxes, gt_labels=None, gt_bboxes_ignore=gt_bboxes_ignore, proposal_cfg=proposal_cfg, **kwargs) losses.update(rpn_losses) else: proposal_list = proposals roi_losses = self.roi_head.forward_train(x, img_metas, proposal_list, gt_bboxes, gt_labels, gt_bboxes_ignore, gt_masks, **kwargs) losses.update(roi_losses) return losses ... # 省略部分代码 关于上面代码，我画了一个示意图，可以方便理解两阶段检测的架构。 可以看到 TwoStageDetector 类的 forward_train 函数比较简单，最难的部分为两个 head ，分别为 RPNHead 和 StandardRoIHead，下面先分析 RPNHead。\n该代码位于mmdet/models/dense_heads/rpn_head.py。\n参考文章 入门mmdetection（壹）\n","date":"2022-06-18T17:14:15+08:00","image":"http://localhost:1313/posts/%E5%9F%BA%E4%BA%8Emmdetection%E6%BA%90%E7%A0%81faster-r-cnn%E7%AE%97%E6%B3%95%E8%A7%A3%E8%AF%BB/Snipaste_2022-06-21_21-12-31_hu_62c45d451c83e919.jpg","permalink":"http://localhost:1313/posts/%E5%9F%BA%E4%BA%8Emmdetection%E6%BA%90%E7%A0%81faster-r-cnn%E7%AE%97%E6%B3%95%E8%A7%A3%E8%AF%BB/","title":"基于mmdetection源码:Faster R-CNN算法解读"},{"content":" 人生亦有命，安能行叹复坐愁？ —— 拟行路难·其四\n目前只做字节跳动、腾讯的算法和后端的高频leetcode算法题。刷题之前先复习经典的一些算法，有相当多算法是经典算法的修改版。\n汇总地址：\n高频leetcode题🔥\n数据结构与算法🔥\n符号定义及含义 当输入规模足够大，使得运行时间只与增长量级有关时，需要研究算法的渐近效率。也就是，当输入规模无限增加时，在极限中，算法的运行时间如何随着输入规模的变大而增加。这里仅引入两个常用的渐进记号。\n$\\Theta$ (西塔) 渐近紧确界，如$\\frac{1}{2} n^{2}-3 n=\\Theta\\left(n^{2}\\right)$，$6n^{3} \\neq \\Theta (n^{2})$，$n \\neq \\Theta (n^{2})$。 $O$（大o）渐进上界，如 $\\frac{1}{2} n^{2}-3 n=O\\left(n^{2}\\right)$，$6n^{3} \\neq O(n^{2})$，$n = O (n^{2})$。 渐进记号代表的是集合，这里的$=$更多地代表$\\in$。 算法复杂度分为时间复杂度和空间复杂度。时间复杂度衡量了执行算法所需要的计算工作量；而空间复杂度是指执行这个算法所需要的内存空间。 在相当多文献资料中，有时我们发现$O$记号非形式化地描述渐进确界，即已经使用$\\Theta$记号定义的东西。 经典算法 经典排序算法 快速排序 python语言版本\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 def Quick_Sort(L, start, end): if start \u0026lt; end: i, j = start, end base = L[i] while i \u0026lt; j: while(i \u0026lt; j) and (L[j] \u0026gt;= base): j -= 1 L[i] = L[j] while(i \u0026lt; j) and (L[i] \u0026lt;= base): i += 1 L[j] = L[i] L[i] = base Quick_Sort(L, start, i - 1) Quick_Sort(L, j + 1, end) return L C++ 语言版本\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 #include \u0026lt;iostream\u0026gt; #include \u0026lt;vector\u0026gt; #include \u0026lt;cassert\u0026gt; using namespace std; void quick_sort(vector\u0026lt;int\u0026gt; \u0026amp;v, int start, int end) { if (start \u0026lt; end) { int i = start; int j = end; int base = v[i]; while (i \u0026lt; j) { while (i \u0026lt; j \u0026amp;\u0026amp; v[j] \u0026gt;= base) j--; v[i] = v[j]; while (i \u0026lt; j \u0026amp;\u0026amp; v[i] \u0026lt;= base) i++; v[j] = v[i]; } assert(i == j); v[i] = base; quick_sort(v, start, i - 1); quick_sort(v, i + 1, end); } } 例题1： 数组中的第K个最大元素（力扣215）（字节-算法-频次6） 给定整数数组 nums 和整数 k，请返回数组中第 k 个最大的元素。\n请注意，你需要找的是数组排序后的第 k 个最大的元素，而不是第 k 个不同的元素。如，输入: [3,2,1,5,6,4] 和 k = 2，输出: 5\npython代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 class Solution: def findKthLargest(self, nums: List[int], k: int) -\u0026gt; int: if len(nums) == 1: return nums[0] left = 0 right = len(nums) - 1 # 还是默认从小到大排列吧 while left \u0026lt;= right: # 必须要等号!! base = nums[left] i = left j = right while i \u0026lt; j: while i \u0026lt; j and nums[j] \u0026gt;= base: j -= 1 nums[i] = nums[j] while i \u0026lt; j and nums[i] \u0026lt;= base: i += 1 nums[j] = nums[i] nums[i] = base if k == len(nums) - i: return nums[i] elif k \u0026gt; len(nums) - i: # k = k - (len(nums) - i) 不要这行! 不用改变k right = i - 1 else: # k不变 left = i + 1 参考：快速排序-Python 实现\n归并排序 python 语言版本\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 def mergesort(L): \u0026#34;\u0026#34;\u0026#34;归并排序\u0026#34;\u0026#34;\u0026#34; if len(L) \u0026lt;= 1: return L mid = len(L) // 2 # 将列表分成更小的两个列表 # 分别对左右两个列表进行处理，分别返回两个排序好的列表 left_L = mergesort(L[:mid]) right_L = mergesort(L[mid:]) # 对排序好的两个列表合并，产生一个新的排序好的列表 return merge(left_L, right_L) def merge(left_L, right_L): \u0026#34;\u0026#34;\u0026#34;合并两个已排序好的列表，产生一个新的已排序好的列表\u0026#34;\u0026#34;\u0026#34; result = [] # 新的已排序好的列表 i = 0 # 下标 j = 0 # 对两个列表中的元素 两两对比。 # 将最小的元素，放到result中，并对当前列表下标加1 while i \u0026lt; len(left_L) and j \u0026lt; len(right_L): if left_L[i] \u0026lt;= right_L[j]: result.append(left_L[i]) i += 1 else: result.append(right_L[j]) j += 1 result += left_L[i:] result += right_L[j:] return result C++ 语言版本\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 #include \u0026lt;iostream\u0026gt; #include \u0026lt;vector\u0026gt; using namespace std; void merge(vector\u0026lt;int\u0026gt;::iterator begin, vector\u0026lt;int\u0026gt;::iterator mid, vector\u0026lt;int\u0026gt;::iterator end, vector\u0026lt;int\u0026gt; \u0026amp;tmp_array) { int idx = 0; auto l = begin, m = mid, r = end; while (l \u0026lt; mid \u0026amp;\u0026amp; m \u0026lt; end) { if (*l \u0026lt; *m) { tmp_array[idx++] = *l; ++l; } else { tmp_array[idx++] = *m; ++m; } } while (l \u0026lt; mid) { tmp_array[idx++] = *l; ++l; } while (m \u0026lt; end) { tmp_array[idx++] = *m; ++m; } // 拷贝 // assert() for (int i = 0; i \u0026lt; idx; ++i) { *(begin + i) = tmp_array[i]; } } void do_merge_sort(vector\u0026lt;int\u0026gt;::iterator begin, vector\u0026lt;int\u0026gt;::iterator end, vector\u0026lt;int\u0026gt; \u0026amp;tmp_array) { int length = end - begin; if (length \u0026lt;= 1) return; auto mid = begin + length / 2; do_merge_sort(begin, mid, tmp_array); do_merge_sort(mid, end, tmp_array); merge(begin, mid, end, tmp_array); } void merge_sort(vector\u0026lt;int\u0026gt; \u0026amp;array) { vector\u0026lt;int\u0026gt; tmp_array(array.size(), 0); do_merge_sort(array.begin(), array.end(), tmp_array); return; } 例题1：合并两个有序数组 （力扣88） python代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 class Solution: def merge(self, nums1: List[int], m: int, nums2: List[int], n: int) -\u0026gt; None: \u0026#34;\u0026#34;\u0026#34; Do not return anything, modify nums1 in-place instead. \u0026#34;\u0026#34;\u0026#34; # 将nums1后移n个位置 for i in range(m - 1, -1, -1): nums1[i + n] = nums1[i] idx = 0 p = n q = 0 while p \u0026lt; m + n and q \u0026lt; n: if nums1[p] \u0026lt; nums2[q]: nums1[idx] = nums1[p] idx += 1 p += 1 else: nums1[idx] = nums2[q] idx += 1 q += 1 while p \u0026lt; m + n: nums1[idx] = nums1[p] idx += 1 p += 1 while q \u0026lt; n: nums1[idx] = nums2[q] idx += 1 q += 1 return 数组 二分查找 例题1：爱吃香蕉的珂珂（力扣875） 珂珂喜欢吃香蕉。这里有 N 堆香蕉，第 i 堆中有 piles[i] 根香蕉。警卫已经离开了，将在 H 小时后回来。\n珂珂可以决定她吃香蕉的速度 K（单位：根/小时）。每个小时，她将会选择一堆香蕉，从中吃掉 K 根。如果这堆香蕉少于 K 根，她将吃掉这堆的所有香蕉，然后这一小时内不会再吃更多的香蕉。\n珂珂喜欢慢慢吃，但仍然想在警卫回来前吃掉所有的香蕉。\n返回她可以在 H 小时内吃掉所有香蕉的最小速度 K（K 为整数）\n分析 此题规约为在数组中寻找一个分解线，左右边符合不同的条件。\npython代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 class Solution: def minEatingSpeed(self, piles: List[int], h: int) -\u0026gt; int: k_left = 1 k_right = max(piles) while k_left \u0026lt; k_right: mid = (k_left + k_right) // 2 if self.canFinish(piles, h, mid): k_right = mid else: k_left = mid + 1 # 必须加1 return k_left def canFinish(self, piles: List[int], h: int, k: int): h_ = 0 for pile in piles: h_ += pile // k h_ += 1 if pile % k != 0 else 0 return h \u0026gt;= h_ 例题2： x 的平方根 （力扣69） 给你一个非负整数 x ，计算并返回 x 的 算术平方根 。\n由于返回类型是整数，结果只保留 整数部分 ，小数部分将被 舍去 。\npython代码 1 2 3 4 5 6 7 8 9 10 11 class Solution: def mySqrt(self, x: int) -\u0026gt; int: l, r, ans = 0, x, -1 while l \u0026lt;= r: mid = (l + r) // 2 if mid * mid \u0026lt;= x: ans = mid l = mid + 1 else: r = mid - 1 return ans 链表 链表翻转 例题1：K 个一组翻转链表（力扣25）（字节-后端-频次60） python代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 class Solution: def reverseKGroup(self, head: Optional[ListNode], k: int) -\u0026gt; Optional[ListNode]: if k == 1: return head # 多指针法 h = None p = head q = head q_pre = None n = 0 pre_last = None while q != None: q_pre = q q = q.next n += 1 if n == k: n = 0 first, last = self.reverse(p, q_pre) if h == None: h = first pre_last = last else: pre_last.next = first pre_last = last if n == 0: pre_last.next = q p = q return h # 翻转p节点和q节点之间的链表 def reverse(self, p: Optional[ListNode], q: Optional[ListNode]): first = q last = p r = p.next last.next = None pre_r = None q_next = q.next while r != q_next: pre_r = r r = r.next pre_r.next = p p = pre_r return first, last 二叉树 二叉树深度优先遍历 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 # class TreeNode: # def __init__(self, val=0, left=None, right=None): # self.val = val # self.left = left # self.right = right class Solution: # 先序遍历 Accepted def preOrder(self, root: TreeNode) -\u0026gt; List[int]: stack = [root] res = [] while stack: node = stack.pop() if node: res.append(node.val) # 访问 stack.append(node.right) # 先将右节点加入栈中 stack.append(node.left) return res # 中序遍历 Accepted def inOrder(self, root: TreeNode) -\u0026gt; List[int]: stack = [] res = [] while root or stack: while root: stack.append(root) root = root.left node = stack.pop() res.append(node.val) # 访问 root = node.right return res # 后序遍历 Accepted def postOrder(self, root: TreeNode) -\u0026gt; List[int]: stack = [] res = [] preNode = None while root or stack: while root: stack.append(root) root = root.left root = stack.pop() if root.right == None or preNode == root.right: # 关键，取出来看看右边节点存在或者是否上次遍历过 res.append(root.val) preNode = root root = None # 避免重复访问左子树，不能丢 else: stack.append(root) root = root.right return res 例题1：求根节点到叶节点数字之和（力扣129） 给你一个二叉树的根节点 root ，树中每个节点都存放有一个 0 到 9 之间的数字。 每条从根节点到叶节点的路径都代表一个数字：\n例如，从根节点到叶节点的路径 1 -\u0026gt; 2 -\u0026gt; 3 表示数字 123 。 计算从根节点到叶节点生成的 所有数字之和 。\n叶节点 是指没有子节点的节点。\npython代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 # class TreeNode: # def __init__(self, val=0, left=None, right=None): # self.val = val # self.left = left # self.right = right class Solution: def __init__(self): self.sum = 0 def sumNumbers(self, root: TreeNode) -\u0026gt; int: self.sum = 0 self.do_sumNumbers(root, 0) return self.sum def do_sumNumbers(self, root: TreeNode, current: int): if root == None: return if root.left == None and root.right == None: self.sum += current * 10 + root.val else: self.do_sumNumbers(root.left, current * 10 + root.val) self.do_sumNumbers(root.right, current * 10 + root.val) 例题2：二叉树的最近公共祖先（力扣236）（字节-算法-频次6） 给定一个二叉树, 找到该树中两个指定节点的最近公共祖先。 百度百科中最近公共祖先的定义为：“对于有根树 T 的两个节点 p、q，最近公共祖先表示为一个节点 x，满足 x 是 p、q 的祖先且 x 的深度尽可能大（一个节点也可以是它自己的祖先）。\npython代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 # 完全按照自己的想法平铺直叙 class Solution: def __init__(self): self.res = None def lowestCommonAncestor(self, root: \u0026#39;TreeNode\u0026#39;, p: \u0026#39;TreeNode\u0026#39;, q: \u0026#39;TreeNode\u0026#39;) -\u0026gt; \u0026#39;TreeNode\u0026#39;: self.res = None self.dfs(root, p, q) return self.res def dfs(self, root: \u0026#39;TreeNode\u0026#39;, p: \u0026#39;TreeNode\u0026#39;, q: \u0026#39;TreeNode\u0026#39;) -\u0026gt; bool: if root is not None: left = self.dfs(root.left, p, q) right = self.dfs(root.right, p, q) node = True if root == p or root == q else False if (left is True and right is True) or \\ (left is True and node is True) or \\ (right is True and node is True): self.res = root return True # return什么都可 elif (left is True) or (right is True) or (node is True): return True else: return False else: return False 二叉树广度优先遍历（按层遍历） 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 # class TreeNode: # def __init__(self, val=0, left=None, right=None): # self.val = val # self.left = left # self.right = right class Solution: def levelOrder(self, root: TreeNode) -\u0026gt; List[List[int]]: import queue q = queue.Queue() res = [] if root: q.put(root) next_level_size = 0 # 维护下次层节点的个数 cur_level_size = 1 level = [] while not q.empty(): node = q.get() level.append(node.val) cur_level_size -= 1 # None节点不入队列 if node.left: q.put(node.left) next_level_size += 1 if node.right: q.put(node.right) next_level_size += 1 if cur_level_size == 0: res.append(level) level = [] # 不能丢 cur_level_size = next_level_size next_level_size = 0 return res 前序和中序遍历构造二叉树 python代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 # Definition for a binary tree node. # class TreeNode: # def __init__(self, val=0, left=None, right=None): # self.val = val # self.left = left # self.right = right class Solution: def buildTree(self, preorder: List[int], inorder: List[int]) -\u0026gt; TreeNode: length = len(preorder) if not length: return None root = TreeNode(preorder[0]) i = inorder.index(preorder[0]) if i: root.left = self.buildTree(preorder[1:1+i], inorder[0:i]) if length - i - 1: # 理解为右子树的节点数量 root.right = self.buildTree(preorder[1+i:length], inorder[i+1:]) return root 例题1：前序和中序遍历构造二叉树 （力扣98） 例题2：二叉树的右侧视图 （力扣199） 给定一个二叉树的 根节点 root，想象自己站在它的右侧，按照从顶部到底部的顺序，返回从右侧所能看到的节点值。\npython代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 class Solution: def solve(self , xianxu: List[int], zhongxu: List[int]) -\u0026gt; List[int]: # write code here # 10：21 # 引入深度变量 def build(preOrder: List[int], inOrder: List[int], depth: int): length = len(preOrder) if not length: return if len(res) \u0026gt; depth: res[depth] = preOrder[0] else: res.append(preOrder[0]) i = inOrder.index(preOrder[0]) if i: build(preOrder[1:i+1], inOrder[0:i], depth + 1) if length - i - 1: build(preOrder[i+1:], inOrder[i+1:], depth + 1) res = [] build(xianxu, zhongxu, 0) return res 二叉搜索树中序遍历 例题1：二叉搜索树中第K小的元素（力扣230） 给定一个二叉搜索树的根节点 root ，和一个整数 k ，请你设计一个算法查找其中第 k 个最小元素（从 1 开始计数）。\npython代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 class Solution: def __init__(self): self.n = 0 self.r = None def kthSmallest(self, root: Optional[TreeNode], k: int) -\u0026gt; int: self.n = 0 self.pre_visit(root, k) return self.r def pre_visit(self, root: Optional[TreeNode], k: int): if root != None: self.pre_visit(root.left, k) self.n += 1 if self.n == k: self.r = root.val return self.pre_visit(root.right, k) python代码（官方） 1 2 3 4 5 6 7 8 9 10 11 12 class Solution: def kthSmallest(self, root: TreeNode, k: int) -\u0026gt; int: stack = [] while root or stack: while root: stack.append(root) root = root.left root = stack.pop() k -= 1 if k == 0: return root.val root = root.right 图结构 1 2 3 4 5 6 7 8 G = [[0, 1, 1, 1, 1, 1, 0, 0], [0, 0, 1, 0, 1, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 1, 0, 0, 0, 1, 1], [0, 0, 0, 0, 0, 1, 0, 1], [0, 0, 0, 0, 0, 1, 1, 0]] 图遍历 下面的代码都是github copilot自动生成的代码，看起来非常不错。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 # 假设图为无向连通图 # 图深度优先遍历 def dfs(G: List[List[int]], v: int) -\u0026gt; List[int]: visited = [False] * len(G) stack = [v] res = [] while stack: v = stack.pop() if not visited[v]: visited[v] = True res.append(v) for i in range(len(G)): if G[v][i] == 1 and not visited[i]: stack.append(i) return res # 图广度优先遍历 def bfs(G: List[List[int]], v: int) -\u0026gt; List[int]: visited = [False] * len(G) queue = [v] res = [] while queue: v = queue.pop(0) if not visited[v]: visited[v] = True res.append(v) for i in range(len(G)): if G[v][i] == 1 and not visited[i]: queue.append(i) return res # 图递归深度优先遍历 def dfs_recur(G: List[List[int]], v: int) -\u0026gt; List[int]: visited = [False] * len(G) res = [] def dfs_recur_helper(v: int): if not visited[v]: visited[v] = True res.append(v) for i in range(len(G)): if G[v][i] == 1 and not visited[i]: dfs_recur_helper(i) dfs_recur_helper(v) return res # 图递归广度优先遍历 def bfs_recur(G: List[List[int]], v: int) -\u0026gt; List[int]: visited = [False] * len(G) res = [] def bfs_recur_helper(v: int): if not visited[v]: visited[v] = True res.append(v) for i in range(len(G)): if G[v][i] == 1 and not visited[i]: bfs_recur_helper(i) bfs_recur_helper(v) return res 参考：\n图的两种遍历方式：DFS、BFS\n例题1：岛屿数量（力扣200）（字节-算法-频次5） 给你一个由 \u0026lsquo;1\u0026rsquo;（陆地）和 \u0026lsquo;0\u0026rsquo;（水）组成的的二维网格，请你计算网格中岛屿的数量。\n岛屿总是被水包围，并且每座岛屿只能由水平方向和/或竖直方向上相邻的陆地连接形成。\n此外，你可以假设该网格的四条边均被水包围。\npython代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 class Solution: def numIslands(self, grid: List[List[str]]) -\u0026gt; int: def dfs(i: int, j: int): if i \u0026gt;= 0 and i \u0026lt; len(grid) and j \u0026gt;= 0 and j \u0026lt; len(grid[i]) and grid[i][j] == \u0026#39;1\u0026#39;: grid[i][j] = \u0026#39;0\u0026#39; dfs(i - 1, j) dfs(i + 1, j) dfs(i, j - 1) dfs(i, j + 1) res = 0 for i in range(len(grid)): for j in range(len(grid[i])): if grid[i][j] == \u0026#39;1\u0026#39;: res += 1 dfs(i, j) return res 其他例题 被围绕的区域（力扣130） 并查集 位运算 参考：位操作基础篇之位操作全面总结\n动态规划算法 引子：计算斐波那契数列 斐波那契数列是指这样一个数列：0、1、1、2、3、5、8、13、21、34、55\u0026hellip;\u0026hellip;\n斐波纳契数列可以用下面的方法定义：\n$$ \\left\\{ \\begin{array}{l} F(0) = 0, \\\\ F(1) = 1, \\\\ F(n) = F(n-1) + F(n-2), \\quad n \\geq 2 \\text{ 为整数} \\end{array} \\right. $$\n如果我们要计算F(5)，递归计算图如下： 可以看到因为重复求解相同的子问题，使得浪费大量的计算时间和计算资源。那么求解斐波那契数列可以采用1）带有备忘录的递归算法；2）自底向上法。\n从斐波那契数列到动态规划 朴素递归算法之所以效率很低，是因为它反复求解相同的子问题。因此，动态规划方法仔细安排求解顺序，对每个子问题只求解一次，并将结果保存下来。如果随后再次需要此子问题的解，只需查找保存的结果，而不必重新计算。因此，动态规划方法时付出额外的内存空间来节省时间，是典型的时空权衡的例子。而时间上的节省可能是非常巨大的：可能将一个指数时间的解转化为一个多项式时间的解。\n动态规划有两种等价的实现方法：\n第一种方法称为带备忘的自顶向下。此方法仍按自然的递归形式编写过程，但过程或保存每个子问题的解（通常在一个数组或散列表）。当需要一个子问题的解时，过程首先检查是否已经保存过此解。如果是，则直接返回保存的值，从而节省了计算时间；否则，按通常方式计算这个子问题。称这个递归过程时带备忘的。\n第二种方法称为自底向上法。这种方法一般需要恰当定义子问题“规模”的概念，使得任何子问题的求解都只依赖与“更小的”子问题的求解。因此可以将子问题按规模排序，按由小到大顺序进行求解。当求解某个子问题时，它所依赖的那些更小的子问题都已求解完毕，结果已经保存。每个子问题只需求解一次，当我们求解它时，它的所有前提子问题都已求解完成。\n两种算法得到的算法具有相同的渐近运行时间，仅有的差异在某些特殊情况下，自顶向下方法并未真正递归地考察所有可能的子问题。由于没有频繁的递归函数调用的开销，自底向上方法的时间复杂性函数通常具有更小的系数。\n动态规划题一般情况，需要先找到合适的状态转移方程/递推公式，中间结果状态的保存一般用数组或者多维数组，这里，如果状态转移方程只依赖之前计算的有限项，且这些有限项符合固定的规则，并且最后计算的结果不是在所有状态中寻找（如max）求得，那么往往并不需要一个数组，只需要记录某几个之前的状态（变量可以重复利用），就可以递推后面的情况，降低空间复杂度。该想法总结自求解斐波那契数列。\n例题 例题1：打家劫舍（力扣198） 你是一个专业的小偷，计划偷窃沿街的房屋。每间房内都藏有一定的现金，影响你偷窃的唯一制约因素就是相邻的房屋装有相互连通的防盗系统，如果两间相邻的房屋在同一晚上被小偷闯入，系统会自动报警。\n给定一个代表每个房屋存放金额的非负整数数组，计算你不触动警报装置的情况下 ，一夜之内能够偷窃到的最高金额。如，输入：[2,7,9,3,1] 输出：12\n递推公式 $$ \\left\\{\\begin{array}{l} dp[i][0] \\text { 代表偷了第间房获得的最大收益 } \\\\ dp[i][1] \\text { 代表没有偷第 } \\mathrm{i} \\text { 间房获得的最大收益 } \\end{array}\\right. $$\n$$ \\left\\{\\begin{array}{l} d p[i+1][0]=dp[i][1]+L[i+1] \\\\ d p[i+1][1]=\\max (d p[i][0], d p[i][1]) \\end{array}\\right. $$\npython代码 1 2 3 4 5 6 7 8 9 10 11 class Solution: def rob(self, nums: List[int]) -\u0026gt; int: length = len(nums) import numpy as np dp = np.zeros((length, 2)) dp[0][0] = nums[0] # 偷了第i家获得的最大收益 dp[0][1] = 0 # 没偷了第i家获得的最大收益 for i in range(length - 1): dp[i + 1][0] = dp[i][1] + nums[i + 1] dp[i + 1][1] = max(dp[i][0], dp[i][1]) return int(dp.max()) 优化之后的递推公式 用 $d p[i]$ 表示前 $i$ 间房屋能偷窃到的最高总金额, 那么就有如下的状态转移方程: $$ d p[i]=\\max (d p[i-2]+n u m s[i], d p[i-1]) $$ 边界条件为: $$ \\begin{cases}d p[0]=n u m s[0] \u0026amp; \\text { 只有一间房屋, 则偷窄该房屋 } \\\\ d p[1]=\\max (n u m s[0], n u m s[1]) \u0026amp; \\text { 只有两间房屋, 选择其中金额较高的房屋进行偷窃 }\\end{cases} $$ 最终的答案即为 $d p[n-1]$, 其中 $n$ 是数组的长度。\n例题2：零钱兑换 (力扣322) 给你一个整数数组 coins ，表示不同面额的硬币；以及一个整数 amount ，表示总金额。计算并返回可以凑成总金额所需的最少的硬币个数 。如果没有任何一种硬币组合能组成总金额，返回 -1 。\n你可以认为每种硬币的数量是无限的。 如，输入：coins = [1, 2, 5], amount = 11，输出：3\n分析 首先，想要凑成总金额又想使得所需的硬币个数最少，那么在组合中尽可能得使用更大面额的硬币；如果最大面额的硬币小于所需凑成的总金额，那么可以尝试先用一定数量的最大面额硬币，那么形成一个子问题为： 使用除去最大面额的硬币来凑成新总金额所需最小的硬币个数，新总金额 = 总金额 - 最大面额硬币 * 最大面额硬币个数。\npython代码 1 2 3 4 5 6 7 8 9 class Solution: def coinChange(self, coins: List[int], amount: int) -\u0026gt; int: dp = [float(\u0026#39;inf\u0026#39;)] * (amount + 1) dp[0] = 0 for coin in coins: for x in range(coin, amount + 1): dp[x] = min(dp[x], dp[x - coin] + 1) return dp[amount] if dp[amount] != float(\u0026#39;inf\u0026#39;) else -1 例题3： 最长有效括号（力扣32） 给你一个只包含 \u0026lsquo;(\u0026rsquo; 和 \u0026lsquo;)\u0026rsquo; 的字符串，找出最长有效（格式正确且连续）括号子串的长度。如，输入：s = \u0026ldquo;)()())\u0026quot;，输出：4，解释：最长有效括号子串是 \u0026ldquo;()()\u0026rdquo;\npython代码 1 2 3 4 5 6 7 8 9 10 class Solution: def longestValidParentheses(self, s: str) -\u0026gt; int: n = len(s) if n==0:return 0 dp = [0]*n for i in range(len(s)): # i-dp[i-1]-1是与当前)对称的位置 if s[i]==\u0026#39;)\u0026#39; and i-dp[i-1]-1\u0026gt;=0 and s[i-dp[i-1]-1]==\u0026#39;(\u0026#39;: dp[i]=dp[i-1]+dp[i-dp[i-1]-2]+2 # 会出现dp[-1]，然而没影响 return max(dp) 例题4：编辑距离 （力扣72）（字节-算法-频次8） 给你两个单词 word1 和 word2， 请返回将 word1 转换成 word2 所使用的最少操作数。\n你可以对一个单词进行如下三种操作：插入一个字符、删除一个字符、替换一个字符。如： 输入：word1 = \u0026ldquo;horse\u0026rdquo;, word2 = \u0026ldquo;ros\u0026rdquo;\n输出：3\n解释：\nhorse -\u0026gt; rorse (将 \u0026lsquo;h\u0026rsquo; 替换为 \u0026lsquo;r\u0026rsquo;)\nrorse -\u0026gt; rose (删除 \u0026lsquo;r\u0026rsquo;)\nrose -\u0026gt; ros (删除 \u0026rsquo;e\u0026rsquo;)\n官方给的思路如何保证是全局最小操作数呢？另外，处理dp边界时候，可以申请一个额外的空间i=0，j=0，即申请dp[0\u0026hellip;n + 1][0\u0026hellip;m + 1]空间，然后把第一行和第一列的值设置为边界，这样递推代码中不用额外考虑边界情况，这样可以简化代码。\npython代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 class Solution: def minDistance(self, word1: str, word2: str) -\u0026gt; int: if len(word1) == 0: return len(word2) if len(word2) == 0: return len(word1) # 递推式已经确定了，边界条件注意弄对就ok了！ # 这里其实可以申请n + 1, m + 1大小的二维数组 import numpy as np n, m = len(word1), len(word2) self.dp = np.zeros((n, m), dtype=int) for i in range(n): for j in range(m): if word1[i] == word2[j]: self.dp[i][j] = self.getDp(i - 1, j - 1) else: self.dp[i][j] = min(self.getDp(i, j - 1), self.getDp(i - 1, j), self.getDp(i - 1, j - 1)) + 1 return int(self.dp[n - 1][m - 1]) def getDp(self, i : int, j: int): if i \u0026lt; 0 and j \u0026lt; 0: return 0 if i \u0026lt; 0: return j + 1 if j \u0026lt; 0: return i + 1 return self.dp[i][j] 例题5：最长递增子序列 （力扣300）（字节-算法-频次6） 给你一个整数数组 nums ，找到其中最长严格递增子序列的长度。\n子序列 是由数组派生而来的序列，删除（或不删除）数组中的元素而不改变其余元素的顺序。例如，[3,6,2,7] 是数组 [0,3,1,6,2,2,7] 的子序列\n看着有些难度，实际上只要想到动态规划，并且以nums[i]处作为子序列的结尾，从小递推到给定的序列的长度，就可以解决问题了。\npython代码 1 2 3 4 5 6 7 8 class Solution: def lengthOfLIS(self, nums: List[int]) -\u0026gt; int: dp = [1] * len(nums) for i in range(len(nums)): for j in range(i): if nums[i] \u0026gt; nums[j]: dp[i] = max(dp[i], dp[j] + 1) # 更精简 return max(dp) 其他例题 青蛙过河（力扣403） 动态规划中常用思想 增量法：字符串/矩阵表示的结构中，往往可以考虑尾部增加一个字符所带来的影响/变化，从而考虑多个情况，建立递归公式。 在字符串表示的结构中，任何一个子串/子序列，都必须有一个结尾字符，往往可以考虑将以字符结尾的某个DP变量作为动态规划状态，从而考虑更长的字符串。 奇淫技巧（小题大做） 例题1：寻找重复数 （力扣287）（字节-算法-频次3） 待解决 小强有两个序列 a 和 b ，这两个序列都是由相同的无重复数字集合组成的，现在小强想把 a 序列变成 b 序列，他只能进行以下的操作：\n从序列a中选择第一个或者最后一个数字井把它插入 a 中的任意位置。\n问小强至少需要几次操作可以将序列 a 变为序列 b 。\n输入描述：\n一行一个整数 n 表示序列的长度。接下来两行每行 n 个整数。第一行表示序列a，第二行表示序列b。1≤ n ≤ $10^5；$1≤ $a_i$, $b_i$ ≤ $10^9$。保证给出的序列符合题意。\n内推 字节跳动内推链接：字节内推，有需要的同学自取。\n未归档 配置校验数 小华在开发配置校验功能时，发现配置的打开和关闭总是两两结对，为了减少这个状态的存储空间，小华将这些配置的“开°，“关“状态转换为1和0 的数组从左向右依次填充，如：\n因为配置总是成对出现，所以数组长度为偶数，同时为了容易查找结对的配置，小华约定：对于 M 对配置，坐标 i 和 i+M 的配置组成一对。因为第一对配置必须开启，小华发现可以使用一个整数来表示，比如3，二进制表达为11，就代表一对配置同时打开，小华称之为配置校验数。\n于是，小华突发其想，想研究一下这样能刚好表达结对配置同时打开或关闭的整數有多少个，现在请你设计一个程序，帮小华找出不大于给定的非负整数N的配置校验数有多少个。\n基本计算器 [力扣224](https://leetcode.cn/problems/basic-calculator/）\nc++ 代码\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 # include \u0026lt;iostream\u0026gt; # include \u0026lt;stack\u0026gt; using namespace std; class Solution { public: int calculate(string s) { // 括号展开+栈 stack\u0026lt;int\u0026gt; ops; ops.push(1); int sign = 1; int n = s.size(); int i = 0; int ret = 0; while (i \u0026lt; n) { if (s[i] == \u0026#39; \u0026#39;) i++; else if (s[i] == \u0026#39;+\u0026#39;) { sign = ops.top(); i++; } else if (s[i] == \u0026#39;-\u0026#39;) { sign = -ops.top(); i++; } else if (s[i] == \u0026#39;(\u0026#39;) { ops.push(sign); i++; } else if (s[i] == \u0026#39;)\u0026#39;) { ops.pop(); i++; } else { long num = 0; for (; i \u0026lt; n \u0026amp;\u0026amp; \u0026#39;0\u0026#39; \u0026lt;= s[i] \u0026amp;\u0026amp; s[i] \u0026lt;= \u0026#39;9\u0026#39;; i++) { num = 10 * num + s[i] - \u0026#39;0\u0026#39;; } ret += sign * num; } } return ret; } }; int main() { Solution solution; string s; getline(cin, s); cout \u0026lt;\u0026lt; solution.calculate(s) \u0026lt;\u0026lt; endl; return 0; } 参考：\n动态规划课件和代码\n","date":"2022-02-18T13:08:49Z","image":"http://localhost:1313/posts/leetcode%E7%AE%97%E6%B3%95%E9%A2%98%E6%80%BB%E7%BB%93/algorithms_cover_hu_4a0ce591dae895aa.jpg","permalink":"http://localhost:1313/posts/leetcode%E7%AE%97%E6%B3%95%E9%A2%98%E6%80%BB%E7%BB%93/","title":"LeetCode 进阶指南：解题思路与算法题分类总结"},{"content":"用矩阵推导网络。\n符号定义 使用小写字母$x$表示标量，粗体小写字母$\\boldsymbol{x}$表示向量，注意向量可能为行向量或者列向量，大写字母$X$表示矩阵。 $\\sigma$为逐元素sigmoid函数：$\\sigma(z)=\\frac{1}{1+\\mathrm{e}^{-z}}$。 $\\boldsymbol{1}$为列向量，$\\boldsymbol{1}=(1, 1, 1 \\cdots 1, 1, 1)^{T}$，非指示函数。 $exp(\\boldsymbol{a})$表示逐元素求指数。 $log(\\boldsymbol{a})$表示逐元素求自然对数。 符号含义 列向量$\\boldsymbol{x}=\\left(x_{1}, x_{2}, x_{3} \\cdots x_{n-2}, x_{n-1}, x_{n}\\right)^{T}$代表一个输入样本，具有$n$个特征值。 设列向量$\\boldsymbol{z}=\\left(z_{1}, z_{2}, z_{3} \\cdots z_{n-2}, z_{n-1}, z_{n}\\right)^{T}$，\n$\\sigma(\\boldsymbol{z}) = \\left(\\sigma(z_{1}), \\sigma(z_{2}), \\sigma(z_{3}) \\cdots \\sigma(z_{n-2}), \\sigma(z_{n-1}), \\sigma(z_{n})\\right)$ 设列向量$\\boldsymbol{a}=\\left(a_{1}, a_{2}, a_{3} \\cdots a_{n-2}, a_{n-1}, a_{n}\\right)^{T}$，$\\operatorname{softmax}(\\boldsymbol{a})=\\frac{\\exp (\\boldsymbol{a})}{\\mathbf{1}^{T} \\exp (\\boldsymbol{a})}$，分母为行向量乘以列向量为标量，分子为列向量，所以结果仍为列向量。 运算法则 矩阵运算法则 对尺寸相同的矩阵$A, B$，$\\operatorname{tr}\\left(A^{T} B\\right)=\\sum_{i, j} A_{i j} B_{i j}$。 矩阵微分运算符法则 1. 加减法、矩阵乘法、转置、求迹。 $$ d(X \\pm Y)=d X \\pm d Y $$ $$ d(X Y)=(d X) Y+X d Y $$ $$ d\\left(X^{T}\\right)=(d X)^{T} $$ $$ d \\operatorname{tr}(X)=\\operatorname{tr}(d X) $$\n2. 求逆。 $$ d X^{-1}=-X^{-1} d X X^{-1} $$ 此式可以在 $ X X^{-1}=I $ 两侧求微分来证明。\n3. 行列式。 $$ d|X|=\\operatorname{tr}\\left(X^{\\ast} d X\\right) $$\n其中$X^{\\ast}$表示$X$的伴随矩阵，在$X$可逆时，上式又可以写作为 $d|X|=|X|\\operatorname{tr}\\left(X^{-1} d X\\right)$。此式可以用Laplace展开证明，详见张贤达《矩阵分析与应用》。\n4. 逐元素乘法。 $$ d(X \\odot Y)=d X \\odot Y+X \\odot d Y $$\n$\\odot$表示尺寸相同的矩阵$X$，$Y$逐元素相乘。\n5. 逐元素函数。 $$ d \\sigma(X)=\\sigma^{\\prime}(X) \\odot d X $$\n$\\sigma(X)=\\left[\\sigma\\left(X_{i j}\\right)\\right]$是逐元素标量函数运算，$\\sigma^{\\prime}(X)=\\left[\\sigma^{\\prime}\\left(X_{i j}\\right)\\right]$ 是逐元素求导数。例如： $$ X=\\left[\\begin{array}{ll} X_{11} \u0026amp; X_{12} \\\\ X_{21} \u0026amp; X_{22} \\end{array}\\right] $$\n$$ d \\sin (X)=\\left[\\begin{array}{ll} \\cos X_{11} d X_{11} \u0026amp; \\cos X_{12} d X_{12} \\\\ \\cos X_{21} d X_{21} \u0026amp; \\cos X_{22} d X_{22} \\end{array}\\right]=\\cos (X) \\odot d X $$\n理解 定义：标量f对矩阵 $X$ 的导数, 定义为 $\\frac{\\partial f}{\\partial X}=\\left[\\frac{\\partial f}{\\partial X_{i j}}\\right]$，即f对X逐元素求导排成与X尺寸相同的矩阵。\n将矩阵导数与微分建立联系：$d f=\\sum_{i=1}^{m} \\sum_{j=1}^{n} \\frac{\\partial f}{\\partial X_{i j}} d X_{i j}=\\operatorname{tr}\\left(\\frac{\\partial f^{T}}{\\partial X} d X\\right)$。\n微分算子$d$作用于矩阵$X$，表示为逐元素作用。\n第一个等号是全微分公式，第二个等号表达了矩阵导数与微分的联系。\n$tr()$代表迹(trace)是方阵对角线元素之和。\n举例：设$X=\\left[\\begin{array}{l}X_{0_0}, X_{01} \\\\ X_{10}, X_{11}\\end{array}\\right]$, $d X=\\left[\\begin{array}{l}dX_{00}, dX_{01} \\\\ dX_{10}, dX_{11}\\end{array}\\right]$，$\\frac{d f}{d X}=\\left[\\begin{array}{ll}\\frac{\\partial f}{\\partial X_{00}}, \\frac{\\partial f}{\\partial X_{01}} \\\\ \\frac{\\partial f}{\\partial X_{10}}, \\frac{\\partial f}{\\partial X_{11}}\\end{array}\\right]$，$\\operatorname{tr}\\left(\\frac{\\partial f^{T}}{\\partial X} d X\\right)=\\operatorname{tr}\\left(\\left[\\begin{array}{ll}\\frac{\\partial f}{\\partial X_{00}}, \\frac{\\partial f}{\\partial X_{10}} \\\\ \\frac{\\partial f}{\\partial X_{01}}, \\frac{\\partial f}{\\partial X_{11}}\\end{array}\\right]\\left[\\begin{array}{l}dX_{00}, dX_{01} \\\\ dX_{10}, dX_{11}\\end{array}\\right]\\right)$\n思考 样本特征值排列为列向量，方便统一形式为权重参数$W$放在$\\boldsymbol{x}$前，进行乘积。 全连接网络 $$ l=-\\boldsymbol{y}^{T} \\log \\operatorname{softmax}\\left(W_{2} \\sigma\\left(W_{1} \\boldsymbol{x}\\right)\\right) $$\n符号说明 $l$为损失函数。 $\\boldsymbol{x}$为单样本，则$l$只包含一个样本的损失函数。 分类网络类别数为$m$，$\\boldsymbol{y}$ 是除一个元素为1外其它元素为 0 的的 $m \\times 1$ 列向量, $W_{2}$ 是 $m \\times p$ 矩阵, $W_{1}$ 是 $p \\times n$ 矩阵, $\\boldsymbol{x}$ 是 $n \\times 1$ 列向量, $l$ 是标量 推导 $\\frac{\\partial l}{\\partial W_{1}}$ 和 $\\frac{\\partial l}{\\partial W_{2}}$ 定义：\n$\\boldsymbol{a_{1}}=W_{1}\\boldsymbol{x}$\n$\\boldsymbol{h}_1=\\sigma\\left(\\boldsymbol{a}_1\\right)$\n$ \\boldsymbol{a_{2}}=W_{2}\\boldsymbol{h_{1}}$ $l=-\\boldsymbol{y}^{T} \\log \\operatorname{softmax}\\left(\\boldsymbol{a}_{2}\\right)$\n已知 $\\frac{\\partial l}{\\partial \\boldsymbol{a_{2}}}=\\operatorname{softmax}\\left(\\boldsymbol{a}_{2}\\right)-\\boldsymbol{y}$ 。\n推导结果： $$ \\frac{\\partial l}{\\partial W_{2}}=\\frac{\\partial l}{\\partial \\boldsymbol{a_{2}}} \\boldsymbol{h_{1}}^{T} $$ $$ \\frac{\\partial l}{\\partial W_{1}}=\\frac{\\partial l}{\\partial \\boldsymbol{a}_{1}} \\boldsymbol{x}^{T} $$\n推广到多个样本 使用矩阵来表示N个样本，以简化形式。\n定义：\n$X=\\left[\\boldsymbol{x_{1}}, \\cdots, \\boldsymbol{x_{N}}\\right]$\n$A_{1}=\\left[\\boldsymbol{a_{1,1}}, \\cdots \\boldsymbol{a_{1, N}}\\right]=W_{1} X+\\boldsymbol{b_{1}} \\mathbf{1}^{T}$\n$H_{1}=\\left[\\boldsymbol{h_{1,1}}, \\cdots, \\boldsymbol{h_{1, N}}\\right]=\\sigma\\left(A_{1}\\right)$\n$A_{2}=\\left[\\boldsymbol{a_{2,1}}, \\cdots, \\boldsymbol{a_{2, N}}\\right]=W_{2} H_{1}+\\boldsymbol{b_{2}} \\mathbf{1}^{T}$\n注意这里使用全$\\mathbf{1}$向量来扩展维度。\n推导结果：\n$$ \\frac{\\partial l}{\\partial W_{1}}=\\frac{\\partial l}{\\partial A_{1}} X^{T}, \\quad \\frac{\\partial l}{\\partial \\boldsymbol{b_1}}=\\frac{\\partial l}{\\partial A_{1}} \\mathbf{1} $$\n$$ \\frac{\\partial l}{\\partial W_{2}}=\\frac{\\partial l}{\\partial A_{2}} H_{1}^{T}, \\quad \\frac{\\partial l}{\\partial \\boldsymbol{b_2}}=\\frac{\\partial l}{\\partial A_{2}} \\mathbf{1} $$\n参考 神经网络的一些公式总结\n矩阵求导术（上）\n矩阵求导术（下）\n更新记录 调整格式和排版。 —— 2022.07.19\n使用 pandoc 渲染，对公式展示更友好。 —— 2022.08.27\n","date":"2021-10-29T11:20:28Z","image":"http://localhost:1313/posts/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9F%A9%E9%98%B5%E5%88%86%E6%9E%90/matrix_analysis_hu_1d32265eb6a15bcb.jpg","permalink":"http://localhost:1313/posts/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9F%A9%E9%98%B5%E5%88%86%E6%9E%90/","title":"矩阵运算在深度学习中的理论与应用"},{"content":"为了更深入理解卷积神经网络，这篇博客介绍在卷积神经网络中常用的卷积操作底层是如何实现的。\n卷积 卷积本身的执行过程是通过在特征图上滑动卷积核来完成的，如下面两个动图，形象地展示了单通道卷积和多通道卷积操作。\n单通道卷积 多通道卷积 多通道卷积计算底层实现 假设输入图像及卷积和大小如下图所示： 第一步：分别将特征图和卷积转换为矩阵 卷积核 对于2D卷积，本身是四维的卷积核，将其转换为二维由$C_{\\text {out }} \\times C \\times K \\times K$变为$C_{\\text {out }} \\times M$，其中$M=C \\times K \\times K$。\n例如，如下卷积核的维度是$2 \\times 3 \\times 2 \\times 2$，分别为 filter 1 和 filter 2。\n$$ \\left[\\begin{array}{ll} 1 \u0026amp; 1 \\\\ 2 \u0026amp; 2 \\end{array}\\right]\\left[\\begin{array}{ll} 1 \u0026amp; 1 \\\\ 1 \u0026amp; 1 \\end{array}\\right]\\left[\\begin{array}{ll} 0 \u0026amp; 1 \\\\ 1 \u0026amp; 0 \\end{array}\\right] $$\n$$ \\left[\\begin{array}{ll} 1 \u0026amp; 0 \\\\ 0 \u0026amp; 1 \\end{array}\\right]\\left[\\begin{array}{ll} 2 \u0026amp; 1 \\\\ 2 \u0026amp; 1 \\end{array}\\right]\\left[\\begin{array}{ll} 1 \u0026amp; 2 \\\\ 2 \u0026amp; 0 \\end{array}\\right] $$\n转换成$C_{\\text {out }} \\times M$矩阵为$2 \\times 12$大小，如下： $$ \\left[\\begin{array}{llllllllllll} 1 \u0026amp; 1 \u0026amp; 2 \u0026amp; 2 \u0026amp; 1 \u0026amp; 1 \u0026amp; 1 \u0026amp; 1 \u0026amp; 0 \u0026amp; 1 \u0026amp; 1 \u0026amp; 0 \\\\ 1 \u0026amp; 0 \u0026amp; 0 \u0026amp; 1 \u0026amp; 2 \u0026amp; 1 \u0026amp; 2 \u0026amp; 1 \u0026amp; 1 \u0026amp; 2 \u0026amp; 2 \u0026amp; 0 \\end{array}\\right] $$\n特征图 对于输入为$C \\times H \\times W$的特征图, 将其转换为$\\left(H^{\\prime} \\times W^{\\prime}\\right) \\times(C \\times K \\times K)$的矩阵。其中$H^{\\prime}$和 $W^{\\prime}$为输出特征图的长和宽。与卷积核kernel的变换不同，feature map不是单纯将矩阵resize一下就行, 而是要根据卷积核的尺寸、与特征图的作用过程需要的stride和padding，从输入特征中选择相应的值组成转换后的矩阵。\n例如, 假设输入的特征图的大小为 $3 \\times 3 \\times 3$, 特征图为： $$ \\left[\\begin{array}{lll} 1 \u0026amp; 2 \u0026amp; 0 \\ 1 \u0026amp; 1 \u0026amp; 3 \\ 0 \u0026amp; 2 \u0026amp; 2 \\end{array}\\right]\\left[\\begin{array}{lll} 0 \u0026amp; 2 \u0026amp; 1 \\ 0 \u0026amp; 3 \u0026amp; 2 \\ 1 \u0026amp; 1 \u0026amp; 0 \\end{array}\\right]\\left[\\begin{array}{lll} 1 \u0026amp; 2 \u0026amp; 1 \\ 0 \u0026amp; 1 \u0026amp; 3 \\ 3 \u0026amp; 3 \u0026amp; 2 \\end{array}\\right] $$ 采用 $2 \\times 2$ 卷积核, stride为 $1$, padding为 $0$ ，转换得到如下： $$ \\left[\\begin{array}{llllllllllll} 1 \u0026amp; 2 \u0026amp; 1 \u0026amp; 1 \u0026amp; 0 \u0026amp; 2 \u0026amp; 0 \u0026amp; 3 \u0026amp; 1 \u0026amp; 2 \u0026amp; 0 \u0026amp; 1 \\ 2 \u0026amp; 0 \u0026amp; 1 \u0026amp; 3 \u0026amp; 2 \u0026amp; 1 \u0026amp; 3 \u0026amp; 2 \u0026amp; 2 \u0026amp; 1 \u0026amp; 1 \u0026amp; 3 \\ 1 \u0026amp; 1 \u0026amp; 0 \u0026amp; 2 \u0026amp; 0 \u0026amp; 3 \u0026amp; 1 \u0026amp; 1 \u0026amp; 0 \u0026amp; 1 \u0026amp; 3 \u0026amp; 3 \\ 1 \u0026amp; 3 \u0026amp; 2 \u0026amp; 2 \u0026amp; 3 \u0026amp; 2 \u0026amp; 1 \u0026amp; 0 \u0026amp; 1 \u0026amp; 3 \u0026amp; 3 \u0026amp; 2 \\end{array}\\right] $$ 这样, 最终的计算结果就变成了\n$F \\times C^{T}=\\left(\\left(H^{\\prime} \\times W^{\\prime}\\right) \\times(C \\times K \\times K)\\right) \\times\\left(C_{\\text {out }} \\times(C \\times K \\times K)\\right)^{T}=\\left(H^{\\prime} \\times W^{\\prime}\\right) \\times C_{\\text {out }}$\n整体的流程可以简化为 下面用代码实现上面卷积过程：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 import torch from torch.nn.functional import unfold, fold x = torch.Tensor([[[[1, 2, 0], [1, 1, 3], [0, 2, 2]], [[0, 2, 1], [0, 3, 2], [1, 1, 0]], [[1, 2, 1], [0, 1, 3],[3, 3, 2]]]]) print(x.shape) weight = torch.Tensor([[[[1, 1], [2, 2]], [[1, 1], [1, 1]], [[0, 1], [1, 0]]], [[[1, 0], [0, 1]], [[2, 1], [2, 1]], [[1, 2], [2, 0]]]]) print(weight.shape) kernel_size = 2 F = unfold(x, kernel_size).transpose(1, 2) print(F) C = weight.view(weight.size(0), -1) print(C) # F x C\u0026#39; out_unf = F.matmul(C.t()) print(out_unf) out = fold(out_unf.transpose(1, 2), (2, 2), (1, 1)) print(out) print(out.shape) 如果把特征图按照行优先展开为一维向量，那么对应的卷积操作如下： 总结与分析 输出层的节点值并不是由全部输入层的节点值与权重乘积和得到，而只有部分输入节点参与到计算；从另一的角度可以当成是有一部分权重为零。 有大量权重被共享，有几个滤波器就共享了几套权重参数，这点原因应该是空间平移不变性，即某一区域和另一区域并没有差别。 上面将所有特征图拉成一维向量，这样只是和全连接层做对比，实际上，因为图像数据存在多通道，例如一般情况下的RGB三通道图像，每个通道包含一个维度的信息；另外图像中像素点之间的位置信息在二维图像中可以更好的呈现（编码），而拉成一维向量会丢失这些信息。 从信息论角度来说，三通道图像是否有图形的信息存在冗余。 参考： 卷积计算的底层实现\nYJango的卷积神经网络\n更新记录 调整格式和排版。 —— 2022.07.19\n","date":"2021-10-22T15:15:50Z","image":"http://localhost:1313/posts/%E5%8D%B7%E7%A7%AF%E8%AE%A1%E7%AE%97%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0/convolutional_calculation_hu_ab1e1453929d77b1.png","permalink":"http://localhost:1313/posts/%E5%8D%B7%E7%A7%AF%E8%AE%A1%E7%AE%97%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0/","title":"卷积计算底层实现"},{"content":"C++编程基础 Hello, world! 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 #include \u0026lt;iostream\u0026gt; #include \u0026lt;stdlib.h\u0026gt; //使用atexit() using namespace std; void show1(void) { cout \u0026lt;\u0026lt; \u0026#34;first exit main()\u0026#34; \u0026lt;\u0026lt; endl; } void show2(void) { cout \u0026lt;\u0026lt; \u0026#34;second exit main()\u0026#34; \u0026lt;\u0026lt; endl; } int main(int argc, char* argv[]) { atexit(show1); atexit(show2); cout \u0026lt;\u0026lt; \u0026#34;Hello, world!\u0026#34; \u0026lt;\u0026lt; endl; system(\u0026#34;pause\u0026#34;); return 0; } /*打印 Hello, world! second exit main() first exit main() */ main 函数前面的数据类型 int 与 void main 函数的返回值是返回给主调进程，使主调进程得知被调用程序的运行结果。\n标准规范中规定 main 函数的返回值为 int，一般约定返回 0 值时代表程序运行无错误，其它值均为错误号，但该约定并非强制。\n如果程序的运行结果不需要返回给主调进程，或程序开发人员确认该状态并不重要，比如所有出错信息均在程序中有明确提示的情况下，可以不写 main 函数的返回值。在一些检查不是很严格的编译器中，比如 VC, VS 等，void 类型的 main 是允许的。不过在一些检查严格的编译器下，比如 g++, 则要求 main 函数的返回值必须为 int 型。\n所以在编程时，区分程序运行结果并以 int 型返回，是一个良好的编程习惯。\nmain 函数执行完后执行其他语句 有时候需要在程序退出时做一些诸如释放资源的操作。我们可以用 atexit() 函数来注册程序正常终止时要被调用的函数。\natexit() 在一个程序中最多可以注册32个处理函数，这些处理函数的调用顺序与注册顺序相反，即后注册的函数先被调用。\n有必要补充一下，main函数执行之前会做什么？全局对象的构造函数会在main函数之前执行。例\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 class C { public: C() { std::cout \u0026lt;\u0026lt; \u0026#34;call C()\u0026#34; \u0026lt;\u0026lt; std::endl; }; }; C c0; //全局变量 int main() { std::cout \u0026lt;\u0026lt; \u0026#34;main() start\u0026#34; \u0026lt;\u0026lt; std::endl; C c1; // call C() return 0; } /** call C() main() start call C() */ main函数之前执行的操作 main函数执行之前，主要就是初始化系统相关资源：\n设置栈指针 初始化静态static变量和global全局变量，即.data段的内容 将未初始化部分的全局变量赋初值：数值型short，int，long等为0，bool为FALSE，指针为NULL等等，即.bss段的内容 全局对象初始化，在main之前调用构造函数 将main函数的参数argc，argv等传递给main函数，然后才真正运行main函数 \u0026ldquo;\\n\u0026rdquo; 与 endl 的区别 在 C++ 中，终端输出换行时，用cout\u0026lt;\u0026lt;......\u0026lt;\u0026lt; endl 与\u0026quot;\\n\u0026quot; 都可以，这是初级的认识。但二者有小小的区别，用 endl 时会刷新缓冲区，使得栈中的东西刷新一次，但用 \u0026ldquo;\\n\u0026rdquo; 不会刷新，它只会换行，栈内数据没有变化。但一般情况，二者的区别是很小的，建议用 endl 来换行。\n1 std::cout \u0026lt;\u0026lt; std::endl; 相当于:\n1 std::cout \u0026lt;\u0026lt; \u0026#39;\\n\u0026#39; \u0026lt;\u0026lt; std::flush; 或者\n1 std::cout \u0026lt;\u0026lt; \u0026#39;\\n\u0026#39;; std::fflush(stdout); endl 除了写 '\\n' 之外，还调用 flush 函数，刷新缓冲区，把缓冲区里的数据写入文件或屏幕。考虑效率就用 '\\n'。\n一般情况下，不加endl大多数情况下，也能正常输出，是因为在系统较为空闲时候，会查看缓存区的内容，如果发现新的内容，便进行输出。但是你并不清楚，系统什么时候输出，什么时候不输出，与系统自身的运行状况有关。而刷新缓存区，是强制性的，绝对性的输出，不取决于系统运行状况。所以正如《C++ Primer》书中所写，为了避免出现没有刷新输出流的情况发生，在使用打印语句来调试程序时，一定要加入 endl或 flush 操纵符。\n这里可能会想到，以后遇到这类问题，干脆直接都使用 endl，不用 \\n 不就好了吗？\n也不是，要知道，endl会不停地刷新输出流，频繁的操作会降低程序的运行效率，这也是C++标准库对流的输入/输出操作使用缓冲区的原因。没有必要刷新输出流的时候应尽量使用 \\n，比如对于无缓冲的流 cerr，就可以直接使用 \\n。\n头文件里的 \u0026quot; \u0026quot; 与 \u0026lt; \u0026gt; \u0026lt;\u0026gt; 默认去系统目录中找头文件。像标准的 C 头文件 stdio.h、stdlib.h 和 C++ 头文件 iostream、string 等用这个方法。 \u0026quot; \u0026quot; 首先在当前目录下寻找，如果找不到，再到系统目录中寻找。 这个用于 include 自定义的头文件，让系统优先使用当前目录中定义的。\n命名空间 std 所谓名称空间它是一种将库函数封装起来的方法。通过这种方法，可以避免和应用程序发生命名冲突的问题。\n如果想要使用 cin，cout 这两个 iostream对象，不仅要包含 \u0026lt;iostream\u0026gt; 头文件，还得让命名空间std内的名称曝光，即 using namespace std;\n真正的开发过程中， 尽量避免使用 using namespace std; 等直接引入整个命名空间，否则会因为命名空间污染导致很多不必要的问题， 比如自己写的某个函数，名称正好和 std 中的一样， 编译器会不知道使用哪一个， 引起编译报错， 建议使用由命名空间组合起来的全称： std::cout \u0026lt;\u0026lt; \u0026quot;Hello World\u0026quot; \u0026lt;\u0026lt; std::endl;\nsystem(\u0026ldquo;pause\u0026rdquo;) 包含头文件 stdlib.h，并在主程序中加入 system(\u0026quot;pause\u0026quot;); 可以在程序运行完以后使黑框暂停显示，等待输入，而不是闪退。linux环境下运行该程序需去掉该语句。\ncout 与 printf() cout 流速度较慢，如果速度过慢可以用 \u0026lt;stdio.h\u0026gt; 库中的 printf() 格式化输出函数，不需要 using namespace std;。但注意 printf() 中不能使用 endl。printf 是函数。cout是ostream对象，和 \u0026laquo; 配合使用。如果 printf 碰到不认识的类型就没办法了，而cout可以重载进行扩展。\nmain函数与命令行参数 一个程序的main()函数可以包括两个参数\n第一个参数的类型为int型； 第二个参数为字符串数组。 通常情况下，将第一个参数命名为argc，第二个参数为argv（当然参数名字可以换）。由于字符串数组有两种表达方式，因此，main函数存在两种书写方法：\n1 2 3 int main(int argc, char* argv[])//这里使用char* argv[] int main(int argc, char** argv)//这里使用char **argv int argc：表示字符串的数量，操作系统会自动根据第二个参数传入数字，程序员不用管，只需要正确使用即可。若用户输入N个字符串，那么argc= N + 1；因为 argv[0] 为程序的路径。\nchar* argv[]：字符串数组，即多个字符串。为用户输入的一系列字符串，字符串之间以空格间隔，形式为：str1 str2 str3 在linux下，若存在可执行文件a.out，则运行该程序命令为：\n1 ./a.out str1 str2 str3 预处理、编译与链接 预处理： 预处理也称为预编译，它为编译做准备工作，主要进行代码文本的替换，用于处理#开头的指令 。\n编译：编译是将编译好的源程序*.cpp文件翻译成二进制目标代码的过程。编译过程是使用C++提供的编译程序完成的，该过程会检查程序语法错误、函数变量的声明是否正确。正确的源程序文件经过编译在磁盘上生成目标文件（windows上是*.obj，linux上是*.o）。\n链接：链接将编译生成的各个目标程序模块（一个或者多个）及系统或者第三方提供的库函数*.lib链接在一起，生成可以在操作系统上直接运行的可执行文件（windows上的*.exe）\n安装 g++\n1 sudo apt-get install g++ build-essential 将源文件hello.cpp编译成可执行文件hello\n1 g++ hello.cpp -o hello 运行可执行文件\n1 ./hello 如果省略-o hello也是没问题的。由于命令行中未指定可执行程序的文件名，编译器采用默认的 a.out。程序可以这样来运行：\n1 ./a.out 如果是多个 C++代码文件，如f1.cpp，f2.cpp，编译命令如下：\n1 g++ f1.cpp f2.cpp -o myexec 则会生成一个名为myexec的可执行文件。\n静态链接和动态链接 要生成可执行文件，必须经历两个阶段，即编译、链接。\n在链接过程中，静态链接和动态链接就出现了区别。静态链接的过程就已经把要链接的内容已经链接到了生成的可执行文件中，就算你在去把静态库删除也不会影响可执行程序的执行；而动态链接这个过程却没有把内容链接进去，而是在执行的过程中，再去找要链接的内容，生成的可执行文件中并没有要链接的内容，所以当你删除动态库时，可执行程序就不能运行。所以动态链接生成的可执行文件要比静态链接生成的文件要小一些。\n各自的优缺点：\n静态链接库执行速度比动态链接库快。（执行过程不需要找链接的内容）\n动态链接库更节省内存。（未写入要链接的内容）\n深入浅出静态链接和动态链接\niostream 头文件 函数和描述 \u0026lt;iostream\u0026gt; 该文件定义了 cin、cout、cerr 和 clog 对象，分别对应于标准输入流、标准输出流、非缓冲标准错误流和缓冲标准错误流。 \u0026lt;iomanip\u0026gt; 该文件通过所谓的参数化的流操纵器（比如 setw 和 setprecision），来声明对执行标准化 I/O 有用的服务。 \u0026lt;fstream\u0026gt; 该文件为用户控制的文件处理声明服务。 标准输入流 cin\n1 2 3 4 5 6 char name[50]; short age; cout \u0026lt;\u0026lt; \u0026#34;请输入您的名称与年龄： \u0026#34;; cin \u0026gt;\u0026gt; name \u0026gt;\u0026gt; age; //C++ 编译器根据要输入值的数据类型，选择合适的流提取运算符来提取值，并把它存储在给定的变量中。 //流提取运算符 \u0026gt;\u0026gt; 在一个语句中可以多次使用 标准输出流 cout\n1 2 char str[] = \u0026#34;Hello C++\u0026#34;; cout \u0026lt;\u0026lt; \u0026#34;Value of str is : \u0026#34; \u0026lt;\u0026lt; str \u0026lt;\u0026lt; endl; 标准错误流 cerr\ncerr 对象附属到标准错误设备，通常也是显示屏，但是 cerr 对象是非缓冲的，且每个流插入到 cerr 都会立即输出。\n1 2 char str[] = \u0026#34;Unable to read....\u0026#34;; cerr \u0026lt;\u0026lt; \u0026#34;Error message : \u0026#34; \u0026lt;\u0026lt; str \u0026lt;\u0026lt; endl; 标准日志流 clog\nclog 对象附属到标准错误设备，通常也是显示屏，但是 clog 对象是缓冲的。这意味着每个流插入到 clog 都会先存储在缓冲在，直到缓冲填满或者缓冲区刷新时才会输出。\n1 2 char str[] = \u0026#34;Unable to read....\u0026#34;; clog \u0026lt;\u0026lt; \u0026#34;Error message : \u0026#34; \u0026lt;\u0026lt; str \u0026lt;\u0026lt; endl; 1 2 3 4 5 6 7 8 #include \u0026lt;iostream\u0026gt; using namespace std; int main() { cout \u0026lt;\u0026lt; \u0026#34;cout\u0026#34; \u0026lt;\u0026lt; endl; cerr \u0026lt;\u0026lt; \u0026#34;cerr\u0026#34; \u0026lt;\u0026lt; endl; return 0; } linux下命令行输入：\n1 2 g++ main.cpp -o a ./a \u0026gt;\u0026gt; test.log 终端输出“cerr”，\n打开test.log，里面只有一行字符串“cout”。\ncout默认情况下是在终端显示器输出，cout流在内存中开辟了一个缓冲区，用来存放流中的数据，当向cout流插入一个endl，不论缓冲区是否满了，都立即输出流中所有数据，然后插入一个换行符。cout可以被重定向到文件。\ncerr不经过缓冲而直接输出，一般用于迅速输出出错信息，是标准错误，默认情况下被关联到标准输出流，但它不被缓冲，也就说错误消息可以直接发送到显示器，而无需等到缓冲区或者新的换行符时，才被显示。不被重定向。\n有时程序调用导致栈被用完了，此时如果使用cout 会导致无内存输出。使用cerr 会在任何情况下输出错误信息。 不被缓冲就是你打一个字符就马上在显示器显示，而不是等到endl才打印。 clog流也是标准错误流，作用和cerr一样，区别在于cerr不经过缓冲区，直接向显示器输出信息，而clog中的信息存放在缓冲区，缓冲区满或者遇到endl时才输出。clog用的少。\n变量 勿混用带符号类型和无符号类型 一个算术表达式中既有无符号又有有符号时，如int，那个int就会转换为无符号数\n1 2 3 4 unsigned u = 10; int i = -42; std::cout \u0026lt;\u0026lt; i + i \u0026lt;\u0026lt; std::endl; // 输出-84 std::cout \u0026lt;\u0026lt; u + i \u0026lt;\u0026lt; std::endl; // 如果int占32位，输出4294967264 无符号数不会小于0这一事实关系到循环的写法 【PRIMER 34】\n1 2 3 // WRONG: u can never be less than 0; the condition will always succeed for (unsigned u = 10; u \u0026gt;= 0; --u) std::cout \u0026lt;\u0026lt; u \u0026lt;\u0026lt; std::endl; 当u等于0时，\u0026ndash;u的结果将会是4294967295。一种解决办法是用while语句来代替for语句，前者可以在输出变量前先减去1。\n1 2 3 4 5 6 unsigned u = 11; // start the loop one past the first element we want to print while (u \u0026gt; 0) { --u; // decrement first, so that the last iteration will print 0 std::cout \u0026lt;\u0026lt; u \u0026lt;\u0026lt; std::endl; } 初始化 初始化不等于赋值（assignment）。初始化的含义是创建变量时赋予其一个初始值，而赋值的含义是把对象的当前值擦除，再用一个新值来替代。【PRIMER 39】\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 int a(5); // 构造函数语法，比如复数需要初始化两个值 complex\u0026lt;double\u0026gt; purei(0, 7); int b = 6; // C 风格的运算符（=）初始化 //关于指针 int arr[5] = {1, 2, 3, 4, 5}; int *p = arr; // 合法，数组名即首地址 cout \u0026lt;\u0026lt; p[1] \u0026lt;\u0026lt; endl; // 如果要对数组求址，就需要定义一个数组指针，指向一个包含5个元素的数组 int(*pa)[5] = \u0026amp;arr; cout \u0026lt;\u0026lt; \u0026#34;arr[0] = \u0026#34; \u0026lt;\u0026lt; **pa \u0026lt;\u0026lt; \u0026#34;, arr[2] = \u0026#34; \u0026lt;\u0026lt; (*pa)[2] \u0026lt;\u0026lt; endl; cout \u0026lt;\u0026lt; \u0026#34;p[1] - [p0] = \u0026#34; \u0026lt;\u0026lt; pa[1] - pa[0] \u0026lt;\u0026lt; endl; // 输出： // arr[0] = 1, arr[2] = 3 // p[1] - [p0] = 5，表明数组指针包含 5 个元素 vector\u0026lt;int\u0026gt; vec(arr, arr + 5); vector\u0026lt;int\u0026gt; *pv = \u0026amp;vec; // 合法 //而 vector\u0026lt;int\u0026gt; *pv = vec; 不合法，因为 vec 是 vector 型对象，它的名字不是首地址 cout \u0026lt;\u0026lt; vec[1] \u0026lt;\u0026lt; endl; // 注意与数组的差别 new 与 vector 定义多维变长数组并初始化，查看code\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 #include \u0026lt;iostream\u0026gt; #include \u0026lt;vector\u0026gt; #include \u0026lt;algorithm\u0026gt; using namespace std; int main() { int row = 2; int col = 3; int **p = new int*[row]; for (int i = 0; i \u0026lt; row; ++i) { p[i] = new int[col]; for (int j = 0; j \u0026lt; col; ++j) { p[i][j] = i * col + j; } } for (int i = 0; i \u0026lt; row; ++i) for (int j = 0; j \u0026lt; col; ++j) printf(\u0026#34;p[%d][%d] = %d\\n\u0026#34;, i, j, p[i][j]); cout \u0026lt;\u0026lt; \u0026#34;--------------------\u0026#34; \u0026lt;\u0026lt; endl; int *p1 = new int[5]; // 未初始化， p 指向含 5 的整数的堆内存空间的首地址 cout \u0026lt;\u0026lt; p1[0] \u0026lt;\u0026lt; \u0026#34; \u0026#34; \u0026lt;\u0026lt; p1[1] \u0026lt;\u0026lt; \u0026#34; \u0026#34; \u0026lt;\u0026lt; *p1 \u0026lt;\u0026lt; endl; int *p2 = new int(5); // 初始化一个值，p 指向一个数 cout \u0026lt;\u0026lt; p2[0] \u0026lt;\u0026lt; \u0026#34; \u0026#34; \u0026lt;\u0026lt; p2[1] \u0026lt;\u0026lt; \u0026#34; \u0026#34; \u0026lt;\u0026lt; *p2 \u0026lt;\u0026lt; endl; cout \u0026lt;\u0026lt; \u0026#34;----------------------\u0026#34; \u0026lt;\u0026lt; endl; int a = 2, b = 2, c = 3; vector\u0026lt;vector\u0026lt;vector\u0026lt;int\u0026gt; \u0026gt; \u0026gt; v(a, vector\u0026lt;vector\u0026lt;int\u0026gt; \u0026gt;(b, vector\u0026lt;int\u0026gt;(c, 5))); for (int i = 0; i \u0026lt; v.size(); ++i) for (int j = 0; j \u0026lt; v[0].size(); ++j) for (int k = 0; k \u0026lt; v[0][0].size(); ++k) printf(\u0026#34;v[%d][%d][%d] = %d\\n\u0026#34;, i, j, k, v[i][j][k]); cout \u0026lt;\u0026lt; \u0026#34;-------------------------\u0026#34; \u0026lt;\u0026lt; endl; vector\u0026lt;int\u0026gt; v1(c, 6); vector\u0026lt;vector\u0026lt;int\u0026gt; \u0026gt;v2(b, v1); vector\u0026lt;vector\u0026lt;vector\u0026lt;int\u0026gt; \u0026gt; \u0026gt;v3(a, v2); for (int i = 0; i \u0026lt; v.size(); ++i) for (int j = 0; j \u0026lt; v[0].size(); ++j) for (int k = 0; k \u0026lt; v[0][0].size(); ++k) printf(\u0026#34;v3[%d][%d][%d] = %d\\n\u0026#34;, i, j, k, v3[i][j][k]); cout \u0026lt;\u0026lt; \u0026#34;-------------------------\u0026#34; \u0026lt;\u0026lt; endl; int* pmalloc = (int *)malloc(sizeof(int) * row * col); for (int i = 0; i \u0026lt; row; ++i) for (int j = 0; j \u0026lt; col; ++j) pmalloc[i * col + j] = i * col + j; for (int i = 0; i \u0026lt; row; ++i) for (int j = 0; j \u0026lt; col; ++j) printf(\u0026#34;pmalloc[%d * %d + %d] = %d\\n\u0026#34;, i, col, j, pmalloc[i * col + j]); free(pmalloc); } 逗号表达式 1 2 3 4 5 6 7 8 9 10 // 【例 1】 cout \u0026lt;\u0026lt; a_string \u0026lt;\u0026lt; (cnt % line_size ? \u0026#39; \u0026#39; : \u0026#39;\\n\u0026#39;); // 若某一行计数不超过 line_size，就打印空格，否则换行。用来限制某一行字符打印的个数 //【ESS 11】 // 【例 2】 fun(f2(v1,v2),(v3,v4,v5),(v6,max(v7,v8))); // fun 函数的实参个数有几个？ // 答：三个。 // 第一个是 f2 的返回值，第二个是逗号表达式(v3,v4,v5)的值，第三个是逗号表达式(v6,max(v7,v8))的值。 指针 如果指针不指向任何对象，则【提领】操作（也可称为【解引用】，即取指针指向的内容）会导致未知的执行结果。这意味着在使用指针时，必须在提领前确定它的确指向某对象。\n一个未指向任何对象的指针，其地址为0，也被称为 nullptr 指针。我们可以在定义阶段便初始化指针，令其值为 0.\n1 2 3 4 5 int *p = 0; // 初始化指针地址为0 if (p \u0026amp;\u0026amp; *p != 1024) // 如果 p 地址不为零，才能有 *p 操作 *p = 1024; // 当 p 的地址为 0，直接提领，会报错 //【ESS 28】 野指针 指的是没有被初始化过的指针。指针变量未初始化时不会自动成为 nullptr，而是一个随机值。\n1 2 3 4 5 int main() { int* p; // 未初始化 std::cout\u0026lt;\u0026lt; *p \u0026lt;\u0026lt; std::endl; // 未初始化就被使用 return 0; } 因此，为了防止出错，对于指针初始化时都是赋值为 nullptr，这样在使用时编译器就会直接报错，产生非法内存访问。\n悬空指针 悬空指针，指针最初指向的内存已经被释放了的一种指针。（指针操作超越变量的作用域，比如函数返回栈内存的指针或引用）\n1 2 3 4 5 6 int main() { int * p = nullptr; int* p2 = new int; p = p2; delete p2; } 此时 p和p2就是悬空指针，指向的内存已经被释放。继续使用这两个指针，行为不可预料。需要设置为p=p2=nullptr。此时再使用，编译器会直接保错。\n野指针和悬空指针，无法通过简单地判断是否为 nullptr 避免，所以要习惯在初始化时赋值或析构时赋为nullptr。\nvoid*是一种特殊的指针类型，可以存放任意对象的地址，但不能直接操作void*指针所指的对象。\n指针与数组名的区别 修改内容上的差别：\n1 2 3 4 char a[] = \u0026#34;hello\u0026#34;; a[0] = \u0026#39;H\u0026#39;; char *p = \u0026#34;world\u0026#34;; // p 指向常量字符串，该字符串存储在文字常量区，不可更改 // p[0] = \u0026#34;W\u0026#34; // 所以这个赋值有问题 1 2 3 4 5 6 7 8 9 10 int main() { char a[] = \u0026#34;hello\u0026#34;; char *p = a; // 这样让指针指向数组 a，而非常量字符串，就可以修改了 p[0] = \u0026#39;H\u0026#39;; a[1] = \u0026#39;E\u0026#39;; printf(\u0026#34;%d\u0026#34;, sizeof(p)); // 64 位机器 std::cout \u0026lt;\u0026lt; p \u0026lt;\u0026lt; std::endl; return 0; } //输出：8HEllo sizeof\n1 2 3 4 5 6 7 8 sizeof(a); // 输出6，包含 \u0026#39;\\0\u0026#39; sizeof(p); // 64 位机器输出 8 /* 指针类型对象占用内存为一个机器字的长度： 这意味着在16位cpu上是16位 = 2字节 32位cpu上是32位 = 4字节 64位cpu上就是64位也就是8字节了 */ 数组指针与指针数组 1 2 3 4 5 6 7 8 9 10 11 12 13 type (*p)[]; // 数组指针 /* type a[]，a 是一个数组，数组内元素都是 type 类型，将 a 换成 (*p)， 可以理解为 （*p）是一个数组，数组内元素都是 type 类型，那么 p 就是指向这样的数组的指针，即数组指针。 */ type *p[]; // 指针数组 /* type *p[]即(type *)p[]，则 p 是一个 type* 类型的数组(类比int a[10]，a 是 int 型数组） 即 p 是一个数组，数组内元素都是指针（ type *） */ // 在后文的介绍中使用右左法则，更容易理解 稍微复杂一些的指针数组：\n1 2 3 4 5 6 7 8 9 const int seq_cnt = 6; vector\u0026lt;int\u0026gt; *seq_addrs[seq_cnt] = { \u0026amp;fibonacci, \u0026amp;lucas, \u0026amp;pell, \u0026amp;triangular, \u0026amp;square, \u0026amp;pentagonal }; // seq_addrs 是一个数组，存储 vector\u0026lt;int\u0026gt; * 型的指针， // seq_addrs[0] 的内容为指针，该指针指向 fibonacci， // 而 fibonacci 的类型为 vector\u0026lt;int\u0026gt;。 //【ESS 29】 指针函数与函数指针 指针函数：返回类型是指针的函数，如\n1 2 3 4 5 6 char *StrCat(char *ptr1, char *ptr2) { char *p; do something; return p; } 函数指针：指向函数的指针，如\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 #include \u0026lt;stdio.h\u0026gt; int max(int x, int y) { return x \u0026gt; y? x: y; } int main() { // int max(int x, int y); int (*ptr)(int, int); ptr = max; int max_num = (*ptr)(12, 18); // int max_num = ptr(12, 18);也是对的 printf(\u0026#34;%d\u0026#34;, max_num); return 0; } // 打印 18。 1 2 int (*ptr)(); // “()” 表明该指针指向函数，函数返回值为 int int (*ptr)[3]; // “[]” 表明该指针指向一维数组，该数组里包含三个元素，每一个元素都是int类型。 数组名指向了内存中一段连续的存储区域，可以通过数组名的指针形式去访问，也可以定义一个相同类型的指针变量指向这段内存的起始地址，从而通过指针变量去引用数组元素。\n每一个函数占用一段内存区域，而函数名就是指向函数所占内存区的起始地址的函数指针（地址常量），故函数指针解引用与不解引用没有区别 。通过引用函数名这个函数指针让正在运行的程序转向该入口地址执行函数的函数体，也可以把函数的入口地址赋给一个指针变量，使该指针变量指向该函数。\n复杂指针声明 函数指针数组\n1 2 3 4 const vector\u0026lt;int\u0026gt;* (*seq_array[])(int) = { fibon_seq, lucas_seq, pell_seq, triang_seq, square_seq, pent_seq }; seq_array 是一个可以持有六个函数指针的指针数组，第一个元素指向函数 fibon_seq()，该函数原型为 const vector\u0026lt;int\u0026gt; *fibon_seq(int);。\n【ESS 62】\n解读复杂指针使用右左法则：首先从未定义的标识符所在的圆括号看起，然后往右看，再往左看。每当遇到圆括号就调转阅读方向。一旦解析完圆括号里的东西，就跳出圆括号。重复这个过程，直到整个声明解析完毕。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 int (*func)(int *p, int (*f)(int*)); // func左边有一个*表明func是一个指针，跳出圆括号看右边，右边有括号，说明func是一个函数指针， // 指向的函数接收两个形参，分别是整型指针 int * 和函数指针 int (*f)(int*)，返回值为 int。 int (*func[5])(int *p); // func 是一个数组，含5个元素，左边*号，表明 func 是一个指针数组（由于[]优先级高于*，func先跟[]结合，然后*修饰func[5]，故该数组的元素都是指针）。 //再往右看，是括号，说明 func 里的指针是函数指针，函数指针所指向的函数接收 int * 型参数并返回 int。 int (*(*func)[5])(int *p); // func 是一个指针，指向含有 5 个元素的数组，数组里的元素都是指针，而且都是函数指针， // 函数指针指向的函数接收 int * 型形参并返回 int。 int (*(*func)(int *p))[5]; // func 是一个指针，该指针指向一个函数，该函数接收 int * 型参数返回一个指针， // 返回的指针指向一个数组，该数组含有 5 个元素，每一个元素都是 int 型。 指针(pointer)与引用(reference) 1 2 3 int ival = 1024; int *pi = \u0026amp;ival; // pointer int \u0026amp;rval = ival; // reference 引用是别名，而指针是地址。指针可以被赋值，以指向另一个不同的对象，而引用只能在定义时被初始化一次，以后不能修改，但引用的那个对象内容却可以改变。可以把引用理解为指针常量，而普通指针为指针变量。\n引用不能为空，指针可以为空。故在使用上，指针可能（也可能不）指向一个对象，提领时一定要先确定其值非 0。而引用，则必定会代表某个对象，所以不需要作此检查。\n从内存分配上来看，程序为指针变量分配内存区域，而不为引用分配内存区域。\n引用使用时无需解引用(*)，指针需要解引用；\n引用没有 const，指针有 const；\n“sizeof 引用” 得到的是所指向的变量(对象)的大小，而 “sizeof 指针” 得到的是指针本身的大小；\n指针可以有多级，但是引用只能是一级（int **p；合法 而 int \u0026amp;\u0026amp;a是不合法的）\n指针和引用的自增(++)运算意义不一样；\n1 2 3 4 5 6 int a = 0; int \u0026amp;b = a; int *p = \u0026amp;a; b++; // 相当于 a++; b 只是 a 的一个别名，和 a 一样使用。 p++; // p 指向 a 后面的内存 (*p)++; // 相当于 a++ （在二进制层面，引用一般是通过指针来实现的，只不过编译器帮我们完成了转换。总的来说，引用既具有指针的效率，又具有变量使用的方便性和直观性。）\n【ESS 46，47】\n引用作为函数参数 传递引用给函数与传递指针给函数的效果是一样的。这时，被调函数的形参就成为原来主调函数中的实参变量或对象的一个别名来使用，所以在被调函数中对形参变量的操作就是对其相应的目标对象（在主调函数中）的操作。\n使用引用传递函数的参数，在内存中并没有产生实参的副本，它是直接对实参操作；而使用一般变量传递函数的参数，当发生函数调用时，需要给形参分配临时存储单元，形参变量是实参变量的副本；如果传递的是对象，还将调用拷贝构造函数。因此，当参数传递的数据较大时，用引用比用一般变量传递参数的效率和所占空间都好。\n使用指针作为函数的参数虽然也能达到与使用引用的效果，但是，在被调函数中同样要给形参分配存储单元，且需要重复使用 \u0026ldquo;*指针变量名\u0026rdquo; 的形式进行运算，这很容易产生错误且程序的可读性较差；另一方面，在主调函数的调用点处，必须用变量的地址作为实参。而引用更容易使用，更清晰。\n常引用作为函数参数 如果既要利用引用提高程序的效率，又要保护传递给函数的数据不在函数中被改变，就应使用常引用\n1 2 3 4 5 6 7 8 9 10 11 12 13 void foo(const string \u0026amp;s) { cout \u0026lt;\u0026lt; s \u0026lt;\u0026lt; endl; } // 如果形参里的 const 去掉，程序就报错， // 因为 ss 与 \u0026#34;world!\u0026#34; 都是常量，你不能把一个 const 类型转换成非 const 类型。 // 所以 foo() 形参必定要用 const 修饰。 int main() { const string ss(\u0026#34;hello \u0026#34;); foo(ss); foo(\u0026#34;world!\u0026#34;); } 对于常量类型的变量，其引用也必须是常量类型的；对于非常量类型的变量，其引用可以是非常量的，也可以是常量的。但是要注意，无论什么情况都不能使用常量引用修改其引用的变量的值。\n函数返回引用与返回值 返回引用的好处：在内存中不产生被返回值的副本。\n同时注意，正是因为这点原因，所以返回一个局部变量的引用是不可取的。因为随着该局部变量生存期的结束，相应的引用也会失效，产生 runtime error!\n【注意】\n最好不要返回局部变量的引用； 最好不要返回函数内部 new 分配的内存的引用； 流操作符重载返回值应为引用； 全局变量和局部静态变量的返回值可以是引用； 可以返回类成员的引用； 指针运算 *\u0026amp;p和\u0026amp;*p \u0026amp;：取出变量的存储地址。对指针变量 p，\u0026amp;p 取指针变量 p 所占用内存的地址，可以说是二级指针。 *：引用指针所指向单元的内容。 1 2 3 4 1、*\u0026amp;p 等价于*(\u0026amp;p) 2、\u0026amp;*p 等价于\u0026amp;(*p) p 是 int 变量，那么 *\u0026amp;p = p，而 \u0026amp;*p 是非法的。因为 *p 非法 p 是 int* 变量，那么 *\u0026amp;p = p，\u0026amp;*p = p，都是 p p+(或-)n 指针加减一个数，是指该指针上移或下移n个数据之后的内存地址。即：\n1 p +(或-) n * sizeof(type); *p++，*(p++)， (*p)++，*++p，++*p *p++ 和 *(p++) 没有区别，因为 ++ 在变量之后，运算得先用再自增，所以先执行*p，p再自增。这又与 (*p)++ 有区别，这里面先 *p，*p 再自增而不是 p 自增。\n1 2 3 4 5 // 一个 ++ 在变量后，先用再自增的例子。 int a = 3; int b = 3; printf(\u0026#34;%d\u0026#34;,a++); //打印3,但a值已经变成4了。先用a，a再自增，所以就是先打印3,打印完再自增。 printf(\u0026#34;%d\u0026#34;,++b); //先自增，自增完，再用。 *++p 等价于 *(++p)，p 先自增，自增完后再取 *p 的值，即取下一个元素的值，而不是当前元素。 ++*p，*p自增。\ni++ 与 ++i 的效率 对于内置数据类型，两者差别不大； 对于自定义数据类型（如类），++i 返回对象的引用，而 i++ 返回对象的值，导致较大的复制开销，因此效率低。 前缀++和后缀++的原型为：【PRIMER 501】\n1 2 3 // class C; C\u0026amp; C::operator++(); // 前缀运算符返回递增或递减后对象的引用 C C::operator++(int); // 后缀运算符返回对象的值。为了与前缀运算符作区分，后缀版本接受一个（不被使用，编译器默认设为0）int类型的形参。 sizeof sizeof 计算普通变量与指针所占空间的大小 1 2 3 4 5 6 7 8 9 10 // 在32 位操作系统上，用 sizeof 计算下列变量所占空间的大小 // 32位，char:1，short:2, int:4，long:4 char str[] = \u0026#34;hello\u0026#34;; // 6 char *p = str; // 4 int n = 10; // 4 void fun(char str[100]) { sizeof(str);\t// 4，函数形参对传入的数组是按照指针处理的，在函数体内可以通过修改 str 修改函数外的数组 } void *p = malloc(100);\t// 4, p 指向 100 个字节的堆内存，但本质上还是指针。 sizeof 计算空类的大小 1 2 3 class A {}; cout \u0026lt;\u0026lt; sizeof(A) \u0026lt;\u0026lt; endl;\t// 1 // 空类不包含任何信息，本来求 sizeof 的时候应该是 0，但是当我们声明该类型的实例的时候，它必须在内存中占用空间，否则无法使用。至于占多少空间由编译器来决定，使用 gcc version 7.5.0 (Ubuntu 7.5.0-3ubuntu1~18.04) 编译打印 1。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 class A { public: A() {}; ~A() {}; // virtual void f() {}; //【1】 // static int a; // 【2】 }; cout \u0026lt;\u0026lt; sizeof(A) \u0026lt;\u0026lt; endl; // 注释【1】【2】，无虚函数，依旧占用空间 1 字节 // 只注释【1】，因为 static 变量不属于类，且无虚函数，依旧占用空间 1 字节 // 如果去掉【1】处注释，含虚函数，得占用内存 4。有虚函数时，默认有一个指针指向虚函数表。该指针占 4 字节。 // 普通成员函数不占用类的空间。类的函数是该类所有实例共享的，调用时通过隐藏的 this 指针和类的实例相关联， // 普通成员函数代码编译后存储在程序代码区，根本就不在类实例中，所以不占实例空间。 sizeof 计算类对象与结构体、联合体所占空间的大小 在 32 位操作系统上，占用空间 char:1，short:2, int:4，long:4\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 class A\t// 1 { public: char ch; }; class B\t// 4 + 2 + 填充2 = 8 { public: int i; short j; }; class C\t// 4 + 2 + 1 + 1 = 8 { public: int i; short j; char c1; char c2; }; class D\t// 1 + 填充3 + 4 + 1 + 填充1 + 2 = 12 { public: char c1; int i; char c2; short j; }; // 【注意】类 C，D 的区别在于变量定义的顺序不一样 D d; printf(\u0026#34;%x, %x, %x, %x, %x\\n\u0026#34;, \u0026amp;d, \u0026amp;d.c1, \u0026amp;d.i, \u0026amp;d.c2, \u0026amp;d.j); // 输出：12ffed4, 12ffed4, 12ffed8, 12ffedc, 12ffede 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 // 注意 S1 与 S2 也就是成员变量定义时顺序不一样而已 struct S1\t// 4 + 1 + 1 + 填充2 = 8 { int a1; char c1; char c2; }; struct S2\t// 1 + 填充3 + 4 + 1 + 填充3 = 12 { char c1; int a1; char c2; }; S2 s2; printf(\u0026#34;%x, %x, %x, %x\\n\u0026#34;, \u0026amp;s2, \u0026amp;s2.c1, \u0026amp;s2.a1, \u0026amp;s2.c2); // 输出：10ff794, 10ff794, 10ff798, 10ff79c 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 union u1\t// 8 { double a; int b; }; union u2\t// 13，对齐方式是1，13 是 1 的整数倍 { char a[13]; char b; }; union u3\t// 16，对齐方式是 4，16 是 4 的整数倍 { char a[13]; int b; }； 这一切都与字节对齐有关：\n结构体变量的首地址能够被其最宽基本类型成员的大小所整除； 结构体每一个成员相对于结构体首地址的偏移量都是成员大小的整数倍，如有需要，编译器会在成员之间加上填充字节； 结构体的总大小为结构体最宽基本数据类型成员大小的整数倍，如有需要，编译器会在最末一个成员之后加上填充字节。 联合体（共用体），类同理。\nsizeof 与 strlen 区别 sizeof 是操作符，strlen 是函数；\n数组做 sizeof 参数不退化，传递给 strlen 就退化成指针（函数的形参将数组按指针处理）；\n1 2 3 4 5 6 7 8 9 10 char *s = \u0026#34;hello\u0026#34;; char str[20] = \u0026#34;hello\u0026#34;; cout \u0026lt;\u0026lt; sizeof(s) \u0026lt;\u0026lt; \u0026#39; \u0026#39; \u0026lt;\u0026lt; sizeof(str) \u0026lt;\u0026lt; endl; // sizeof 对字符指针和字符数组的处理不同 // cout \u0026lt;\u0026lt; sizeof s \u0026lt;\u0026lt; \u0026#39; \u0026#39; \u0026lt;\u0026lt; sizeof str \u0026lt;\u0026lt; endl; // sizeof 后面不加括号也正确，因为 sizeof 是运算符不是函数，但用 sizeof 求类型大小，必须加括号，比如 sizeof(int) cout \u0026lt;\u0026lt; strlen(s) \u0026lt;\u0026lt; \u0026#39; \u0026#39; \u0026lt;\u0026lt; strlen(str) \u0026lt;\u0026lt; endl; /* 打印 4 20 5 5 */ sizeof 在编译阶段就计算出来了，所以可以定义数组的维度，而strlen是在运行时候才计算出来；\nstrcpy 与 memcpy 区别 复制的内容不同。strcpy 只能复制字符串，而 memcpy 可以复制任意内容，例如字符数组、整型、结构体、类等。 复制的方法不同。strcpy 不需要指定长度，它遇到被复制字符的结束符 \u0026ldquo;\\0\u0026rdquo; 才结束，所以容易溢出。memcpy 则是根据其第 3 个参数决定复制的长度。 用途不同。通常在复制字符串时用 strcpy，而需要复制其他类型数据时则一般用 memcpy 。 作用域与生存周期 c++ 变量有两个属性非常重要：作用域和生存周期。\n花括号作用域 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 // 花括号可以看作是作用域标识符，除了在写函数时候用到，它还有一个作用是表示变量的作用域： { // 外花括号 int a = 0; {\t// 内花括号 int b = 0; a = 1; //【1】正确，对外花括号内的 a 重新赋值 } // b = 1; // 错误，b 已经被销毁了 cout \u0026lt;\u0026lt; a \u0026lt;\u0026lt; endl; /* 输出为 1。如果将【1】处 a = 1； 改成 int a = 1；此时输出为 0。 因为前者 a = 1 表明修改的是外花括号内的 a，而后者表明定义一个局部变量 a 并初始化， 内花括号的 a 屏蔽了外花括号的 a，而 cout 打印的是外花括号的 a */ } // 对于 if, while, for 在花括号里定义的变量，出了花括号就被释放了， int a = 1; for (int a = 2; a == 2; ++a) { cout \u0026lt;\u0026lt; a \u0026lt;\u0026lt; endl; //for 中定义的 a 作用域在花括号内，屏蔽 for 外定义的 a } cout \u0026lt;\u0026lt; a \u0026lt;\u0026lt; endl; // 打印外花括号的 a /* 打印 2 1 */ 【PRIMER 44】\n作用域中一旦声明了某个名字，在它所嵌套着的所有作用域中都能访问该名字。同时，允许在内层作用域中重新定义外层作用域已有的名字，此时内层作用域中新定义的名字将屏蔽外层作用域的名字。\n可以用作用域操作符::来覆盖默认的作用域规则。因为全局作用域本身并没有名字，所以当作用域操作符的左侧为空时，会向全局作用域发出请求获取作用域操作符右侧名字对应的变量。\n内存分配 一个程序将操作系统分配给其运行的内存块分为 5 个区域：\n静态区（全局区）：存放程序的全局变量和静态变量。初始化的全局变量和静态变量在一个区域， 未初始化的全局变量和未初始化的静态变量在相邻的另一块区域。程序结束后由系统释放。（在以前的C语言中，全局变量又分为初始化的和未初始化的，在C++里面没有这个区分了，他们共同占用同一块内存区。）\n堆区：存放程序的动态数据。\n栈区：存放程序的局部数据，即各个函数的参数和局部变量等。函数结束，自动释放。\n（文字）常量区：常量字符串存放的区域，程序结束后由系统释放。\n代码区：存放程序的代码，即程序中的各个函数代码块。\n1 2 3 4 5 6 7 8 9 10 11 12 int a = 0; // 全局初始化区 char *p1; // 全局未初始化区 int main() { int b; // 栈 char s[] = \u0026#34;abc\u0026#34;; // 栈 char *p2; // 栈 char *p3 = \u0026#34;123456\u0026#34;; // 字符常量 “123456\\0” 在常量区，p3 在栈上。 static int c = 0; // 全局（静态）初始化区 p1 = (char *)malloc(10); p2 = (char *)malloc(20); // 分配得来的 10 和 20 字节的区域在堆区。 strcpy(p1, \u0026#34;123456\u0026#34;); // “123456\\0” 放在文字常量区，编译器可能会将它与 p3 所指向的 \u0026#34;123456\\0\u0026#34; 优化成一个地方 } 局部变量和全局变量 局部变量也称为内部变量，它是在函数内定义的。其作用域仅限于函数内，离开该函数后再使用这种变量是非法的。\n全局变量也称为外部变量，它是在函数外部定义的变量。它不属于哪一个函数，它属于一个源程序文件。其作用域是整个源程序。在函数内部，局部变量可以屏蔽全局变量。如果一个全局变量用 static 修饰，它就是静态全局变量，它的作用域是该文件范围（称为文件作用域，即其它文件不能使用它）\n操作系统和编译器是怎么变量是全局还是局部 操作系统和编译器，可能是通过内存分配的位置来知道的，全局变量分配在全局数据段并且在程序开始运行的时候被加载。局部变量则分配在堆栈里面。\n静态存储与动态存储 变量的生存周期只与变量的存储位置（存储类别）有关。可以分为：\n静态存储方式（在程序运行期间，系统对变量分配固定的存储空间） 动态存储方式（在程序运行期间，系统对变量动态（不固定）的分配存储空间） 而变量的存储类别可以分为静态存储和动态存储\nauto 自动变量(动态存储方式) static 静态变量(静态存储方式) register 寄存器变量(动态存储方式) extern 外部变量(静态存储方式) C++变量保存在堆还是栈？ 如果对象是函数内的非静态局部变量，则对象，对象的成员变量保存在栈区。 如果对象是全局变量，则对象，对象的成员变量保存在静态区。 如果对象是函数内的静态局部变量，则对象，对象的成员变量保存在静态区。 如果对象是 new 出来的，则对象，对象的成员变量保存在堆区。 1 2 3 4 5 6 void foo() { int* p = new int[5]; } // 在栈内存中存放了一个指向一块堆内存的指针 p // 程序会先确定在堆中分配内存的大小，然后调用 operator new 分配内存 // 然后返回这块内存的首地址，存入栈中 堆与栈的效率 栈是程序启动的时候，系统分好了给你的，你自己用，系统不干预。\n堆是用的时候才向系统申请的，用完了还回去，这个申请和交还的过程开销相对就比较大了。\n堆相对于栈，效率低，多次分配（malloc/new）容易产生碎片，使用时最好结合相关操作系统（Linux、Windows、RTOS ）使用，因为系统针对内存管理有专门的优化算法，减少内存碎片。堆虽然有一定的缺点，但其最大的优点是使用灵活，而且堆容量大，一般需要申请比较大的内存块时，都会从堆中申请。\nnew 与 delete 堆内存（空闲空间）里的内存分配通过 new 表达式来完成，释放通过 delete 表达式来完成。堆内存由程序员自行管理。\n1 2 3 4 5 6 7 int *p1 = new int; // 未初始化 int *p2 = new int(1024); // 指定初值, p2 指向一个 int 对象，其值为 1024 int *p3 = new int[1024]; // 从 heap 中分配一个数组，含有1024个元素，p3 指向数组第一个元素 delete p1; delete p2; delete [] p3 // new[] 与 delete[] 要一一对应 // 如果不使用 delete，由 heap 分配而来的对象就永远不会被释放，这被称之为内存泄漏。 【ESS 49，50】\nnew/delete 与 malloc/free 关系 malloc/free 是 C/C++ 的标准库函数，new/delete 是 C++ 的运算符。它们都可用于申请动态内存和释放内存。\n对于非内部数据类型的对象而言，光用 malloc/free 无法满足动态对象的要求。对象在创建的同时要自动执行构造函数，对象在消亡之前要自动执行析构函数。由于 malloc/free 是库函数而不是运算符，不在编译器控制权限之内，不能够把执行构造函数和析构函数的任务强加于 malloc/free（malloc 只能申请内存，不能在申请内存的时候对所申请的内存进行初始化工作，而构造函数可以。free 只能释放内存，而如果析构函数设计得好的话，在释放内存的同时还可以完成额外的其他工作）。因此 C++ 语言需要一个能完成动态内存分配和初始化工作的运算符 new ，以及一个能完成清理与释放内存工作的运算符 delete 。\nnew / new[]：完成两件事，先底层调用 malloc 分配内存，然后调用构造函数（创建对象）。 delete/delete[]：也完成两件事，先调用析构函数（清理资源），然后底层调用 free 释放空间。 new 在申请内存时会自动计算所需字节数，而 malloc 则需我们自己输入申请内存空间的字节数。 malloc/free 的使用\n1 2 3 4 5 6 7 8 9 10 11 12 #include \u0026lt;iostream\u0026gt; using namespace std; int main() { int *score, num; cin \u0026gt;\u0026gt; num; if ((score = (int *)malloc(sizeof(int) * num)) == nullptr) cerr \u0026lt;\u0026lt; \u0026#34;fail\u0026#34; \u0026lt;\u0026lt; endl; else { do something; free(score); // 释放内存 } } malloc、calloc、realloc的区别 malloc与calloc的区别为1块与n块的区别\nrealloc将 ptr 指向的内存的大小增大到 size，新增加的内存块没有初始化。\n1 2 3 (type *)malloc(sizeof(type));\t// 分配一个长度为 sizeof(type) 的连续空间，且未初始化，是随机数 (type *)calloc(n, sizeof(type)); // 分配 n 块 长度为 sizeof(type) 的连续空间，初始化，均为 0。 (type *)realloc(ptr, size) // 将ptr指向的空间增大到size，新增加的内存块没有初始化。 宏 1 2 3 #define MAX(x, y) (((x) \u0026gt; (y)) ? (x) : (y)) #define POW(x) ((x) * (x)) // 为什么用括号？因为宏只是简单的字符替换 头文件 头文件的扩展名习惯上是.h，标准库例外。 函数的定义只能有一份，倒是可以有多份声明。我们不能把函数的定义放在头文件，因为一个程序的多个代码文件可能都会包含这个头文件。但只定义一份的规则有一个例外，内联函数。为了能够扩展内联函数的内容，以便在每个调用点上，编译器都取得其定义，必须将内联函数的定义放在头文件中，而不是放在各个不同程序代码文件中（如果两个函数在定义时函数名和参数列表都一样(返回类型可以不一样)，则会出错，因为重载要保证参数列表不一样）。 一个对象和变量同函数一样，也只能在程序中定义一次，因此也应该将定义放在程序代码文件中，而不是头文件中。一般地，加上 extern 就可以放在头文件中作为声明了。 1 2 3 // 如果想声明一个变量而非定义它，就在变量名前添加 extern 关键字，而且不要显式地初始化变量 extern int x; // 声明 x 而非定义 int y; // 声明并定义 y const int a = 6;就可以放入头文件中，因为 const object 就和 inline 函数一样，是”一次定义“规则下的例外。因为 const 定义一出文件外便不可见（文件作用域），这意味着可以在多个不同的文件中加以定义。\n头文件用 \u0026lt;\u0026gt; 表明此文件被认为是标准的或项目专属的头文件，编译器搜索此文件时，会先在系统默认的磁盘目录下寻找；头文件用 ” “ 表明此文件被认为是用户提供的头文件，会先在包含此文件的磁盘目录开始寻找，找不到再去系统默认的目录下寻找。\n【ESS 63，64】\n#ifndef/#define/#endif作用 防止头文件的重复包含和编译\n1 2 3 4 5 6 7 8 9 10 11 12 13 #ifndef A_H // 意思是 if not define a.h\u0026#34; 如果不存在a.h #define A_H // 就引入 a.h #include \u0026lt;math.h\u0026gt; // 引用标准库的头文件 … #include “header.h” // 引用非标准库的头文件 … void Function1(…); // 全局函数声明 … class Box // 类结构声明 { … }; #endif // 最后一句应该写 #endif，它的作用相当于 if 的反花括号 \u0026#39;}\u0026#39; extern “C” 作为C语言的扩展，C++ 保留了一部分过程式语言的特点，因而它可以定义不属于任何类的全局变量和函数。但是，C++ 毕竟是一种面向对象的设计语言，为了支持函数的重载，C++ 对全局函数的处理方式有着明显的不同。\n首先看一下 C++ 对类似C的函数是怎样编译的：\n作为面向对象的语言，C++ 为了支持函数重载，函数在被 C++ 编译后在符号库中的名字与 C 语言的不同。假如某个函数的原型为 void foo(int x, int y);，该函数被 C 编译器编译后在符号库中的名字为 _foo，而 C++ 编译器则会产生 _foo_int_int 之类的名字。_foo_int_int 这样的名字是包含了函数名以及形参，C++就是靠这种机制来实现函数重载的。 如果在 C 中连接 C++ 编译的符号时，就会因找不到符号问题而发生连接错误。\n被 extern “C” 修饰的函数或者变量是按照 C 语言方式编译和链接的，所以可以用一句话来概括 extern “C” 的真实目的：实现 C++ 与 C 的混合编程。\ntypedef 声明 可以使用 typedef 为一个已有的类型取一个新的名字。\ntypedef 可以声明各种类型名，但不能用来定义变量。用 typedef 可以声明数组类型、字符串类型，使用比较方便。\n用 typedef 只是对已经存在的类型增加一个类型名，而没有创造新的类型。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 typedef int feet;\t// 告诉编译器，feet 是 int 的另一个名称：可以理解 feet 为 int 的别名 feet distance;\t// 它创建了一个整型变量 distance typedef int A[];\t// 定义了数组类型，数组大小由初始化时候决定 typedef int B[9];\t// 定义了大小为9的数组类型，用 B 定义并初始化数组时，元素个数不应超过9 A arra = { 0, 1, 2, 3, 4 };\t// arra 长度为 5 cout \u0026lt;\u0026lt; arra[3] \u0026lt;\u0026lt; \u0026#39; \u0026#39; \u0026lt;\u0026lt; sizeof arra/sizeof arra[0] \u0026lt;\u0026lt; endl; // 打印 3 5 B arrb = { 0, 1, 2, 3, 4 }; // 实际是 {0， 1， 2， 3， 4， 0， 0， 0， 0} cout \u0026lt;\u0026lt; arrb[8] \u0026lt;\u0026lt; \u0026#39; \u0026#39; \u0026lt;\u0026lt; sizeof arrb / sizeof arrb[0] \u0026lt;\u0026lt; endl; // 打印 0 9 typedef int (*pfun)(int x, int y); // 定义一个 pfun 类型，表明一个函数指针类型 int fun(int x, int y); pfun p = fun;\t// 定义了一个 pfun 类型的函数指针，并指向函数 fun int ret = p(2, 3); typedef struct Student\t// 定义了一个 ST 类型的结构体，下次定义结构体可直接用 ST 定义， {\t// ST Lux = { 123, \u0026#39;F\u0026#39; }; int id; char sex; }ST; decltype 类型指示符 【PRIMER 62】\nC++11新增decltype类型指示符，作用是选择并返回操作数的数据类型，此过程中编译器不实际计算表达式的值。\n1 decltype(f()) sum = x; // sum has whatever type f returns decltype处理顶层const和引用的方式与auto有些不同，如果decltype使用的表达式是一个变量，则decltype返回该变量的类型（包括顶层const和引用）。\n1 2 3 4 const int ci = 0, \u0026amp;cj = ci; decltype(ci) x = 0; // x has type const int decltype(cj) y = x; // y has type const int\u0026amp; and is bound to x decltype(cj) z; // error: z is a reference and must be initialized 如果decltype使用的表达式不是一个变量，则decltype返回表达式结果对应的类型。如果表达式的内容是解引用操作，则decltype将得到引用类型。如果decltype使用的是一个不加括号的变量，则得到的结果就是该变量的类型；如果给变量加上了一层或多层括号，则decltype会得到引用类型，因为变量是一种可以作为赋值语句左值的特殊表达式。\ndecltype((var))的结果永远是引用，而decltype(var)的结果只有当var本身是一个引用时才会是引用。\n1 2 3 int i = 42; decltype((i)) d1 = i; // d1 has type int\u0026amp; decltype(i) d2 = i; // d2 has type int 枚举类型 如果一个变量只有几种可能的值，可以定义为枚举(enumeration)类型。每个枚举元素在声明时被分配一个整型值，默认从 0 开始，逐个加 1。也可以在声明时将枚举元素的值一一列举出来。\n注意\n枚举元素是常量，除了初始化时不可给它赋值。 枚举变量的值只可取列举的枚举元素值。 1 2 3 4 5 6 enum 枚举名{ 标识符[=整型常数], 标识符[=整型常数], ... 标识符[=整型常数] } 枚举变量; 如果枚举没有初始化,，即省掉 \u0026ldquo;=整型常数\u0026rdquo; 时，则从第一个标识符开始。\n1 2 3 4 5 enum color { red, green, blue } c; c = blue; // c 为枚举变量，把枚举元素 blue 赋给 c，此时 c = 2 // 若直接这样赋值 c = 2；就会报错！你只能把{ red, green, blue }赋值给 c。 // blue = 2；报错！blue 是常量而不是变量。 // 未初始化默认 red = 0, green = 1, blue = 2 若给某一个标识符赋值如 green = 5\n1 2 3 4 5 6 enum color { red, green = 5, blue } c; c = blue;\t// 6 color d;\t// d 也为枚举变量 d = red;\t// d = 0 // 部分值初始化，要满足后面的值比前面值大 1，此时 red 默认为 0 // green 初始化为 5 ，blue 要满足比 green 大 1 即 blue = 6 C结构体、C++结构体、C++类的区别 C 结构体与 C++ 结构体\nC 语言中的结构体不能为空，否则会报错 C 语言中的结构体只涉及到数据结构，而不涉及到算法，也就是说在 C 中数据结构和算法是分离的。换句话说就是 C 语言中的结构体只能定义成员变量，但是不能定义成员函数（虽然可以定义函数指针，但毕竟是指针而不是函数）。然而 C++ 中结构体既可以定义成员变量又可以定义成员函数， C++ 中的结构体和类体现了数据结构和算法的结合。 C++ 中结构体与类\n相同之处： 结构体中也可以包含函数；也可以定义 public、private、protected 数据成员；定义了结构体之后，可以用结构体名来创建对象。也就是说在 C++ 当中，结构体中可以有成员变量，可以有成员函数，可以从别的类继承，也可以被别的类继承，可以有虚函数。总的一句话：class 和 struct 的语法基本相同，从声明到使用，都很相似。 区别：对于成员访问权限和继承方式，class 中默认的是 private，而 struct 中则是 public。class 还可以用于表示模板类型，struct 则不行。 实际上C++中保留struct关键字是为了使C++编译器能够兼容C语言开发的程序\n结构体与联合体（共用体）的区别 结构和联合都是由多个不同的数据类型成员组成, 但在任何同一时刻, 联合中只存放了一个被选中的成员（所有成员共用一块地址空间）, 而结构体的所有成员都存在（不同成员的存放地址不同）。 （在 struct 中，各成员都占有自己的内存空间，它们是同时存在的。一个 struct 变量的总长度等于所有成员长度之和。在 Union 中，所有成员不能同时占用它的内存空间，它们不能同时存在。Union 变量的长度等于最长的成员的长度。） 对联合体不同成员赋值, 将会对其它成员重写, 原来成员的值就不存在了, 而对于结构的不同成员赋值是互不影响的。 类型转换 【PRIMER 142-146】\n无须程序员介入，会自动执行的类型转换叫做隐式转换（implicit conversions）。\n算术转换 （Integral Promotions）\n把一种算术类型转换成另一种算术类型叫做算术转换。\n整型提升（integral promotions）负责把小整数类型转换成较大的整数类型。\n其他隐式类型转换 （Other Implicit Conversions）\n在大多数表达式中，数组名字自动转换成指向数组首元素的指针。\n常量整数值0或字面值nullptr能转换成任意指针类型；指向任意非常量的指针能转换成void*；指向任意对象的指针能转换成const void*。\n任意一种算术类型或指针类型都能转换成布尔类型。如果指针或算术类型的值为0，转换结果是false，否则是true。\n指向非常量类型的指针能转换成指向相应的常量类型的指针。\n显式转换 （Explicit Conversions）\n显式类型转换也叫做强制类型转换（cast）。虽然有时不得不使用强制类型转换，但这种方法本质上是非常危险的。建议尽量避免强制类型转换。\n命名的强制类型转换（named cast）形式如下：\n1 cast-name\u0026lt;type\u0026gt;(expression); 其中type是转换的目标类型，expression是要转换的值。如果type是引用类型，则转换结果是左值。cast-name是static_cast、dynamic_cast、const_cast和reinterpret_cast中的一种，用来指定转换的方式。\ndynamic_cast支持运行时类型识别。 任何具有明确定义的类型转换，只要不包含底层const，都能使用static_cast。 const_cast只能改变运算对象的底层const，不能改变表达式的类型。同时也只有const_cast能改变表达式的常量属性。const_cast常常用于函数重载。 reinterpret_cast通常为运算对象的位模式提供底层上的重新解释。 早期版本的C++语言中，显式类型转换包含两种形式：\n1 2 type (expression); // function-style cast notation (type) expression; // C-language-style cast notation 类型安全 类型安全是指同一段内存在不同的地方，会被强制要求使用相同的办法来解释(内存中的数据是用类型来解释的)。\nJava 语言是类型安全的，除非强制类型转换。\nC 语言不是类型安全的，因为同一段内存可以用不同的数据类型来解释，比如 1 用 int 来解释就是 1，用 boolean来解释就是 true。\nC++ 也不是绝对类型安全的，但使用得当，它将远比 C 更有类型安全性。\nC++提供了一些新的机制保障类型安全：\n操作符 new 返回的指针类型严格与对象匹配，而不是 void C 中很多以 void* 为参数的函数可以改写为 C++ 模板函数，而模板是支持类型检查的； 引入 const 关键字代替 #define constants，它是有类型、有作用域的，而 #define constants 只是简单的文本替换； 一些 #define 宏可被改写为 inline 函数，结合函数的重载，可在类型安全的前提下支持多种类型，当然改写为模板也能保证类型安全； C++ 提供了 dynamic_cast 关键字，使得转换过程更加安全，因为 dynamic_cast 比 static_cast 涉及更多具体的类型检查。 try语句块和异常处理 【PRIMER 172】\n异常（exception）是指程序运行时的反常行为，这些行为超出了函数正常功能的范围。当程序的某一部分检测到一个它无法处理的问题时，需要使用异常处理（exception handling）。\n异常处理机制包括throw表达式（throw expression）、try语句块（try block）和异常类（exception class）。\n异常检测部分使用throw表达式表示它遇到了无法处理的问题（throw引发了异常）。 异常处理部分使用try语句块处理异常。try语句块以关键字try开始，并以一个或多个catch子句（catch clause）结束。try语句块中代码抛出的异常通常会被某个catch子句处理，catch子句也被称作异常处理代码（exception handler）。 异常类用于在throw表达式和相关的catch子句之间传递异常的具体信息。 throw表达式 throw表达式包含关键字throw和紧随其后的一个表达式，其中表达式的类型就是抛出的异常类型。\ntry语句块 try语句块的通用形式：\n1 2 3 4 5 6 7 8 9 10 11 12 try { program-statements } catch (exception-declaration) { handler-statements } catch (exception-declaration) { handler-statements } // . . . try语句块中的program-statements组成程序的正常逻辑，其内部声明的变量在块外无法访问，即使在catch子句中也不行。catch子句包含关键字catch、括号内一个对象的声明（异常声明，exception declaration）和一个块。当选中了某个catch子句处理异常后，执行与之对应的块。catch一旦完成，程序会跳过剩余的所有catch子句，继续执行后面的语句。\n如果最终没能找到与异常相匹配的catch子句，程序会执行名为terminate的标准库函数。该函数的行为与系统有关，一般情况下，执行该函数将导致程序非正常退出。类似的，如果一段程序没有try语句块且发生了异常，系统也会调用terminate函数并终止当前程序的执行。\n标准异常 异常类分别定义在4个头文件中：\n头文件exception定义了最通用的异常类exception。它只报告异常的发生，不提供任何额外信息。\n头文件stdexcept定义了几种常用的异常类。\n头文件new定义了bad_alloc异常类。\n头文件type_info定义了bad_cast异常类。\n标准库异常类的继承体系：\n只能以默认初始化的方式初始化exception、bad_alloc和bad_cast对象，不允许为这些对象提供初始值。其他异常类的对象在初始化时必须提供一个string或一个C风格字符串，通常表示异常信息。what成员函数可以返回该字符串的string副本。\n类 \u0026amp; 对象 类包含对象所需的数据，以及描述用户与数据交互所需的操作。\n成员函数可以定义在类内部，或者单独使用范围解析运算符（域区分符） :: 来定义。在类定义中定义的成员函数把函数声明为内联的，即使没有使用 inline 标识符。\n类的成员名和方法的参数名不能相同，建议成员名加上 \u0026rsquo;m\u0026rsquo; 前缀或者末尾加上 \u0026lsquo;_\u0026rsquo;。\n【PLUS 353】\n类对象声明 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 class C { public: C() { std::cout \u0026lt;\u0026lt; \u0026#34;call C()\u0026#34; \u0026lt;\u0026lt; std::endl; }; C(int _m) : m(_m) { std::cout \u0026lt;\u0026lt; \u0026#34;call C(int m)\u0026#34; \u0026lt;\u0026lt; std::endl; }; private: int m; }; int main() { C c1; // call C() C c2(); // 仅仅声明了一个函数 c2，它返回 C 类型，所以不要乱加括号 C c3(1); // call C(int m) return 0; } 类访问修饰符 public：公有成员在程序中类的外部是可访问的。可以不使用任何成员函数来设置和获取公有变量的值。 private：私有成员变量或函数在类的外部是不可访问的，甚至是不可查看的。只有类和友元函数可以访问私有成员（派生类也不能访问）。 protected：保护成员变量或函数与私有成员十分相似，但有一点不同，保护成员在派生类（即子类）中是可访问的。 封装继承多态 封装 封装是实现面向对象程序设计的第一步，封装就是将数据或函数等集合在一个个的单元中（称之为类）。\n封装的意义在于保护或者防止代码（数据）被无意中破坏。\n继承 继承主要实现代码重用，节省开发时间。子类可以继承父类的一些东西。\n有 public, protected, private 三种继承方式，它们相应地改变了派生类的用户以及派生类的派生类的访问权限。\npublic 继承：基类 public 成员，protected 成员，private 成员的访问属性在派生类中分别变成：public, protected, private\nprotected 继承：基类 public 成员，protected 成员，private 成员的访问属性在派生类中分别变成：protected, protected, private\nprivate 继承：基类 public 成员，protected 成员，private 成员的访问属性在派生类中分别变成：private, private, private\n但无论哪种继承方式，上面两点都没有改变：\nprivate 成员只能被本类成员（类内，不是实例化的对象）和友元访问，不能被派生类访问； protected 成员可以被派生类（类内，不是实例化的对象）访问。 私有继承的作用 私有继承时，编译器一般不会将派生类对象转换成基类对象。且派生类与基类不是 is a 的关系，而是意味着“is implement in terms of”（以\u0026hellip;\u0026hellip;实现）的关系。如果类D私有继承于B，这样做，只是因为D想使用B中的某些代码，而不是因为类D的对象与类B的对象之间右什么概念上的关系。因此，私有继承在软件“设计”过程中毫无意义，只是在软件“实现”时才有用。\n私有继承与组合的不同 组合是has a关系，如果需要使用一个对象的某些方法，可以用组合，也可以私有继承。选择它们的原则是尽可能使用组合，万不得已才使用继承。继承最大的问题就在于：继承层次过深、继承关系过于复杂会影响到代码的可读性和可维护性（继承了无用或者有害的方法，代码膨胀等，还有，在继承时，基类之间或基类与派生类之间发生成员同名时，将出现对成员访问的不确定性，即同名二义性）。 私有继承中派生类能访问基类的protected成员，并且可以重写基类的虚函数，甚至当基类是抽象类的情况。组合不具有这样的功能。 多态 同一个方法在派生类和基类中的行为是不同的，即方法的行为取决于调用该方法的对象。有两种重要的机制可以实现多态公有继承：\n在派生类中重新定义基类的方法 使用虚方法 【注意】在派生类中重新定义基类的方法，会导致基类方法被隐藏（函数隐藏），这不是重载，重载是一个类中的方法与另一个方法同名，但是参数表不同，这种方法称之为重载方法。\n重载与重写 重写（overried，覆盖、覆写）：是指子类重新定义父类虚函数的方法。与多态有关。\n重载（overload）：是指允许存在多个同名函数，而这些函数的参数列表不同（或许参数个数不同，或许参数类型不同，或许两者都不同）返回值类型随意。与多态无关。\nC++中 const 用于函数重载。常成员函数不能更新类的成员变量，也不能调用该类中没有用const修饰的成员函数，只能调用常成员函数。非常量对象可以调用常成员函数和非常成员函数，但是如果有重载的非常成员函数则会调用非常成员函数。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 class C { public: C(int v) : mValue(v){}; void fun() const { std::cout \u0026lt;\u0026lt; \u0026#34;void fun() const\u0026#34; \u0026lt;\u0026lt; std::endl; }; void fun() { std::cout \u0026lt;\u0026lt; \u0026#34;void fun()\u0026#34; \u0026lt;\u0026lt; std::endl; }; private: int mValue; }; int main() { const C c1(1); C c2(2); c1.fun(); c2.fun(); return 0; } /* 打印 void fun() const void fun() **/ 顶层const是不支持重载的，因为函数调用的时候，存在形实结合的过程，所以不管有没有const都不会改变实参的值。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 void fun(char *s) { std::cout \u0026lt;\u0026lt; \u0026#34;non-const fun() \u0026#34; \u0026lt;\u0026lt; s \u0026lt;\u0026lt; std::endl; } void fun(char *const s) // 顶层 const 不支持重载 { std::cout \u0026lt;\u0026lt; \u0026#34;const fun() \u0026#34; \u0026lt;\u0026lt; s \u0026lt;\u0026lt; std::endl; } /** 编译出错 test.cpp:21:6: error: redefinition of ‘void fun(char*)’ void fun(char *const s) ^~~ test.cpp:16:6: note: ‘void fun(char*)’ previously defined here void fun(char *s) ^~~ */ ​\t底层const支持重载\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 void fun(char *s) { std::cout \u0026lt;\u0026lt; \u0026#34;non-const fun() \u0026#34; \u0026lt;\u0026lt; s \u0026lt;\u0026lt; std::endl; } void fun(const char *s) // 底层 const 支持重载 { std::cout \u0026lt;\u0026lt; \u0026#34;const fun() \u0026#34; \u0026lt;\u0026lt; s \u0026lt;\u0026lt; std::endl; } int main() { char *ptr1 = \u0026#34;hello\u0026#34;; const char *ptr2 = \u0026#34;world\u0026#34;; fun(ptr1); fun(ptr2); return 0; } /** non-const fun() hello const fun() world */ // 对于引用也是同样的道理，如 // void fun(int \u0026amp;i) 和 void fun(const int \u0026amp;i) 也是可以重载的。 // 原因是第一个 i 引用的是一个变量，而第二个 i 引用的是一个常量，两者是不一样的，类似于上面的指向变量的指针和指向常量的指针。 构造函数与析构函数 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 class Line { private: double length; public: void setLength(double len); Line(double len); // 构造函数的名称与类的名称完全相同。不会返回任何类型，也不会返回 void，常用于赋初值 ~Line(); // 析构函数，函数名与类完全相同，只是在前面加了一个波浪号（~）作为前缀，它不会返回任何值，也不会返回void，也不能带有任何参数（所以不可以被重载）。析构函数有助于在跳出程序（比如关闭文件、释放内存等）前释放资源。 double Line::getLength(void) //方法可以定义在类中 { return length; } }; Line::Line(double len) // 方法也可以通过范围解析运算符定义在类外，这是构造函数的具体实现，注意函数前无类型 { cout \u0026lt;\u0026lt; \u0026#34;Object is being created, length = \u0026#34; \u0026lt;\u0026lt; len \u0026lt;\u0026lt; endl; length = len; //初始化属性 } Line::~Line(void) { cout \u0026lt;\u0026lt; \u0026#34;Object is being deleted\u0026#34; \u0026lt;\u0026lt; endl; } 也可以使用初始化列表来初始属性\n1 2 3 4 Line::Line( double len): length(len) { cout \u0026lt;\u0026lt; \u0026#34;Object is being created, length = \u0026#34; \u0026lt;\u0026lt; len \u0026lt;\u0026lt; endl; } 1 2 3 4 5 6 // 同时初始化多个值 Person::Person( double name, double age, double job): Name(name), Age(age), Job(job) // 将参数 name, age, job 初始化给属性 Name, Age, Job { .... } 构造函数不同于类方法，因为它创建新的对象，而其他类对象只是被现有的类调用。这是构造函数不能被继承的原因之一。 继承意味着派生类继承基类的成员函数和成员变量，然而，在构造函数完成其工作之前，对象并不存在。\n一定要使用显式析构函数来释放类构造函数使用 new 分配的所有内存，并完成类对象所需的任何特殊的清理工作。对于基类即使它不需要析构函数，也应提供一个虚析构函数。\n初始化派生类把基类中所有的成员继承过来，除了构造函数和析构函数。友元函数不属于类，它只是给类开了一个后门，自然不能被继承。子类继承父类，那么默认的，就是继承了父类的成员函数和成员变量。\n初始化子类时，会先自动调用父类的构造函数，然后才调用子类的构造函数。\n析构时，按相反顺序进行。\n构造从类层次的最根处开始，在每一层中，首先调用基类的构造函数，然后调用成员对象的构造函数。析构则严格按照与构造相反的次序执行，该次序是唯一的，否则编译器将无法自动执行析构过程。\n【PLUS 524，525，527】\n不同于其他函数，构造函数不能被声明为const。当我们创建类的一个const对象时，直到构造函数完成初始化过程，对象才真正取得其常量属性。因此，构造函数在const对象的构造过程中可以向其写值。\n【PRIMER 235】\n构造函数可以被重载，析构函数不可以被重载。因为析构函数只能有一个且不带参数。\n委托构造函数 C++11扩展了构造函数初始值功能，可以定义委托构造函数。委托构造函数使用它所属类的其他构造函数执行它自己的初始化过程。【PRIMER 261】\n= default和= delete 在C++中，声明自定义的类型之后，编译器会默认生成一些成员函数，这些函数被称为默认函数。其中包括：\n1 2 3 4 5 6 7 8 9 10 11 12 class A { // C++03 A(); // 默认构造函数 A(const A \u0026amp;); // 拷贝构造函数 ~A(); // 析构函数 A \u0026amp;operator=(const A \u0026amp;); // 拷贝赋值运算符 // C++11 新增 A(A \u0026amp;\u0026amp;); // 移动构造函数 A \u0026amp;operator=(A \u0026amp;\u0026amp;); // 移动赋值运算符 }; 这6个函数的实现例子，以string为例，查看实现\n另外，编译器还会默认生成一些操作符函数，包括：\n（7）operator ,\n（8）operator \u0026amp;，有两个，const版本和非const版本\n1 2 A* operator\u0026amp;(); //取址运算符 const A* operator\u0026amp;() const; //取址运算符(const版本) （9）operator \u0026amp;\u0026amp;\n（10）operator *\n（11）operator -\u0026gt;\n（12）operator -\u0026gt;*\n（13）operator new\n（14）operator delete\n= default 显示缺省函数 只有当类没有声明任何构造函数时，编译器才会自动生成默认构造函数。一旦类定义了其他构造函数，那么除非再显式地定义一个默认的构造函数，否则类将没有默认构造函数。【PRIMER 236】\n在C++11中，如果类需要默认的函数行为，可以通过在参数列表后面添加=default来要求编译器生成构造函数。其中=default既可以和函数声明一起出现在类的内部，也可以作为定义出现在类的外部。和其他函数一样，如果=default在类的内部，则默认构造函数是内联的。\n1 Sales_data() = default; = delete 显示删除函数 另一方面，有时候可能需要限制一些默认函数的生成。\n例如：需要禁止拷贝构造函数的使用。以前通过把拷贝构造函数声明为private访问权限，这样一旦使用编译器就会报错。\n而在 C++11 中，只要在函数的定义或者声明后面加上= delete就能实现这样的效果。这种方式不容易犯错，且更容易理解。\n在C ++ 11之前，操作符delete 只有一个目的，即释放已动态分配的内存。而C ++ 11标准引入了此操作符的另一种用法，即：禁用成员函数的使用。这是通过附加= delete说明符到该函数声明的结尾。\n拷贝（复制）构造函数 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 class Line { public: Line(int len); //构造函数 Line(const Line \u0026amp;obj); //拷贝构造函数 ~Line(); // 析构函数 private: int *ptr; }; // 成员函数定义，包括构造函数 Line::Line(int len) { cout \u0026lt;\u0026lt; \u0026#34;调用构造函数\u0026#34; \u0026lt;\u0026lt; endl; // 为指针分配内存 ptr = new int; *ptr = len; } Line::Line(const Line \u0026amp;obj) { cout \u0026lt;\u0026lt; \u0026#34;调用拷贝构造函数并为指针 ptr 分配内存\u0026#34; \u0026lt;\u0026lt; endl; ptr = new int; *ptr = *obj.ptr; // 拷贝值 } Line::~Line(void) { cout \u0026lt;\u0026lt; \u0026#34;释放内存\u0026#34; \u0026lt;\u0026lt; endl; delete ptr; } 什么情况使用拷贝构造函数 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 class Test { public: int a; Test(int x) : a(x) { cout \u0026lt;\u0026lt; \u0026#34;Test(int x)\u0026#34; \u0026lt;\u0026lt; endl; } Test(const Test\u0026amp; t) { cout \u0026lt;\u0026lt; \u0026#34;copy constructor\u0026#34; \u0026lt;\u0026lt; endl; a = t.a; } }; void fun1(Test test) { cout \u0026lt;\u0026lt; \u0026#34;fun1()\u0026#34; \u0026lt;\u0026lt; endl; } Test fun2() { Test t(2); cout \u0026lt;\u0026lt; \u0026#34;fun2()\u0026#34; \u0026lt;\u0026lt; endl; return t; } int main(int argc, char* argv[]) { Test t1(1); cout \u0026lt;\u0026lt; \u0026#34;-------\\n\u0026#34;; Test t2(t1);\t// 通过使用另一个同类型的对象来初始化新创建的对象。 cout \u0026lt;\u0026lt; \u0026#34;-------\\n\u0026#34;; fun1(t1);\t// 复制对象把它作为参数传递给函数。 cout \u0026lt;\u0026lt; \u0026#34;-------\\n\u0026#34;; fun2();\t// 复制对象，并从函数返回这个对象，返回对象时调用拷贝构造函数。 //Test t3 = fun2(); getchar(); return 0; } /* 打印 Test(int x) ------- copy constructor ------- copy constructor fun1() ------- Test(int x) fun2() copy constructor */ **类的对象需要拷贝时，拷贝构造函数将会被调用。**以下情况都会调用拷贝构造函数：\n通过使用另一个同类型的对象来初始化新创建的对象。 复制对象，把它作为参数传递给函数。 复制对象，并从函数返回这个对象。 浅复制与深复制 如果在类中没有显式地声明一个复制构造函数，那么，编译器将会自动生成一个默认的复制构造函数，该构造函数完成对象之间的浅复制。\n自定义复制构造函数是一种良好的编程风格，它可以阻止编译器形成默认的复制构造函数，提高源码效率。\n所谓浅复制，直接为数据成员赋值即可。比如一个实类 c1 里的数据成员里有一个指针 c1.p 指向字符数组 str[] = “hello”，使用浅复制来初始化类 c2，则赋值为 c2.p = c1.p，那么通过 c1.p 改变了 str，c2.p 指向的内容也会改变。\n而深复制要创建新的对象，要为对象的数据成员分配存储空间，直接赋值就将值保存在相应的空间中。比如\n1 2 3 // c1, c2 均是类 c2.p = new char[strlen(c1.p) + 1]; strcpy(c2.p, c1.p); 让 c2.p 指向 new 出来的空间，这时 c1.p 里的内容改变了也不会影响 c2.p。\n编译器与默认的 copy constructor 如果用户定义了一个构造函数（不是拷贝构造函数），且此时在代码中用到了拷贝构造函数，那么编译器会生成默认的拷贝构造函数；如果没有使用，编译器就不会生成默认的拷贝构造函数； 如果用户定义了拷贝构造函数，则编译器就不会再生成拷贝构造函数。 为什么复制构造函数可以访问参数对象的私有成员 封装是编译期的概念，是针对类型而非对象的，在类的成员函数中可以访问同类型实例对象的私有成员变量。\n参考：https://blog.csdn.net/ganwenbo2011/article/details/100919900\n拷贝构造函数与赋值函数的区别 1 2 A (const A\u0026amp;other) // 拷贝构造函数重载声明 A\u0026amp; operator = (const A\u0026amp; other) // 赋值函数重载声明 一般来说在数据成员包含指针对象的时候，需要考虑两种不同的处理需求：一种是复制指针对象，另一种是引用指针对象。拷贝构造函数大多数情况下是复制，而赋值函数是引用对象。\n拷贝构造函数是一个对象初始化一块内存区域，这块内存就是新对象的内存区。赋值构造函数则是把一个对象赋值给一个原有的对象，所以，对于赋值函数，如果原来的对象中有内存分配，就要先把内存释放掉，而且还要检查一下两个对象是不是同一个对象，如果是的话就不做任何检测。\n1 2 3 4 5 6 class A; A a; A b = a; // 调用拷贝构造函数（b 不存在） A c(a) ; // 调用拷贝构造函数 A d; d = a; // 调用赋值函数（d 已初始化） 以字符串的为例子，理解拷贝构造函数和赋值函数\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 String::String(const String \u0026amp;other) //拷贝构造函数 { cout \u0026lt;\u0026lt; \u0026#34;copy construct\u0026#34; \u0026lt;\u0026lt; endl; m_string = new char[strlen(other.m_string) + 1]; //分配空间并拷贝 strcpy(m_string, other.m_string); } String \u0026amp;String::operator=(const String \u0026amp;other) //赋值运算符 { cout \u0026lt;\u0026lt; \u0026#34;operator =funtion\u0026#34; \u0026lt;\u0026lt; endl; if (this == \u0026amp;other) //如果对象和other是用一个对象，直接返回本身 { return *this; } delete[] m_string; //先释放原来的内存 m_string = new char[strlen(other.m_string) + 1]; strcpy(m_string, other.m_string); return *this; } 临时对象的复制与析构 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 class C { public: C() : mValue(0) { std::cout \u0026lt;\u0026lt; \u0026#34;default constructor, value = \u0026#34; \u0026lt;\u0026lt; mValue \u0026lt;\u0026lt; std::endl; }; C(const C \u0026amp;c) { mValue = c.mValue; std::cout \u0026lt;\u0026lt; \u0026#34;copy constructor, value = \u0026#34; \u0026lt;\u0026lt; mValue \u0026lt;\u0026lt; \u0026#34;, this = \u0026#34; \u0026lt;\u0026lt; std::hex \u0026lt;\u0026lt; this \u0026lt;\u0026lt; std::endl; }; C \u0026amp;operator=(const C \u0026amp;c) { if (this == \u0026amp;c) return *this; mValue = c.mValue; std::cout \u0026lt;\u0026lt; \u0026#34;assignment function, value = \u0026#34; \u0026lt;\u0026lt; mValue \u0026lt;\u0026lt; \u0026#34;, this = \u0026#34; \u0026lt;\u0026lt; std::hex \u0026lt;\u0026lt; this \u0026lt;\u0026lt; std::endl; return *this; }; C(int v) : mValue(v) { std::cout \u0026lt;\u0026lt; \u0026#34;constructed by parameter: \u0026#34; \u0026lt;\u0026lt; std::dec \u0026lt;\u0026lt; mValue \u0026lt;\u0026lt; \u0026#34;, this = \u0026#34; \u0026lt;\u0026lt; std::hex \u0026lt;\u0026lt; this \u0026lt;\u0026lt; std::endl; }; virtual ~C() { std::cout \u0026lt;\u0026lt; \u0026#34;destructor, value = \u0026#34; \u0026lt;\u0026lt; mValue \u0026lt;\u0026lt; \u0026#34;, this = \u0026#34; \u0026lt;\u0026lt; std::hex \u0026lt;\u0026lt; this \u0026lt;\u0026lt; std::endl; }; private: int mValue; }; C create(C c) { std::cout \u0026lt;\u0026lt; \u0026#34;start creat\u0026#34; \u0026lt;\u0026lt; std::endl; return c; } int main() { C c1 = create(5); std::cout \u0026lt;\u0026lt; \u0026#34;finish creat c1\u0026#34; \u0026lt;\u0026lt; std::endl; C c2 = create(c1); std::cout \u0026lt;\u0026lt; \u0026#34;finish creat c2\u0026#34; \u0026lt;\u0026lt; std::endl; C c3 = create(8); std::cout \u0026lt;\u0026lt; \u0026#34;finish creat c3\u0026#34; \u0026lt;\u0026lt; std::endl; C c4 = 12; std::cout \u0026lt;\u0026lt; \u0026#34;finish creat c4\u0026#34; \u0026lt;\u0026lt; std::endl; c4 = c1; return 0; } // g++ test.cpp -o test -std=c++11 -m32 /* 打印 constructed by parameter: 5, this = 0xffb5a528 // create 函数值传递，调用带参数的构造函数，生成临时对象 start creat copy constructor, value = 5, this = 0xffb5a520 // return 值，调用拷贝构造函数，生成临时对象 destructor, value = 5, this = 0xffb5a528 // 析构值传递所产生的临时对象（形参） finish creat c1 copy constructor, value = 5, this = 0xffb5a530 // create 函数值传递，调用拷贝构造函数，生成临时对象 start creat copy constructor, value = 5, this = 0xffb5a518 // return 值，调用拷贝构造函数，生成临时对象 destructor, value = 5, this = 0xffb5a530 // 析构值传递所产生的临时对象（形参） finish creat c2 constructed by parameter: 8, this = 0xffb5a538 // create 函数值传递，调用带参数的构造函数，生成临时对象 start creat copy constructor, value = 8, this = 0xffb5a510 // return 值，调用拷贝构造函数，生成临时对象 destructor, value = 8, this = 0xffb5a538 // 析构值传递所产生的临时对象（形参） finish creat c3 constructed by parameter: 12, this = 0xffb5a508 // 隐式转换，调用带参数的构造函数 finish creat c4 assignment function, value = 5, this = 0xffb5a508 // 调用赋值函数，将 c1 赋给 c4 destructor, value = 5, this = 0xffb5a508 // c4 析构 destructor, value = 8, this = 0xffb5a510 // c3 析构 destructor, value = 5, this = 0xffb5a518 // c2 析构 destructor, value = 5, this = 0xffb5a520 // c1 析构 */ 空类的成员函数 1 2 3 4 5 6 7 8 9 10 class Empty { public: Empty(); Empty(const Empty\u0026amp; ); ~Empty(); Empty\u0026amp; operator=(consy Empty\u0026amp; ); Empty* operator\u0026amp; (); // 取地址运算符 const Empty* operator\u0026amp; () const; // const 类型取地址运算符 }; 缺省构造函数。 缺省拷贝构造函数。 缺省析构函数。 赋值运算符。 取址运算符。 取址运算符 const 。 有些书上只是简单的介绍了前四个函数。没有提及后面这两个函数。但后面这两个函数也是空类的默认函数。另外需要注意的是，只有当实际使用这些函数的时候，编译器才会去定义它们。\n初始化列表 使用初始化列表的原因 初始化类的成员有两种方式，一是使用初始化列表，二是在构造函数体内进行赋值操作。\n主要是性能问题，对于内置类型，如 int, float 等，使用初始化列表和在构造函数体内初始化差别不是很大，但是对于类类型来说，最好使用初始化列表，因为使用初始化列表少了一次调用默认构造函数的过程，这对于数据密集型的类来说，是非常高效的（参考下文代码段例1）。\n必须使用初始化列表的情况 （只能使用初始化而不能赋值）【PRIMER 259】\n初始化和赋值的区别事关底层效率：前者直接初始化数据成员，后者则先初始化再赋值。\n除了效率问题之外，有些时候初始化列表是不可或缺的，以下几种情况时必须使用初始化列表：\n常量成员，因为常量只能初始化不能赋值，所以必须放在初始化列表里面；\n引用类型，引用必须在定义的时候初始化，并且不能重新赋值，所以也要写在初始化列表里面；\n没有默认构造函数的类类型（比如构造函数为私有），因为使用初始化列表可以不必调用默认构造函数来初始化，而是直接调用拷贝构造函数初始化。（参考下文代码段例1）\n如果在子类的构造函数中需要初始化父类的 private 成员。直接对其赋值是不行的，只有调用父类的构造函数才能完成对它的初始化。（参考下文代码段例2）\n【总结】当类中含有 const 常量、reference 成员变量；基类的构造函数都需要初始化列表。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 // 例1 class A { public: int num; A() // 无参构造函数 { cout \u0026lt;\u0026lt; \u0026#34;Construct A\u0026#34; \u0026lt;\u0026lt; endl; } A(const A \u0026amp;obj) // 拷贝构造函数 { cout \u0026lt;\u0026lt; \u0026#34;Copy constructor for A\u0026#34; \u0026lt;\u0026lt; endl; this-\u0026gt;num = obj.num; } A \u0026amp;operator=(const A \u0026amp;obj) // 赋值运算符 { cout \u0026lt;\u0026lt; \u0026#34;assignment for A\u0026#34; \u0026lt;\u0026lt; endl; this-\u0026gt;num = obj.num; return *this; } }; class B { public: A a; B(A \u0026amp;obj) { a = obj; } // 【1】 //B(A \u0026amp;obj) : a(obj) {} // 【2】 }; int main() { A a; B b(a); return 0; } /** * 开放【1】注释【2】打印 * Construct A // main 函数里的 A a 打印 * Construct A // 因为在 class B 中，语句 A a 调用了默认构造函数，使用列表初始化就不调用它，转而去调用拷贝构造函数 * assignment for A * 开放【2】注释【1】打印 * Construct A * Copy constructor for A */ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 // 例2 class A { private: int a; public: A(int x) : a(x) {} }; class B : public A { private: int b; public: B(int x, int y) : A(x) { // a = x;\t// a 为 private，无法在子类中被访问 // A(x);\t// 在函数体内调用父类的构造函数不合法 b = y; } }; 初始化顺序 成员是按照他们在类中出现的顺序进行初始化的，而不是按照他们在初始化列表出现的顺序初始化的。\n1 2 3 4 5 6 class foo { public: int i; int j; foo(int x): i(x), j(i) {} // ok, 先初始化 i，后初始化 j }; 再看下面的代码：\n1 2 3 4 5 6 7 8 9 10 11 12 class foo { public: int i; int j; foo(int x): j(x), i(j) {} // i 值未定义 /* 这里 i 的值是未定义。因为虽然 j 在初始化列表里面出现在 i 前面， 但是 i 先于 j 定义，所以先初始化 i，而 i 由 j 初始化， 此时 j 尚未初始化，所以导致 i 的值未定义。 一个好的习惯是，按照成员定义的顺序进行初始化。 */ }; 友元 友元函数 友元函数声明只能出现在类定义的内部，在类内部出现的位置不限（一般在类定义的开始或结束前的位置集中声明友元）。友元不是类的成员函数，也不受它所在区域访问控制级别的约束。\n友元声明仅仅指定了访问权限，而并非一个通常意义上的函数声明。如果希望类的用户能调用某个友元函数，就必须在友元声明之外再专门对函数进行一次声明（部分编译器没有该限制）。\n为了使友元对类的用户可见，通常会把友元的声明（类的外部）与类本身放在同一个头文件中。\n友元函数的定义在类外部，但与成员函数有相同的权限，所以可以访问类的所有私有（private）成员和保护（protected）成员。\n友元可以是一个函数，该函数被称为友元函数。友元也可以是一个类，该类被称为友元类，在这种情况下，整个类及其所有成员都是友元。\n【PRIMER 241, 242】\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 // Sales_data.h class Sales_data { // friend declarations for nonmember Sales_data operations added friend Sales_data add(const Sales_data\u0026amp;, const Sales_data\u0026amp;); friend std::istream \u0026amp;read(std::istream\u0026amp;, Sales_data\u0026amp;); friend std::ostream \u0026amp;print(std::ostream\u0026amp;, const Sales_data\u0026amp;); // other members and access specifiers as before public: Sales_data() = default; Sales_data(const std::string \u0026amp;s, unsigned n, double p): bookNo(s), units_sold(n), revenue(p*n) { } Sales_data(const std::string \u0026amp;s): bookNo(s) { } Sales_data(std::istream\u0026amp;); std::string isbn() const { return bookNo; } Sales_data \u0026amp;combine(const Sales_data\u0026amp;); private: std::string bookNo; unsigned units_sold = 0; double revenue = 0.0; }; // declarations for nonmember parts of the Sales_data interface Sales_data add(const Sales_data\u0026amp;, const Sales_data\u0026amp;); std::istream \u0026amp;read(std::istream\u0026amp;, Sales_data\u0026amp;); std::ostream \u0026amp;print(std::ostream\u0026amp;, const Sales_data\u0026amp;); 友元类 除了普通函数，类还可以把其他类或其他类的成员函数声明为友元。友元类的成员函数可以访问此类包括非公有成员在内的所有成员。\n1 2 3 4 5 6 class Screen { // Window_mgr members can access the private parts of class Screen friend class Window_mgr; // ... rest of the Screen class }; 友元关系不存在传递性。\n把其他类的成员函数声明为友元时，必须明确指定该函数所属的类名。\n如果类想把一组重载函数声明为友元，需要对这组函数中的每一个分别声明。\n1 2 3 4 5 6 class Screen { // Window_mgr::clear must have been declared before class Screen friend void Window_mgr::clear(ScreenIndex); // ... rest of the Screen class }; 友元函数可以直接定义在类的内部，这种函数是隐式内联的。但是必须在类外部提供相应声明令函数可见。如下：\n1 2 3 4 5 6 7 8 9 10 11 struct X { friend void f() { /* friend function can be defined in the class body */ } X() { f(); } // error: no declaration for f void g(); void h(); }; void X::g() { return f(); } // error: f hasn\u0026#39;t been declared void f(); // declares the function defined inside X void X::h() { return f(); } // ok: declaration for f is now in scope 【PRIMER 250~252】\n友元访问控制与继承 一个类可以使用protected关键字来声明外部代码无法访问，但是派生类对象可以访问的成员。\n派生类的成员或友元只能访问派生类对象中的基类部分的protected成员。对于普通的基类对象中的protected成员没有任何访问权限。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 class Base { protected: int prot_mem; // protected member }; class Sneaky : public Base { friend void clobber(Sneaky\u0026amp;); // can access Sneaky::prot_mem friend void clobber(Base\u0026amp;); // can\u0026#39;t access Base::prot_mem int j; // j is private by default }; // ok: clobber can access the private and protected members in Sneaky objects void clobber(Sneaky \u0026amp;s) { s.j = s.prot_mem = 0; } // error: clobber can\u0026#39;t access the protected members in Base void clobber(Base \u0026amp;b) { b.prot_mem = 0; } 【PRIMER 543】\n内联函数 C++ 内联函数是通常与类一起使用。如果一个函数是内联的，那么在编译时，编译器会把该函数的代码副本放置在每个调用该函数的地方。在类中定义的函数都是内联函数，即使不用 inline 说明符。定义不在类里面，且声明和定义都没有inline，就不会隐式内联。C++类里面的哪些成员函数是内联函数？\n引入内联函数的目的是为了解决程序中函数调用的效率问题，因为编译器使用相同的函数代码代替函数调用，对于内联代码，程序无需跳转到另一个位置执行代码，再跳回来。因此内联函数的运行速度比常规函数稍快，但代价是需要占用更多的内存。如果在程序的多个不同的地方调用内联函数，该程序将包含该内联函数的多个副本。总的来说就是用空间换时间。所以内联函数一般都是1-5行的小函数。关于内联函数可以总结为：\n相当于把内联函数里面的内容写在调用内联函数处； 相当于不用执行进入函数的步骤，直接执行函数体； 相当于宏，却比宏多了类型检查，真正具有函数特性； 不能包含循环、递归、switch 等复杂操作； 在类声明中定义的函数，除了虚函数的其他函数都会自动隐式地当成内联函数。在类外定义需要显式内联； 使用内联函数不过是向编译器提出一种申请，编译器可以拒绝你的申请。 内联函数与宏的区别 内联函数在编译时展开，宏在预编译（预处理）时展开； 在编译的时候，内联函数可以直接被镶嵌到目标代码里，而宏只是一个简单的文本替换； 内联函数可以完成诸如类型检测、语句是否正确等编译功能，宏就不具有这样的功能； 内联函数是函数，宏不是函数； 宏在定义时要小心处理宏参数（用括号括起来），否则会出现二义性，而内联函数定义时不会出现二义性 volatile volatile 关键字是一种类型修饰符，用它声明的类型变量表示这个变量可能被意想不到的修改（比如：操作系统、硬件或者其它线程等）。遇到这个关键字声明的变量，编译器对访问该变量的代码就不再进行优化，从而可以提供对特殊地址的稳定访问。当要求使用 volatile 声明的变量的值的时候，系统总是重新从它所在的内存读取数据，即使它前面的指令刚刚从该处读取过数据。\n虽然volatile在嵌入式方面应用比较多，但是在PC软件的多线程中，volatile修饰的临界变量也是非常实用的。\n聊聊C++的mutable和volatile\n一个参数可以既是 const 又是 volatile 吗 可以，用const和volatile同时修饰变量，表示这个变量在程序内部是只读的，不能改变的，只在程序外部条件变化下改变，并且编译器不会优化这个变量。每次使用这个变量时，都要小心地去内存读取这个变量的值，而不是去寄存器读取它的备份。\n注意：在此一定要注意const的意思，const只是不允许程序中的代码改变某一变量，其在编译期发挥作用，它并没有实际地禁止某段内存的读写特性。\nexplicit 普通函数是能够被隐式调用（如使用=），而 explicit 构造函数只能被显式调用。\nexplicit 是用来防止隐式转换的，它只对一个实参的构造函数有效，且只允许出现在类内的构造函数声明处。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 class Test1 { public: int num; char *str; Test1(int n, char *s) { num = n, str = s; cout \u0026lt;\u0026lt; \u0026#34;call Test1(int n, char *s)\\n\u0026#34;; } }; class Test2 { public: int num; char *str; string type_info; explicit Test2(int n, char *s) : num(n), str(s) { cout \u0026lt;\u0026lt; \u0026#34;call explicit Test2(int n, char *s)\\n\u0026#34;; } explicit Test2(string) : type_info(\u0026#34;call explicit Test2(string)\\n\u0026#34;) { cout \u0026lt;\u0026lt; type_info; } explicit Test2(char) : type_info(\u0026#34;call explicit Test2(char)\\n\u0026#34;) { cout \u0026lt;\u0026lt; type_info; } Test2(int) : type_info(\u0026#34;call explicit Test2(int)\\n\u0026#34;) { cout \u0026lt;\u0026lt; type_info; } explicit Test2(short) : type_info(\u0026#34;call explicit Test2(short)\\n\u0026#34;) { cout \u0026lt;\u0026lt; type_info; } }; int main(int argc, char *argv[]) { Test1 t1 = {12, \u0026#34;hello...\u0026#34;}; // 隐式调用成功 //Test2 t2 = { 12, \u0026#34;hello...\u0026#34; };\t// 编译错误，不能隐式调用其构造函数 Test2 t3(12, \u0026#34;hello...\u0026#34;); // 显式调用成功 short n = 42; Test2 t4 = n; // 虽然 n 是 short 类型，但因为 explicit Test2(short) 不能隐式调用，故退而求其次把 n 转换成 int 调用 Test2(int) Test2 t5(n); // 显示调用 explicit Test2(short) } /* 打印 call Test1(int n, char *s) call explicit Test2(int n, char *s) call explicit Test2(int) call explicit Test2(short) */ const 1 2 3 const Stock \u0026amp;Stock::topval(const Stock \u0026amp; s) const {......} //有两只股票，返回价格高的那一只股票【PLUS 363，365】 该函数显式的访问一个对象（参数），又隐式的访问另一个对象（调用的对象），并返回其中一个对象的引用。参数中的 const 表明，该函数不会修改被显式访问的对象（不会修改参数指针指向的内容），而括号后的 const 表明，该函数不会修改被隐式地访问的对象（该类方法 Stock::topval() 不会修改类里的数据），最前面的 const 表明函数的返回值不能被修改。\nconst形参和实参 当形参有顶层const时，传递给它常量对象或非常量对象都是可以的。\n可以使用非常量对象初始化一个底层const形参，但是反过来不行。\n把函数不会改变的形参定义成普通引用会极大地限制函数所能接受的实参类型，同时也会给别人一种误导，即函数可以修改实参的值。\n顶层cosnt作形参，不会重载。如：\n1 2 void fun(const int *i) { do_something }; void fun(int *i) { do_something }; // 错误，重复定义了fun(int) 【PRIMER 191， 207】\n函数返回引用 返回引用能节省调用拷贝（复制）构造函数生成的副本所需的时间和析构函数删除副本所需的时间。但并不总是可以返回引用，函数不能返回在函数中创建的临时对象的引用，因为当函数结束，临时对象就消失了。 【PLUS 526】\n引用返回左值【PRIMER 202】\n一般地：可以取地址，有名字的就是左值；反之，右值。\n1 2 3 4 5 6 7 8 9 10 char \u0026amp;get_val (string \u0026amp;str, string::size_type ix) { return str[ix]; } int main() { string s(\u0026#34;a value\u0026#34;); get_val(s, 0) = \u0026#39;A\u0026#39;; // 函数返回引用可作为左值（如果是常量引用则不可），将s[0]的值改为A return 0; } const作用 修饰变量，说明该变量不可以被改变；\n修饰指针，分为指向常量的指针和指针常量；\n修饰函数引用参数，即避免了拷贝，又避免了函数对引用值的修改；\n如void fun(A const \u0026amp;a);A是用户自定义类型。相比于值传递减少了临时对象的构造、复制、析构过程，用 const 修饰引用，避免函数通过引用修改 a。\n修饰函数返回值，说明该返回值不能被修改，且该返回值只能赋值给加 const 修饰的同类型变量\n修饰类的成员函数，说明在该成员函数内不能修改成员变量。\n默认情况下，const对象被设定成仅在文件内有效。当多个文件中出现了同名的const变量时，其实等同于在不同文件中分别定义了独立的变量。【PRIMER 54】\n如果想在多个文件间共享const对象：\n若const对象的值在编译时已经确定，则应该定义在头文件中。其他源文件包含该头文件时，不会产生重复定义错误。\n若const对象的值直到运行时才能确定，则应该在头文件中声明，在源文件中定义。此时const变量的声明和定义前都应该添加extern关键字。\n1 2 3 4 // file_1.cc 定义并初始化一个常量，该常量能被其它文件访问 extern const int bufSize = fcn(); // file_1.h extern const int bufSize; // 与file_1.cc中定义的是同一个 const使用\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 // 类 class A { private: const int a; // 常对象成员，只能在初始化列表赋值 public: // 构造函数 A() : a(0) { }; A(int x) : a(x) { }; // 初始化列表 // 后置const可用于对重载函数的区分 int getValue(); // 普通成员函数 int getValue() const; // 常成员函数，不得修改类中的任何数据成员的值 }; void function() { // 对象 A b; // 普通对象，可以调用全部成员函数 const A a; // 常对象，只能调用常成员函数、更新常成员变量 const A *p = \u0026amp;a; // 常指针 const A \u0026amp;q = a; // 常引用 // 指针 char greeting[] = \u0026#34;Hello\u0026#34;; char* p1 = greeting; // 指针变量，指向字符数组变量 const char* p2 = greeting; // 指针变量，指向字符数组常量 char* const p3 = greeting; // 常指针，指向字符数组变量 const char* const p4 = greeting; // 常指针，指向字符数组常量 } // 函数 void function1(const int Var); // 传递过来的参数在函数内不可变 void function2(const char* Var); // 参数指针所指内容为常量 void function3(char* const Var); // 参数指针为常指针 void function4(const int\u0026amp; Var); // 引用参数在函数内为常量 // 函数返回值 const int function5(); // 返回一个常数 const int* function6(); // 返回一个指向常量的指针变量，使用：const int *p = function6(); int* const function7(); // 返回一个指向变量的常指针，使用：int* const p = function7(); const修饰指针 指针本身是一个独立的对象，它又可以指向另一个对象。所以指针和 const 同时使用时，有两种情况：【PRIMER 57】\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 int i = 0; int *const j = \u0026amp;i; // 顶层 const // 指针常量,指向不可变地址的指针，但可以对它指向的内容进行修改。 // 指针j指向i，const修饰指针j本身， // 所以不允许修改j，但可以通过j修改i的值 const int *k = \u0026amp;i; // 底层 const // 常量指针，指向常量的指针，该指针指向的地址里的内容不可变。 // 指针k指向i，const修饰k指向的i， // 所以可以修改k，但不可以通过k修改i的值 int const *p = \u0026amp;i; // 底层 const // 即 const int *p，同上，为常量指针。 // const 修饰离右边最近的那一个，int const *p 等价于 const int *p // 都可以理解为 const 修饰（*p）而不是 p，那么 p 可变,p 指向的值不可变 const int * const p = \u0026amp;i; // p 只能指向 i，且 p 指向的 i 也不可变 constexpr和常量表达式 【PRIMER 58】\n常量表达式（constant expressions）指值不会改变并且在编译过程就能得到计算结果的表达式。\n一个对象是否为常量表达式由它的数据类型和初始值共同决定。\n1 2 3 4 const int max_files = 20; // max_files is a constant expression const int limit = max_files + 1; // limit is a constant expression int staff_size = 27; // staff_size is not a constant expression const int sz = get_size(); // sz is not a constant expression C++11允许将变量声明为constexpr类型以便由编译器来验证变量的值是否是一个常量表达式。\n1 2 3 constexpr int mf = 20; // 20 is a constant expression constexpr int limit = mf + 1; // mf + 1 is a constant expression constexpr int sz = size(); // ok only if size is a constexpr function 指针和引用都能定义成constexpr，但是初始值受到严格限制。constexpr指针的初始值必须是0、nullptr或者是存储在某个固定地址中的对象。\n函数体内定义的普通变量一般并非存放在固定地址中，因此constexpr指针不能指向这样的变量。相反，函数体外定义的变量地址固定不变，可以用来初始化constexpr指针。\n在constexpr声明中如果定义了一个指针，限定符constexpr仅对指针本身有效，与指针所指的对象无关。constexpr把它所定义的对象置为了顶层const。\n1 2 3 const int *p = \u0026amp;i;\t// p是一个指向整型常量的指针：底层const，p可变，但p指向的内存里的值不可被修改。 constexpr int *p2 = \u0026amp;i; // p2是指向整数的常量指针：顶层const，p2不可变，但可通过p2修改其指向的内存里面的值 constexpr const int *p3 = \u0026amp;i; // p3是指向const int的const指针，可以理解为const int *const p3 = \u0026amp;i; const和constexpr限定的值都是常量。但constexpr对象的值必须在编译期间确定，而const对象的值可以延迟到运行期间确定。\n建议使用constexpr修饰表示数组大小的对象，因为数组的大小必须在编译期间确定且不能改变。\nconst 与 #define 1 2 #define PI 3.1415926 const float pi = 3.1415926; const 常量有数据类型，而宏常量没有数据类型。编译器可以对前者进行类型安全检查。而对后者只进行字符替换，没有类型安全检查，并且在字符替换可能会产生意料不到的错误 。 宏定义是直接替换，它的生命周期止于编译期，不会分配内存，存储于程序的代码段中； const 常量存在于程序的数据段，并分配了实际的内存。 mutable 使用关键字mutable可以声明可变数据成员（mutable data member）。可变数据成员永远不会是const的，即使它在const对象内。因此const成员函数可以修改可变成员的值。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 class Screen { public: void some_member() const; private: mutable size_t access_ctr; // may change even in a const object // other members as before }; void Screen::some_member() const { ++access_ctr; // keep a count of the calls to any member function // whatever other work this member needs to do } 存储类 auto C++ 11 以来，auto 关键字用于两种情况：声明变量时根据初始化表达式自动推断该变量的类型、声明函数时函数返回值的占位符。\nauto是类型推导，让使用者获得动态语言的使用体验；但是有区别，那就是 auto 声明的变量类型，你可以不知道，但是编译器一定要知道，这样才不会报错。\n根据初始化表达式自动推断被声明的变量的类型，如：\n1 2 3 4 5 6 7 8 9 auto a; // 报错！a未初始化，编译器推算不出来 a 是什么类型，就不知道要开辟多大的空间。 auto f = 3.14; // double auto s(\u0026#34;hello\u0026#34;); // const char* auto z = new auto(9); // int* auto x1 = 5, x2 = 5.0, x3 = \u0026#39;r\u0026#39;; // 报错！ /* 当在同一行中定义多个变量时，编译器只对第一个类型进行推导， 然后用推导出来的类型定义其它变量 */ 注意：\nauto 不可作为函数的参数：参数要被编译成指令，auto 做参数，会不知道要开辟多大的空间。 auto 不可直接用来声明数组：因为不知道要开辟多大空间。 auto 在实际中最常见的优势用法是 C++11 提供的新式 for 循环，还有 lambda 表达式等进行配合使用。\nstatic作用 修饰变量：修改变量的存储区域和生命周期，使变量存储在静态区，变量只初始化一次。\n当修饰全局变量的时候，就是静态全局变量。静态全局变量与非静态全局变量都是存储在静态区，但是它们的作用域不一样：静态全局变量的作用域只在该文件里有效（文件作用域），而非静态全局变量的作用域是在整个源程序里有效。 当修饰局部变量的时候，一般用在函数体中，静态局部变量的作用域与普通局部变量一样，只在该函数中有效，但静态局部变量存储在静态区，在函数调用结束会维持其值不变，下次调用该函数不会初始化而是直接使用上一次调用时的值。 修饰普通函数：表明函数的作用范围，仅在定义该函数的文件内才能使用。在多人开发项目时，为了防止与他人命名的函数重名，可以将函数定义为 static。\n修饰成员变量：静态成员变量用来表示唯一的、可共享的成员变量。它可以在同一个类的所有对象中被访问。静态成员变量只有唯一的一份实体。不需要生成对象就可以访问该成员。\nstatic 成员变量必须在类声明的外部进行初始化，以示与普通数据成员的区别。在类外部定义静态成员时，不能重复static关键字，其只能用于类内部的声明语句。【PRIMER 270】\n例如：int Class_name::static_val = 5;\nstatic 成员变量和普通 static 变量一样，都在内存分区的全局数据区分配内存，到程序结束后释放。这就意味着，static 成员变量不随对象的创建而分配内存，也不随对象的销毁而释放内存。而普通成员变量在对象创建时分配内存，在对象销毁时释放内存。\n修饰成员函数：静态成员函数使得不需要生成对象就可以访问该函数。静态成员函数和静态成员变量一样，不属于类，所以静态成员函数不含 this 指针，也就无法访问类的非静态成员。\n【对1，2条的总结】\nstatic 最重要的一条在于修饰普通变量与普通函数时，隐藏普通变量与普通函数。因为未加 static 前缀的全局变量和函数都具有全局可见性。\n静态数据成员与全局变量相比的优势 静态数据成员没有进入程序的全局命名空间，因此不存在与其他全局变量名字冲突的可能； 使用静态数据成员可以隐藏信息。因为静态数据成员可以是 private 成员，而全局变量不能； extern extern 存储类用于提供一个全局变量的引用，全局变量对所有的程序文件都可见。使用 \u0026rsquo;extern\u0026rsquo; 时，对于无法初始化的变量，会把变量名指向一个之前定义过的存储位置(定义只有一次，不可重复定义)。\n多个文件定义了一个可以在其他文件中使用的全局变量或函数时，可以在其他文件中使用 extern 来得到已定义的变量或函数的引用。可以这么理解，extern 是用来在另一个文件中声明一个全局变量或函数。\n类型转换运算符 C++ 中四种类型转换是：static_cast, dynamic_cast, const_cast, reinterpret_cast 1 2 cast-name\u0026lt;type\u0026gt;(expression) // type是转换的目标类型，expression 是被转换的值。 const_cast(常量转换)\n用于将 const 变量转为非 const ，也可以去除 volatile，除此之外不允许任何类型转换。即常量指针被转换成非常量指针，并且仍然指向原来的对象；常量引用被转换成非常量引用，并且仍然引用原来的对象。\nstatic_cast(静态转换)\n任何编写程序时能够明确的类型转换都可以使用 static_cast（static_cast 不能转换掉底层 const，volatile 和 __unaligned 属性）。由于不提供运行时的检查，所以叫 static_cast，因此，需要在编写程序时确认转换的安全性。\n主要在以下几种场合中使用：\n用于类层次结构中，父类和子类之间指针和引用的转换；进行上行转换，把子类对象的指针/引用转换为父类指针/引用，这种转换是安全的；进行下行转换，把父类对象的指针/引用转换成子类指针/引用，这种转换是不安全的，需要编写程序时来确认； 用于基本数据类型之间的转换，例如把 int 转 char，int 转 enum 等，需要编写程序时来确认安全性； 把 void 指针转换成目标类型的指针（这是极其不安全的）； dynamic_cast(动态转换)\n用于动态类型转换。只能用于含有虚函数的类，用于类层次间的向上和向下转化，只能转指针或引用。向下转化时，如果是非法的对于指针返回 nullptr，对于引用抛异常。要深入了解内部转换的原理。\n向上转换：指的是子类向基类的转换。此时与 static_cast 和隐式转换一样，都是非常安全的。 注意菱形继承中的向上转换要指明路径。\n向下转换：指的是基类向子类的转换；\n它通过变量运行时的类型和要转换的类型是否相同，来判断是否能够进行向下转换。\n为什么只能用于含有虚函数的类？\n因为类中存在虚函数，说明它可能有子类，这样才有类型转换的情况发生，由于运行时类型检查需要运行时类型信息，而这个信息存储在类的虚函数表中，只有定义了虚函数的类才有虚函数表。\nreinterpret_cast(重解释)\n几乎什么都可以转，比如将 int 转指针，可能会出问题，尽量少用；\n为什么不使用 C 的强制转换 C 的强制转换表面上看起来功能强大什么都能转，但是转化不够明确，不能进行错误检查，容易出错。\nthis指针 每个非静态成员函数（包含构造函数和析构函数）都有一个this指针，this指针指向调用对象，this是地址，如果要引用调用对象本身，用*this。\n（只有成员函数才有 this 指针，静态成员函数和友元函数都不含 this 指针）\n当一个成员函数被调用时，自动向它传递一个隐含的参数，该参数是一个指向这个成员函数所在的对象的指针。this 指针被隐含地声明为: ClassName *const this，这意味着不能给 this 指针赋值；在 ClassName 类的 const 成员函数中，this 指针的类型为：const ClassName* const，这说明 this 指针所指向的这种对象是不可修改的（即不能对这种对象的数据成员进行赋值操作）。\n一个类的成员函数只有一份，并不是每一个对象对应一个单独的成员函数体，而成员函数之所以能把属于此类的各个对象的数据区分开，就在于每次执行类成员函数时，都会把当前的this指针（对象首地址）传入成员函数，函数体内所有对类数据成员的访问都会转化为this-\u0026gt;数据成员的方式。\n【PLUS 364】\n【注意】静态成员函数里，不能使用 this 指针：\n静态成员函数并不是针对某个类的实例对象，而是属于整个类的，为所有的对象实例所共有。他在作用域的范围内是全局的，独立于类的对象之外的。他只对类内部的静态成员变量做操作。当实例化一个类的对象时候，里面不存在静态成员的。this 指针是相当于一个类的实例的指针，this 是用来操作对象实例的内容的，既然静态成员函数和变量都是独立于类的实例对象之外的，它就不能用 this 指针，也不能操作非静态成员。\n虚函数 1 2 3 4 5 6 7 /*BrassPlus 是 Brass 的子类， ViewAcct() 是两个类中都有的方法。 由于 bp是父类指针，如果基类不用虚方法那么就会调用基类的 ViewAcct() 方法 若在基类中将 ViewAcct() 声明为虚，则 bp-\u0026gt;ViewAcct() 根据对象类型（BrassPlus）调用 BrassPlue::ViewAcct()方法*/ BrassPlus ophelia; Brass *bp; bp = \u0026amp;ophelia; bp-\u0026gt;ViewAcct(); // 是调用子类还是父类的 ViewAcct() 方法？ 【PLUS 503】\n当且仅当通过指针或引用调用虚函数时，才会在运行过程解析该调用，也只有在这种情况下对象的动态类型有可能与静态类型不同。\n在派生类中覆盖某个虚函数时，可以再次使用virtual关键字说明函数性质，但这并非强制要求。因为一旦某个函数被声明为虚函数，则在所有派生类中它都是虚函数。\n在派生类中覆盖某个虚函数时，该函数在基类中的形参必须与派生类中的形参严格匹配。\n派生类可以定义一个与基类中的虚函数名字相同但形参列表不同的函数，但编译器会认为该函数与基类中原有的函数是相互独立的，此时派生类的函数并没有覆盖掉基类中的版本。这往往会发生错误，因为我们原本希望派生类可以覆盖基类中的虚函数，但是一不小心把形参列表写错了。想调试并发现这样的错误非常困难，C++11允许派生类使用override关键字显式地注明虚函数。如果override标记了某个函数，但该函数并没有覆盖已存在的虚函数，编译器将报告错误。override位于函数参数列表之后。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 struct B { virtual void f1(int) const; virtual void f2(); void f3(); }; struct D1 : B { void f1(int) const override; // 正确：f1() 与基类中的 f1() 匹配 void f2(int) override; // 错误：B 没有形如 f2(int) 的函数 void f3() override; // 错误：f3() 不是虚函数 void f4() override; // 错误：B 没有名为 f4() 的函数 } 与禁止类继承类似，函数也可以通过添加final关键字来禁止覆盖操作。\n1 2 3 4 5 6 7 8 9 10 struct D2 : B { // 从 B 继承 f2() 和 f3(),覆盖 f1(int) void f1(int) const final; // 不允许后续的其他类覆盖 f1(int) }; struct D3 : D2 { void f2();\t// 正确：覆盖从 B 继承而来的 f2() void f1(int) const;\t// 错误：D2 已经将 f1 声明成 final。 } final和override关键字出现在形参列表（包括任何const或引用修饰符）以及尾置返回类型之后。\n虚函数也可以有默认实参，每次函数调用的默认实参值由本次调用的静态类型决定。如果通过基类的指针或引用调用函数，则使用基类中定义的默认实参，即使实际运行的是派生类中的函数版本也是如此。\n如果虚函数使用默认实参，则基类和派生类中定义的默认实参值最好一致。\n【PRIMER 536~538】\n回避虚函数 在某些情况下，我们希望对虚函数的调用不要进行动态绑定，而是强迫执行虚函数的某一个特定版本。使用作用域运算符::可以强制执行虚函数的某个版本，不进行动态绑定。\n1 2 // 强行调用基类中定义的函数版本而不管 baseP 的动态类型到底是什么 double undiscounted = baseP-\u0026gt;Quote::net_price(42); 通常情况下，只有成员函数或友元中的代码才需要使用作用域运算符来回避虚函数的动态绑定机制。\n如果一个派生类虚函数需要调用它的基类版本，但没有使用作用域运算符，则在运行时该调用会被解析为对派生类版本自身的调用，从而导致无限递归。\n【PRIMER 539】\n虚函数是怎么实现的 虚函数是通过虚函数表实现的。如果一个类中有一个虚函数，则系统会为这个类分配一个指针成员指向一张虚函数表（vtbl），表中每一项指向一个虚函数地址，虚函数表实际上就是一个函数指针数组。\nC++虚函数原理\n虚函数是否可以内联 虚函数可以是内联函数，内联是可以修饰虚函数的，但是当虚函数表现多态性的时候不能内联。 内联是在编译期间编译器内联，而虚函数的多态性在运行期，编译器无法知道运行期调用哪个代码，因此虚函数表现为多态性时（运行期）不可以内联。 inline virtual 唯一可以内联的时候是：编译器知道所调用的对象是哪个类，这只有在编译器具有实际对象而不是对象的指针或引用时才会发生。 虚析构函数 1 2 3 4 // Employee 是基类，Singer 是派生类 Employee *pe = new Singer; ... delete pe; // call ~Employee() or ~Singer()? 如果基类中的析构函数不是虚的，就只调用对应于指针类型(Employee)的析构函数，但实际中，是想调用派生类的析构函数。如果基类的析构函数是虚的，将调用相应对象类型(Singer)的析构函数，然后自动调用基类的析构函数。因此，使用虚析构函数可以保证正确的析构函数序列被调用。 【PLUS 501，505】\n1 2 3 4 5 // Employee 是基类，Singer 是派生类 Singer *pe = new Singer; ... delete pe; // 先调用 ~Singer() 再调用 ~Employee()， // 因为 pe 是 Singer* 类型指针，而不是 Employee* 类型指针。 静态联编和动态联编 将源程序中的函数调用解释为执行特定的函数代码块被称为函数名联编。在 C 语言中由于不支持函数重载，这很容易，在 C++ 中，由于支持函数重载，编译器必须查看函数的参数才知道调用的是哪一个函数。C++ 在编译过程中就可以完成这种联编，故称为静态联编，又称为早期联编。编译器总是对非虚方法使用静态联编。\n然而虚函数使编译器不知道在编译时到底用哪一个函数，因为编译器不知道用户将选择哪种类型的对象，所以编译器必须生成能够在程序运行时选择正确的虚函数的代码，这被称之为动态联编，也被称为晚期联编。\n【PLUS 501】\n有关虚函数的注意事项 构造函数不能是虚函数。先构造父类对象，然后才能是子类对象，如果构造函数设为虚函数，那么当你在构造父类的构造函数时就不得不显式的调用构造，还有一个原因就是为了防错，试想如果你在子类中一不小心重写了个跟父类构造函数一样的函数，那么你的父类的构造函数将被覆盖，即不能完成父类的构造，就会出错。 析构函数应当是虚函数，除非类不用做基类。即使类不用作基类，通常应给基类提供一个虚析构函数 友元不能是虚函数，因为友元不是类成员，只有类成员才能是虚函数 如果派生类没有重新定义函数，将使用该函数的基类版本。如果派生类位于派生链中，则将使用最新的虚函数版本 如果派生类重新定义函数，将隐藏同名基类方法，这不同于重载 模板函数不能是虚函数。因为，类会在vtbl中存放类中的所有的虚函数的函数指针，而一个模板函数如果设计为虚函数是无法获悉这个模板函数会被实例化为哪些具体的函数。 【PLUS 503，504】\n除构造函数之外的任何非静态函数都能定义为虚函数。virtual关键字只能出现在类内部的声明语句之前而不能用于类外部的函数定义。如果基类把一个函数声明为虚函数，则该函数在派生类中隐式地也是虚函数。 成员函数如果没有被声明为虚函数，则其解析过程发生在编译阶段而非运行阶段。 【PRIMER 528】\n纯虚函数 纯虚函数是一种特殊的虚函数，纯虚函数只是一个接口，是让派生类实现细节的，在纯虚函数中也可以定义具体实现，但没意义。**包含纯虚函数的类是抽象基类（ABC，abstract base class），它只能作为基类，不能创建对象。**可以从抽象基类派生出具体类（普通类），这些类可以创建对象。\n1 2 3 4 5 class C public: virtual int f1() = 0; //函数原型中的 =0 使虚函数成为纯虚函数 virtual double area() const = 0; virtual ~C() {} 【PLUS 509，510】\n虚函数、纯虚函数 类里如果声明了虚函数，这个函数是实现的，哪怕是空实现，它的作用就是为了能让这个函数在它的子类里面可以被覆盖，这样的话，这样编译器就可以使用后期绑定来达到多态了。纯虚函数只是一个接口，是个函数的声明而已，它要留到子类里去实现。 虚函数在子类里面也可以不重载的；但纯虚函数必须在子类去实现。 虚函数的类用于 “实作继承”，继承接口的同时也继承了父类的实现。当然大家也可以完成自己的实现。纯虚函数关注的是接口的统一性，实现由子类完成。 带纯虚函数的类叫抽象类（虚基类），这种类不能直接生成对象，而只有被继承，并重写其虚函数后，才能使用。抽象类和大家口头常说的虚基类还是有区别的，在 C# 中用 abstract 定义抽象类，而在 C++ 中有抽象类的概念，但是没有这个关键字。抽象类被继承后，子类可以继续是抽象类，也可以是普通类，而虚基类，是含有纯虚函数的类，它如果被继承，那么子类就必须实现虚基类里面的所有纯虚函数，其子类不能是抽象类。 继承 类派生列表中的访问说明符用于控制派生类从基类继承而来的成员是否对派生类的用户可见。\n如果派生类没有覆盖其基类的某个虚函数，则该虚函数的行为类似于其他的普通函数，派生类会直接继承其在基类中的版本。\nC++标准并没有明确规定派生类的对象在内存中如何分布，一个对象中继承自基类的部分和派生类自定义的部分不一定是连续存储的。\n每个类控制它自己的成员初始化过程，派生类必须使用基类的构造函数来初始化它的基类部分。派生类的构造函数通过构造函数初始化列表来将实参传递给基类构造函数。\n1 2 3 4 // class Bulk_quote : public Quote Bulk_quote(const std::string\u0026amp; book, double p, std::size_t qty, double disc) : Quote(book, p), min_qty(qty), discount(disc) { } 除非特别指出，否则派生类对象的基类部分会像数据成员一样执行默认初始化。\n派生类初始化时首先初始化基类部分，然后按照声明的顺序依次初始化派生类成员。\n派生类可以访问基类的公有成员和受保护成员。\n如果基类定义了一个静态成员，则在整个继承体系中只存在该成员的唯一定义。如果某静态成员是可访问的，则既能通过基类也能通过派生类使用它。\n只有声明并定义的类才能被用作基类。\n1 2 3 class Base { /* ... */ } ; class D1: public Base { /* ... */ }; class D2: public D1 { /* ... */ }; Base是D1的直接基类（direct base），是D2的间接基类（indirect base）。最终的派生类将包含它直接基类的子对象以及每个间接基类的子对象。\nC++11中，在类名后面添加final关键字可以禁止其他类继承它。\n1 2 3 4 5 6 class NoDerived final { /* */ }; // NoDerived can\u0026#39;t be a base class class Base { /* */ }; // Last is final; we cannot inherit from Last class Last final : Base { /* */ }; // Last can\u0026#39;t be a base class class Bad : NoDerived { /* */ }; // error: NoDerived is final class Bad2 : Last { /* */ }; // error: Last is final 【PRIMER 529~533】\n访问控制 基类中成员的访问说明符和派生列表中的访问说明符都会影响某个类对其继承成员的访问权限。\n派生访问说明符对于派生类的成员及友元能否访问其直接基类的成员没有影响，对基类成员的访问权限只与基类中的访问说明符有关。\n派生访问说明符的作用是控制派生类（包括派生类的派生类）用户对于基类成员的访问权限。\n如果使用公有继承，则基类的公有成员和受保护成员在派生类中属性不发生改变。 如果使用受保护继承，则基类的公有成员和受保护成员在派生类中变为受保护成员。 如果使用私有继承，则基类的公有成员和受保护成员在派生类中变为私有成员。 派生类到基类转换的可访问性（假定D继承自B）：\n只有当D公有地继承B时，用户代码才能使用派生类到基类的转换。 不论D以什么方式继承B，D的成员函数和友元都能使用派生类到基类的转换。 如果D继承B的方式是公有的或者受保护的，则D的派生类的成员函数和友元可以使用D到B的类型转换；反之，如果D继承B的方式是私有的，则不能使用。 对于代码中的某个给定节点来说，如果基类的公有成员是可访问的，则派生类到基类的类型转换也是可访问的。\n友元对基类的访问权限由基类自身控制，即使对于派生类中的基类部分也是如此。\n友元关系不能继承，每个类负责控制各自成员的访问权限。\nc++ 派生类向基类转换的可访问性\n改变成员的可访问性 使用using声明可以改变派生类继承的某个名字的访问级别。新的访问级别由该using声明之前的访问说明符决定。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 class Base { public: std::size_t size() const { return n; } protected: std::size_t n; }; class Derived : private Base // 注意: 私有继承。继承而来的 size() 和 n 都是私有的 { public: // using 改变 size() 的可访问性为 public using Base::size; protected: // using 改变 n 的可访问性为 protected using Base::n; }; 派生类只能为那些它可以访问的名字提供using声明。\n默认情况下，使用class关键字定义的派生类是私有继承的，而使用struct关键字定义的派生类是公有继承的。\n建议显式地声明派生类的继承方式，不要仅仅依赖于默认设置。\n不存在从基类向派生类的隐式转换 之所以存在派生类向基类的隐式转换，是因为每个派生类对象都包含一个基类部分，而基类的引用或指针可以绑定到该基类部分上。一个基类既可以独立存在，也可以作为派生类的一部分存在。如果基类对象不是派生类对象的一部分，则它只含有基类定义的成员，而不含有派生类定义的成员，所以用基类的指针去访问派生类中基类没有的方法或成员，必然出现错误。（承诺过多）【PRIMER 534】\n多重继承与虚继承以及消除二义性方法 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 class Person { string s = \u0026#34;Person\u0026#34;; public: void sleep() { cout \u0026lt;\u0026lt; s + \u0026#34; sleep\u0026#34; \u0026lt;\u0026lt; endl; } void eat() { cout \u0026lt;\u0026lt; s + \u0026#34; eat\u0026#34; \u0026lt;\u0026lt; endl; } }; class Author : public Person\t// 标记【1】Author puplic 继承自 Person { string s = \u0026#34;Author\u0026#34;; public: void writeBook() { cout \u0026lt;\u0026lt; s + \u0026#34; wirte book\u0026#34; \u0026lt;\u0026lt; endl; } }; class Programmer : public Person\t// 标记【2】 { string s = \u0026#34;Programmer\u0026#34;; public: void writeCode() { cout \u0026lt;\u0026lt; s + \u0026#34; write Code\u0026#34; \u0026lt;\u0026lt; endl; } }; class Programmer_Author : public Programmer, public Author // 多重继承 { string s = \u0026#34;Programmer_Author\u0026#34;; }; int main(int argc, char* argv[]) { Programmer_Author pa; pa.writeBook(); pa.writeCode(); //pa.eat();\t// 标记【3】编译错误 pa.Person::eat(); pa.Programmer::sleep(); return 0; } /* 打印 Author wirte book Programmer write Code Person eat Person sleep */ 标记【3】处编译错误，是因为通过多重继承 Programmer_Author 类拥有 Programmer 类和 Author 类的一份拷贝，而 Programmer 类和 Author 类都分别拥有 Person 类的一份拷贝，所以 Programmer_Author 类拥有 Person 的两份拷贝，在调用 Person 类的两份接口时，编译器不清楚需要调用哪一份拷贝，从而产生错误。\n对于这个问题通常有两个解决方案：\n加上范围解析运算符（域区分符）确定调用哪一份拷贝。比如 pa.Programmer::sleep();\n使用虚拟继承，使得多重继承类 Programmer_Author 只有 Person 类的一份拷贝。\n1 2 3 // 在上面代码标记【1】标记【2】处加入 virtual 即可，这样 pa.eat(); 就不会产生错误了。 class Author : virtual public Person\t// 标记【1】 class Programmer : virtual public Person\t// 标记【2】 【总结】多重继承的优点是对象可以调用多个基类中的接口，但是容易出现继承上的二义性。\n多继承中构造函数的调用顺序 多继承中构造函数的调用顺序总结，构造顺序从上到下依次为：\n任何虚拟基类的构造函数按照它们被继承的顺序构造（而不是构造函数的初始化列表的顺序）； 任何非虚拟基类的构造函数按照它们被构造的顺序构造； 任何成员对象的构造按照它们声明的顺序构造，而不是在初始化列表中的顺序； 类自身的构造函数； 右值引用 右值引用就是必须绑定到右值的引用。可以通过\u0026amp;\u0026amp;来获得右值引用。\n一般而言，一个左值表达式表示的是一个对象的身份，而一个右值表达式表示的是对象的值。\n1 2 3 4 5 6 int i = 42;\t// ok：i 是左值 int \u0026amp;r = i; // ok：r 是左值引用 int \u0026amp;\u0026amp;rr = i; // error: 不能将一个右值引用绑定到左值上 int \u0026amp;r2 = i * 42; // error: i * 42 是右值，而 r2 是左值引用 const int \u0026amp;r3 = i * 42; // ok: 可以绑定一个 const 左值引用到右值 int \u0026amp;\u0026amp;rr2 = i * 42; // ok: 将右值引用 rr2 绑定到右值上 右值引用只能绑定到即将被销毁，并且没有其他用户的临时对象上。使用右值引用的代码可以自由地接管所引用对象的资源。\n变量表达式都是左值，所以不能将一个右值引用直接绑定到一个变量上，即使这个变量的类型是右值引用也不行。\n1 2 3 4 5 6 7 int \u0026amp;\u0026amp;rr1 = 42; // ok: rr1 是右值引用 //int \u0026amp;\u0026amp;rr2 = rr1; // error: 但此时作为表达式的 rr1 是左值，而 rr2 却是右值引用 int \u0026amp;\u0026amp;rr3 = std::move(rr1); int \u0026amp;\u0026amp;rr4 = rr1 * 1; rr1 = 5; cout \u0026lt;\u0026lt; \u0026#34;rr1 =\u0026#34; \u0026lt;\u0026lt; rr1 \u0026lt;\u0026lt; \u0026#34; rr3 = \u0026#34; \u0026lt;\u0026lt; rr3 \u0026lt;\u0026lt; \u0026#34; rr4 = \u0026#34; \u0026lt;\u0026lt; rr4 \u0026lt;\u0026lt; endl; // 打印: rr1 =5 rr3 = 5 rr4 = 42 调用move函数可以获得绑定在左值上的右值引用，此函数定义在头文件utility中。\n左值与右值 左值持久，右值短暂：左值有持久的状态，而右值要么是字面常量，要么是表达式求值的过程中创建的临时对象。\n由于右值引用只能绑定到临时的 对象上，可知：\n所引用的对象将要被销毁 该对象没有其他用户 这两个特性意味着：使用右值引用的代码可以自由地接管所引用的对象的资源。\n【PRIMER 471, 472】\n智能指针 智能指针主要用于管理在堆上分配的内存，它将普通的指针封装为一个栈对象。当栈对象的生存周期结束后，会在析构函数中释放掉申请的内存，从而防止内存泄漏。C++ 11中最常用的智能指针类型为shared_ptr，它采用引用计数的方法，记录当前内存资源被多少个智能指针引用。该引用计数的内存在堆上分配。当新增一个时引用计数加 1 ，当过期时引用计数减一。只有引用计数为 0 时，智能指针才会自动释放引用的内存资源。对shared_ptr进行初始化时不能将一个普通指针直接赋值给智能指针，因为一个是指针，一个是类，可以通过构造函数传入普通指针。（ 从auto_ptr也带一点，虽然C++ 11已经遗弃）\nstd::auto_ptr\u0026lt;string\u0026gt; ptr(new string);\nstd::shared_ptr\u0026lt;string\u0026gt; p1;\nstd::shared_ptr\u0026lt;list\u0026lt;int\u0026gt;\u0026gt; p2;\n1 2 3 4 5 6 7 auto_ptr\u0026lt;char*\u0026gt; ap(new char*); *ap = \u0026#34;ap1\u0026#34;; *ap = \u0026#34;ap2\u0026#34;; char **bp = new char*; *bp = \u0026#34;bp1\u0026#34;; cout \u0026lt;\u0026lt; *ap \u0026lt;\u0026lt; endl;\t// \u0026#34;ap2\u0026#34; cout \u0026lt;\u0026lt; *bp \u0026lt;\u0026lt; endl;\t// \u0026#34;bp1\u0026#34; 1 2 3 4 #include \u0026lt;memory\u0026gt; double *p = new double; shared_ptr\u0026lt;double\u0026gt; pshared(p);\t// 合法，显示转换，explicit conversion //shared_ptr\u0026lt;double\u0026gt; pshared = p; // 不合法，隐式转换，implicit conversion 1 2 3 4 5 6 7 8 int main(int argc, char* argv[]) { string str(\u0026#34;hello world!\u0026#34;); // 程序能运行，但是在要释放 pshared 指向的内存时会出错 // 因为 str 不是存在堆中，当 pshared 过期时，delete 运算符会用于非堆内存，造成错误 shared_ptr\u0026lt;string\u0026gt; pshared(\u0026amp;str); cout \u0026lt;\u0026lt; *pshared \u0026lt;\u0026lt; endl; getchar(); } auto_ptr 是C++98提供的解决方案，C++11已经摒弃，并提供了以下几种方案\nshared_ptr 被称为共享指针，用于管理多个智能指针共同拥有的动态分配对象，\nunique_ptr 唯一拥有指定的对象，相比普通指针，拥有 RAII 的特性使得程序出现异常时，动态资源可以得到释放。\nRAII，Resource Acquisition Is Initialization，资源获取即初始化： 其核心是把资源和对象的生命周期绑定，对象创建获取资源，对象销毁释放资源\nweak_ptr 是为了配合shared_ptr而引入的一种智能指针，因为它不具有普通指针的行为，没有重载operator*和-\u0026gt;,它的最大作用在于协助shared_ptr工作，像旁观者那样观测资源的使用情况。\n智能指针的内存泄露以及解决方法 当两个对象相互使用一个 shared_ptr 成员变量指向对方，会造成循环引用，使引用计数失效，从而导致内存泄漏。\n为了解决循环引用导致的内存泄漏，引入了 weak_ptr 弱指针，weak_ptr 的构造函数不会修改引用计数的值，从而不会对对象的内存进行管理，其类似一个普通指针，但不指向引用计数的共享内存，但是其可以检测到所管理的对象是否已经被释放，从而避免非法访问。\n为什么摒弃 auto_ptr 1 2 3 4 auto_ptr\u0026lt;string\u0026gt; p1(new string(\u0026#34;hello\u0026#34;)); auto_ptr\u0026lt;string\u0026gt; p2; p2 = p1;\t// 当 p1, p2 过期时，将删除同一个对象两次 解决之道：\n定义复制运算符，使之执行深复制 建立所有权概念，使同时只有一个智能指针可拥有它。这样，只有拥有对象的智能指针有权析构该对象，这是auto_ptr 的策略，unique_ptr 的策略更严格。 创建智能更高的指针，跟踪引用特定对象的智能指针数。这称为引用计数。 1 2 3 4 5 6 7 8 9 10 11 int main(int argc, char* argv[]) { auto_ptr\u0026lt;string\u0026gt; p1(new string(\u0026#34;hello\u0026#34;)); auto_ptr\u0026lt;string\u0026gt; p2; cout \u0026lt;\u0026lt; *p1 \u0026lt;\u0026lt; endl; // 正常打印 p2 = p1;\t// p1 丧失了对 string 对象的所有权，p1 此时是空指针 cout \u0026lt;\u0026lt; *p1 \u0026lt;\u0026lt; endl; // 编译通过，但运行时报错，因为试图提领空指针 getchar(); } //\t将 auto_ptr 换成 unique_ptr，编译器认为语句 p2 = p1; 非法，在编译阶段报错（因为 p1 不是临时右值）。 //\t将 auto_ptr 换成 shared_ptr，编译运行阶段都没问题，正常打印。 //\tshared_ptr 采用的策略是引用计数，赋值时，计数加一，过期时，计数减一。仅当最后一个指针过期时，才调用 delete。 1 2 shared_ptr\u0026lt;string\u0026gt; p1(new string(\u0026#34;hello\u0026#34;)); shared_ptr\u0026lt;string\u0026gt; p2(p1);\t// 合法，将右值 p1 赋给 p2 1 2 3 unique_ptr\u0026lt;string\u0026gt; p1(new string(\u0026#34;hello\u0026#34;)); //shared_ptr\u0026lt;string\u0026gt; p2(p1);\t// 不合法，右值 p1 是 unique_ptr，若能赋给 p2，则 p1，p2 指向同一个对象，导致 p1 不合法，此语句编译不通过 //unique_ptr\u0026lt;string\u0026gt; p2(p1);\t// 不合法，p1 不是临时右值，注意临时。 1 2 3 4 5 6 7 8 unique_ptr\u0026lt;string\u0026gt; foo() { unique_ptr\u0026lt;string\u0026gt; p1(new string(\u0026#34;hello\u0026#34;)); return p1; } // 函数返回的 unique_ptr\u0026lt;string\u0026gt; 为临时右值，此时可赋给另一个 unique_ptr 型指针 int main(int argc, char* argv[]) { unique_ptr\u0026lt;string\u0026gt; p2(foo()); } 左值，右值\n更多用法（C++ 11） shared_ptr和unique_ptr都支持的操作：\nshared_ptr独有的操作：\nmake_shared函数（定义在头文件memory中）在动态内存中分配一个对象并初始化它，返回指向此对象的shared_ptr。\n智能指针与普通指针的转换 1 2 3 4 5 6 7 8 9 10 11 12 void show(string s) { cout \u0026lt;\u0026lt; s \u0026lt;\u0026lt; endl; } int main() { std::shared_ptr\u0026lt;std::string\u0026gt; s = std::make_shared\u0026lt;std::string\u0026gt;(\u0026#34;hello\\n\u0026#34;); show(*s.get()); // s.get() 获得内置指针 string *，需要解引用传到show()中 // 特别注意，不要使用get()初始化另一个智能指针或为智能指针赋值。 return 0; } 1 2 3 4 5 6 7 shared_ptr\u0026lt;int\u0026gt; p(new int(42)); // reference count is 1 int *q = p.get(); // ok: but don\u0026#39;t use q in any way that might delete its pointer { // new block // undefined: two independent shared_ptrs point to the same memory shared_ptr\u0026lt;int\u0026gt;(q); } // block ends, q is destroyed, and the memory to which q points is freed int foo = *p; // undefined; the memory to which p points was freed 智能指针的get函数返回一个内置指针，指向智能指针管理的对象。主要用于向不能使用智能指针的代码传递内置指针。使用get返回指针的代码不能delete此指针。\n不要使用get初始化另一个智能指针或为智能指针赋值。\n【PRIMER 414】\nshared_ptr是否线程安全 std::shared_ptr的引用计数本身是安全且无锁的，但对象的读写则不是。也就是说std::shared_ptr对象的创建析构是线程安全的，但是多线程读写std::shared_ptr对象不是线程安全的。std::shared_ptr 内存是由于两个组成部分： 指向管理对象的指针 和 引用计数器。在读/写时，是直接对两个变量操作，不可能是原子类型的。因为 std::shared_ptr 有两个数据成员，读写操作不能原子化。使得多线程读写同一个 std::shared_ptr 对象需要加锁。\nunique_ptr 与shared_ptr不同，同一时刻只能有一个unique_ptr指向给定的对象。当unique_ptr被销毁时，它指向的对象也会被销毁。\nmake_unique函数（C++14新增，定义在头文件memory中）在动态内存中分配一个对象并初始化它，返回指向此对象的unique_ptr。\n1 2 3 unique_ptr\u0026lt;int\u0026gt; p1(new int(42)); // C++14 unique_ptr\u0026lt;int\u0026gt; p2 = make_unique\u0026lt;int\u0026gt;(42); 由于unique_ptr独占其指向的对象，因此unique_ptr不支持普通的拷贝或赋值操作。\nunique_ptr操作：\nrelease函数返回unique_ptr当前保存的指针并将其置为空。\nreset函数成员接受一个可选的指针参数，重新设置unique_ptr保存的指针。如果unique_ptr不为空，则它原来指向的对象会被释放。\n1 2 3 4 5 // 将所有权从 p1 (which points to the string Stegosaurus) 转移给 p2 unique_ptr\u0026lt;string\u0026gt; p2(p1.release()); // release makes p1 null unique_ptr\u0026lt;string\u0026gt; p3(new string(\u0026#34;Trex\u0026#34;)); // transfers ownership from p3 to p2 p2.reset(p3.release()); // reset deletes the memory to which p2 had pointed 调用release会切断unique_ptr和它原来管理的对象之间的联系。release返回的指针通常被用来初始化另一个智能指针或给智能指针赋值。如果没有用另一个智能指针保存release返回的指针，程序就要负责资源的释放。\n1 2 p2.release(); // WRONG: p2 won\u0026#39;t free the memory and we\u0026#39;ve lost the pointer auto p = p2.release(); // ok, but we must remember to delete(p) 不能拷贝unique_ptr的规则有一个例外：可以拷贝或赋值一个即将被销毁的unique_ptr（移动构造、移动赋值）。\n1 2 3 4 5 6 unique_ptr\u0026lt;int\u0026gt; clone(int p) { unique_ptr\u0026lt;int\u0026gt; ret(new int (p)); // . . . return ret; } 老版本的标准库包含了一个名为auto_ptr的类，\n类似shared_ptr，默认情况下unique_ptr用delete释放其指向的对象。unique_ptr的删除器同样可以重载，但unique_ptr管理删除器的方式与shared_ptr不同。定义unique_ptr时必须在尖括号中提供删除器类型。创建或reset这种unique_ptr类型的对象时，必须提供一个指定类型的可调用对象（删除器）。\n1 2 3 4 5 6 7 8 9 10 11 12 // p points to an object of type objT and uses an object of type delT to free that object // it will call an object named fcn of type delT unique_ptr\u0026lt;objT, delT\u0026gt; p (new objT, fcn); void f(destination \u0026amp;d /* other needed parameters */) { connection c = connect(\u0026amp;d); // open the connection // when p is destroyed, the connection will be closed unique_ptr\u0026lt;connection, decltype(end_connection)*\u0026gt; p(\u0026amp;c, end_connection); // use the connection // when f exits, even if by an exception, the connection will be properly closed } // 当 p 被摧毁时，自动调用 end_connection 函数 weak_ptr weak_ptr是一种不控制所指向对象生存期的智能指针，它指向一个由shared_ptr管理的对象。将weak_ptr绑定到shared_ptr不会改变shared_ptr的引用计数。如果shared_ptr被销毁，即使有weak_ptr指向对象，对象仍然有可能被释放。\n创建一个weak_ptr时，需要使用shared_ptr来初始化它。weak_ptr只能配合std::shared_ptr使用，不能单独使用。\n1 2 auto p = make_shared\u0026lt;int\u0026gt;(42); weak_ptr\u0026lt;int\u0026gt; wp(p); // wp weakly shares with p; use count in p is unchanged 使用weak_ptr访问对象时，必须先调用lock函数。该函数检查weak_ptr指向的对象是否仍然存在。如果存在，则返回指向共享对象的shared_ptr，否则返回空指针。\n1 2 3 4 5 if (shared_ptr\u0026lt;int\u0026gt; np = wp.lock()) { // true if np is not null // inside the if, np shares its object with p } 使用weak_ptr防止循环引用 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 #include \u0026lt;memory\u0026gt; #include \u0026lt;iostream\u0026gt; class Foo : public std::enable_shared_from_this\u0026lt;Foo\u0026gt; { public: Foo() { std::cout \u0026lt;\u0026lt; __PRETTY_FUNCTION__ \u0026lt;\u0026lt; std::endl; } ~Foo() { std::cout \u0026lt;\u0026lt; __PRETTY_FUNCTION__ \u0026lt;\u0026lt; std::endl; } void self() { mPtr = shared_from_this(); } private: // std::shared_ptr\u0026lt;Foo\u0026gt; mPtr; // 【1】由于循环引用，不会调用析构函数，改 mPtr 为 std::weak_ptr 类型即可 std::weak_ptr\u0026lt;Foo\u0026gt; mPtr; //【2】 }; int main() { { std::shared_ptr\u0026lt;Foo\u0026gt; c = std::make_shared\u0026lt;Foo\u0026gt;(); c-\u0026gt;self(); } return 0; } /** 注释【1】打开【2】，打印 Foo::Foo() Foo::~Foo() 注释【2】打开【1】，打印 Foo::Foo() 由于循环引用，不会调用析构函数 */ std::enable_shared_from_this\u0026lt;T\u0026gt;::shared_from_this 是个侵入式设计。为的解决传入this导致对象被析构两次的问题。\n什么情况下需要使用 shared_from_this()? 用于返回当前对象 this的std::shared_ptr类型指针时：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 #include \u0026lt;memory\u0026gt; #include \u0026lt;iostream\u0026gt; class Foo : public std::enable_shared_from_this\u0026lt;Foo\u0026gt; { public: Foo() { std::cout \u0026lt;\u0026lt; \u0026#34;Foo()\\n\u0026#34;; } ~Foo() { std::cout \u0026lt;\u0026lt; \u0026#34;~Foo()\\n\u0026#34;; } std::shared_ptr\u0026lt;Foo\u0026gt; getSelf() { return shared_from_this(); } }; int main() { Foo *foo = new Foo; std::shared_ptr\u0026lt;Foo\u0026gt; sp1(foo); std::shared_ptr\u0026lt;Foo\u0026gt; sp2 = sp1-\u0026gt;getSelf(); // 【1】为了对 foo对象进行共享 //std::shared_ptr\u0026lt;Foo\u0026gt; sp2(foo); // 【2】 // std::boolalpha 的作用是使 bool 型变量按照 false、true 的格式输出。如不使用该标识符，那么结果会按照 1、0 的格式输出 std::cout \u0026lt;\u0026lt; std::boolalpha \u0026lt;\u0026lt; (sp2.get() == foo) \u0026lt;\u0026lt; std::endl; std::cout \u0026lt;\u0026lt; sp1.use_count() \u0026lt;\u0026lt; \u0026#34; \u0026#34; \u0026lt;\u0026lt; sp2.use_count() \u0026lt;\u0026lt; std::endl; } /* 打印 Foo() true 2 2 ~Foo() */ 如果注释【1】打开【2】，则会析构两次，产生未定义的行为，打印如下\n1 2 3 4 5 6 7 Foo() true 1 1 ~Foo() ~Foo() free(): double free detected in tcache 2 已放弃 (核心已转储) 尽管sp1和sp2都指向了foo，但是却不共享计数，当析构的时候就会被析构两次，产生未定义行为。 std::weak_ptr可以接受std::shared_ptr参数来构造自己，std::shared_ptr也具有接受std::weak_ptr参数来构造自己。\nenable_shared_from_this 函数原型\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 template\u0026lt;typename _Tp\u0026gt; class enable_shared_from_this { protected: ... public: shared_ptr\u0026lt;_Tp\u0026gt; shared_from_this() { return shared_ptr\u0026lt;_Tp\u0026gt;(this-\u0026gt;_M_weak_this); } shared_ptr\u0026lt;const _Tp\u0026gt; shared_from_this() const { return shared_ptr\u0026lt;const _Tp\u0026gt;(this-\u0026gt;_M_weak_this); } private: ... mutable weak_ptr\u0026lt;_Tp\u0026gt; _M_weak_this; } enable_shared_from_this的子类需要返回自身的std::shared_ptr指针，那么就需要继承这个类。\n成员变量为什么是weak_ptr类型\n因为如果是std::shared_ptr类型，那么就永远无法析构对象自身。\n这个_M_weak_this不是这个类中初始化，而是在shared_ptr中初始化，初始化的值就是this。因此如果智能指针类型是std::shared_ptr，那么这个类对象一旦创建，引用计数就是1，那么永远也无法析构。\n为什么不直接传回this\nstd::shared_ptr的引用计数增加是需要用operator=实现的。\n基于引用计数的智能指针实现 源码在./sources/mine/SmartPtr.cpp\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 #include \u0026lt;iostream\u0026gt; #define showfunc std::cout \u0026lt;\u0026lt; __PRETTY_FUNCTION__ \u0026lt;\u0026lt; std::endl; template \u0026lt;class T\u0026gt; class SmartPtr { private: T *mPtr; size_t *mRef; public: SmartPtr(T *p = 0); SmartPtr(const SmartPtr \u0026amp;src); // 加上 explicit 可以拒绝隐式拷贝构造 SmartPtr \u0026amp;operator=(const SmartPtr \u0026amp;rhs); T *operator-\u0026gt;() const; T \u0026amp;operator*() const; ~SmartPtr(); private: void decRef(); //只会被其它成员函数所调用 public: // for debug int get_ref_count() const; }; template \u0026lt;class T\u0026gt; SmartPtr\u0026lt;T\u0026gt;::SmartPtr(T *p) : mPtr(p), // mPtr 指向 p 所指向的内存 mRef(new size_t(1)) // 引用计数初始化为 1 { showfunc; } template \u0026lt;class T\u0026gt; SmartPtr\u0026lt;T\u0026gt;::SmartPtr(const SmartPtr \u0026amp;src) { showfunc; mPtr = src.mPtr; mRef = src.mRef; ++*mRef; } template \u0026lt;class T\u0026gt; SmartPtr\u0026lt;T\u0026gt; \u0026amp;SmartPtr\u0026lt;T\u0026gt;::operator=(const SmartPtr\u0026lt;T\u0026gt; \u0026amp;rhs) { showfunc; ++*rhs.mRef; decRef(); mPtr = rhs.mPtr; mRef = rhs.mRef; return *this; } template \u0026lt;class T\u0026gt; T *SmartPtr\u0026lt;T\u0026gt;::operator-\u0026gt;() const { showfunc; if (mPtr) { return mPtr; } throw std::runtime_error(\u0026#34;dereference of nullptr pointer\u0026#34;); } template \u0026lt;class T\u0026gt; T \u0026amp;SmartPtr\u0026lt;T\u0026gt;::operator*() const { showfunc; if (mPtr) { return *mPtr; } throw std::runtime_error(\u0026#34;dereference of nullptr pointer\u0026#34;); } template \u0026lt;class T\u0026gt; SmartPtr\u0026lt;T\u0026gt;::~SmartPtr() { showfunc; decRef(); } template \u0026lt;class T\u0026gt; void SmartPtr\u0026lt;T\u0026gt;::decRef() //只会被其它成员函数所调用 { std::cout \u0026lt;\u0026lt; \u0026#34;after call decRef(): *mPtr = \u0026#34; \u0026lt;\u0026lt; *mPtr \u0026lt;\u0026lt; \u0026#34;, *mRef = \u0026#34; \u0026lt;\u0026lt; *mRef - 1 \u0026lt;\u0026lt; std::endl; if (0 == --*mRef) // 引用计数先自减，为 0 后，释放内存 { delete mPtr; delete mRef; std::cout \u0026lt;\u0026lt; \u0026#34;real delete\u0026#34; \u0026lt;\u0026lt; std::endl; } } template \u0026lt;class T\u0026gt; int SmartPtr\u0026lt;T\u0026gt;::get_ref_count() const { return *mRef; } int main() { SmartPtr\u0026lt;int\u0026gt; p1(new int(999)); SmartPtr\u0026lt;int\u0026gt; p2(new int(888)); SmartPtr\u0026lt;int\u0026gt; p3(p1); p2 = p3; // 拷贝赋值运算符 SmartPtr\u0026lt;int\u0026gt; p4 = p2; // 隐式拷贝构造 } /* SmartPtr\u0026lt;T\u0026gt;::SmartPtr(T*) [with T = int] SmartPtr\u0026lt;T\u0026gt;::SmartPtr(T*) [with T = int] SmartPtr\u0026lt;T\u0026gt;::SmartPtr(const SmartPtr\u0026lt;T\u0026gt;\u0026amp;) [with T = int] SmartPtr\u0026lt;T\u0026gt;\u0026amp; SmartPtr\u0026lt;T\u0026gt;::operator=(const SmartPtr\u0026lt;T\u0026gt;\u0026amp;) [with T = int] after call decRef(): *mPtr = 888, *mRef = 0 real delete SmartPtr\u0026lt;T\u0026gt;::SmartPtr(const SmartPtr\u0026lt;T\u0026gt;\u0026amp;) [with T = int] SmartPtr\u0026lt;T\u0026gt;::~SmartPtr() [with T = int] after call decRef(): *mPtr = 999, *mRef = 3 SmartPtr\u0026lt;T\u0026gt;::~SmartPtr() [with T = int] after call decRef(): *mPtr = 999, *mRef = 2 SmartPtr\u0026lt;T\u0026gt;::~SmartPtr() [with T = int] after call decRef(): *mPtr = 999, *mRef = 1 SmartPtr\u0026lt;T\u0026gt;::~SmartPtr() [with T = int] after call decRef(): *mPtr = 999, *mRef = 0 real delete */ 基于范围的 for 循环 1 2 3 4 5 6 7 8 9 10 11 12 13 int main(int argc, char* argv[]) { int arr[10] = {1, 2, 3, 4, 5, 6}; for (int \u0026amp;x : arr)\t// 只有使用引用 \u0026amp; 才能通过 x 修改 arr 里的值 { cout \u0026lt;\u0026lt; (x % 2 ? \u0026#34;奇\u0026#34; : \u0026#34;偶\u0026#34;) \u0026lt;\u0026lt; \u0026#39; \u0026#39;; x = x + 1; } cout \u0026lt;\u0026lt; endl; for (int x : arr) cout \u0026lt;\u0026lt; x \u0026lt;\u0026lt; \u0026#39; \u0026#39;; getchar(); } //\t奇 偶 奇 偶 奇 偶 偶 偶 偶 偶 //\t2 3 4 5 6 7 1 1 1 1 处理多维数组 使用范围for语句处理多维数组时，为了避免数组被自动转换成指针，语句中的外层循环控制变量必须声明成引用类型。\n1 2 3 for (const auto \u0026amp;row : ia) // for every element in the outer array for (auto col : row) // for every element in the inner array cout \u0026lt;\u0026lt; col \u0026lt;\u0026lt; endl; 如果row不是引用类型，编译器初始化row时会自动将数组形式的元素转换成指向该数组内首元素的指针，这样得到的row就是int*类型，而之后的内层循环则试图在一个int*内遍历，程序将无法通过编译。\n1 2 for (auto row : ia) for (auto col : row) 使用范围for语句处理多维数组时，除了最内层的循环，其他所有外层循环的控制变量都应该定义成引用类型。\nlambda 表达式 find_if函数接受两个迭代器参数和一个谓词参数。迭代器参数用于指定序列范围，之后对序列中的每个元素调用给定谓词，并返回第一个使谓词返回非0值的元素。如果不存在，则返回尾迭代器。\n对于一个对象或表达式，如果可以对其使用调用运算符()，则称它为可调用对象（callable object）。可以向算法传递任何类别的可调用对象。\n一个lambda表达式表示一个可调用的代码单元，类似未命名的内联函数，但可以定义在函数内部。其形式如下：\n1 [capture list] (parameter list) -\u0026gt; return type { function body } 其中，capture list（捕获列表）是一个由lambda所在函数定义的局部变量的列表（通常为空）。return type、parameter list和function body与普通函数一样，分别表示返回类型、参数列表和函数体。但与普通函数不同，lambda必须使用尾置返回类型，且不能有默认实参。\n定义lambda时可以省略参数列表和返回类型，但必须包含捕获列表和函数体。省略参数列表等价于指定空参数列表。省略返回类型时，若函数体只是一个return语句，则返回类型由返回表达式的类型推断而来。否则返回类型为void。\n1 2 auto f = [] { return 42; }; cout \u0026lt;\u0026lt; f() \u0026lt;\u0026lt; endl; // prints 42 lambda可以使用其所在函数的局部变量，但必须先将其包含在捕获列表中。捕获列表只能用于局部非static变量，lambda可以直接使用局部static变量和其所在函数之外声明的名字。\n1 2 3 // get an iterator to the first element whose size() is \u0026gt;= sz auto wc = find_if(words.begin(), words.end(), [sz](const string \u0026amp;a) { return a.size() \u0026gt;= sz; }); for_each函数接受一个输入序列和一个可调用对象，它对输入序列中的每个元素调用此对象。\n1 2 3 // print words of the given size or longer, each one followed by a space for_each(wc, words.end(), [] (const string \u0026amp;s) { cout \u0026lt;\u0026lt; s \u0026lt;\u0026lt; \u0026#34; \u0026#34;; }); lambda捕获变量和返回 被lambda捕获的变量的值是在lambda创建时拷贝，而不是调用时拷贝。在lambda创建后修改局部变量不会影响lambda内对应的值。\n1 2 3 4 5 6 7 size_t v1 = 42; // local variable // copies v1 into the callable object named f auto f = [v1] { return v1; }; // auto f = [v1] { return ++v1; }; // error: increment of read-only variable ‘v1’，不可以修改 v1 // auto f = [v1] () mutable { return ++v1; }; // 在参数列表后加 mutable 就可以解决问题。返回 43 v1 = 0; auto j = f(); // j is 42; f stored a copy of v1 when we created it 默认情况下，对于值方式捕获的变量，lambda不能修改其值。如果希望修改，就必须在参数列表后添加关键字mutable。\n1 2 3 4 5 size_t v1 = 42; // local variable // f can change the value of the variables it captures auto f = [v1] () mutable { return ++v1; }; v1 = 0; auto j = f(); // j is 43 lambda可以以引用方式捕获变量，但必须保证lambda执行时变量存在。\n1 2 3 4 5 size_t v1 = 42; // local variable // the object f2 contains a reference to v1 auto f2 = [\u0026amp;v1] { return ++v1; }; v1 = 0; auto j = f2(); // j is 1; f2 refers to v1; it doesn\u0026#39;t store it 可以让编译器根据lambda代码隐式捕获函数变量，方法是在捕获列表中写一个\u0026amp;或=符号。\u0026amp;为引用捕获，=为值捕获。\n可以混合使用显式捕获和隐式捕获。混合使用时，捕获列表中的第一个元素必须是\u0026amp;或=符号，用于指定默认捕获方式。显式捕获的变量必须使用与隐式捕获不同的方式。\n1 2 3 4 5 6 // os implicitly captured by reference; c explicitly captured by value for_each(words.begin(), words.end(), [\u0026amp;, c] (const string \u0026amp;s) { os \u0026lt;\u0026lt; s \u0026lt;\u0026lt; c; }); // os explicitly captured by reference; c implicitly captured by value for_each(words.begin(), words.end(), [=, \u0026amp;os] (const string \u0026amp;s) { os \u0026lt;\u0026lt; s \u0026lt;\u0026lt; c; }); lambda捕获列表形式：\n本小节在【PRIMER 350~354】\n参数绑定 std::bind可以绑定普通函数，但不能区分重载，也可以绑定类内成员函数。也可以通过占位符方便更换形参。\nstd::bind在默认情况下，是依靠值传递，使用了std::ref来包裹传入参数才是使用引用传递。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 #include \u0026lt;functional\u0026gt; #include \u0026lt;iostream\u0026gt; class Foo { public: Foo() = default; void add(const int \u0026amp;lhs, const int \u0026amp;rhs) { std::cout \u0026lt;\u0026lt; __PRETTY_FUNCTION__ \u0026lt;\u0026lt; \u0026#34; sum = \u0026#34; \u0026lt;\u0026lt; (lhs + rhs) \u0026lt;\u0026lt; std::endl; } }; void f(int n) { std::cout \u0026lt;\u0026lt; \u0026#34;void f(int n)\u0026#34; \u0026lt;\u0026lt; std::endl; } void f(double n) { std::cout \u0026lt;\u0026lt; \u0026#34;void f(double n)\u0026#34; \u0026lt;\u0026lt; std::endl; } int main() { auto g1 = [] { f(1); }; // OK auto g11 = [] { f(1.0); }; // OK //auto g2 = std::bind(f, 2); // 错误，因为无法确定要绑定哪个重载的 f() auto g3 = std::bind(static_cast\u0026lt;void (*)(int)\u0026gt;(f), 3.0); // OK，强行转换为 void f(int n)，即使传的形参是 double g1(); g11(); g3(); Foo foo; auto g4 = std::bind(\u0026amp;Foo::add, \u0026amp;foo, 1, 2); // std::_Bind\u0026lt;void (Foo::*(Foo *, int, int)\u0026gt; g4 auto g5 = std::bind(\u0026amp;Foo::add, \u0026amp;foo, std::placeholders::_1, std::placeholders::_2); auto g6 = std::bind(\u0026amp;Foo::add, \u0026amp;foo, 1, std::placeholders::_2); g4(); // 1 + 2 = 3 g4(100); // 1 + 2 = 3 g4(100, 200); // 1 + 2 = 3 g5(3, 4); // 3 + 4 = 7 g6(3, 4); // 1 + 4 = 5 // g6(3); // error return 0; } /* void f(int n) void f(double n) void f(int n) void Foo::add(const int\u0026amp;, const int\u0026amp;) sum = 3 void Foo::add(const int\u0026amp;, const int\u0026amp;) sum = 3 void Foo::add(const int\u0026amp;, const int\u0026amp;) sum = 3 void Foo::add(const int\u0026amp;, const int\u0026amp;) sum = 7 void Foo::add(const int\u0026amp;, const int\u0026amp;) sum = 5 */ bind函数定义在头文件functional中，相当于一个函数适配器，它接受一个可调用对象，生成一个新的可调用对象来适配原对象的参数列表。一般形式如下：\n1 auto newCallable = bind(callable, arg_list); 其中，newCallable本身是一个可调用对象，arg_list是一个以逗号分隔的参数列表，对应给定的callable的参数。之后调用newCallable时，newCallable会再调用callable，并传递给它arg_list中的参数。arg_list中可能包含形如_n的名字，其中n是一个整数。这些参数是占位符，表示newCallable的参数，它们占据了传递给newCallable的参数的位置。数值n表示生成的可调用对象中参数的位置：_1为newCallable的第一个参数，_2为newCallable的第二个参数，依次类推。这些名字都定义在命名空间placeholders中，它又定义在命名空间std中，因此使用时应该进行双重限定。\n1 2 3 4 5 6 7 8 9 using std::placeholders::_1; using namespace std::placeholders; bool check_size(const string \u0026amp;s, string::size_type sz); // check6 is a callable object that takes one argument of type string // and calls check_size on its given string and the value 6 auto check6 = bind(check_size, _1, 6); string s = \u0026#34;hello\u0026#34;; bool b1 = check6(s); // check6(s) calls check_size(s, 6) bind函数可以调整给定可调用对象中的参数顺序。\n1 2 3 4 // sort on word length, shortest to longest sort(words.begin(), words.end(), isShorter); // sort on word length, longest to shortest sort(words.begin(), words.end(), bind(isShorter, _2, _1)); 默认情况下，bind函数的非占位符参数被拷贝到bind返回的可调用对象中。但有些类型不支持拷贝操作。\n如果希望传递给bind一个对象而又不拷贝它，则必须使用标准库的ref函数。ref函数返回一个对象，包含给定的引用，此对象是可以拷贝的。cref函数生成保存const引用的类。\n1 2 ostream \u0026amp;print(ostream \u0026amp;os, const string \u0026amp;s, char c); for_each(words.begin(), words.end(), bind(print, ref(os), _1, \u0026#39; \u0026#39;)); 【PRIMER 354~356】\n函数调用运算符 重载operator()运算符 函数调用运算符必须定义为成员函数。一个类可以定义多个不同版本的调用运算符，相互之间必须在参数数量或类型上有所区别。\n该类也可以称为可调用对象，或函数对象。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 class PrintString { public: PrintString(ostream \u0026amp;o = cout, char c = \u0026#39; \u0026#39;): os(o), sep(c) { } void operator()(const string \u0026amp;s) const { os \u0026lt;\u0026lt; s \u0026lt;\u0026lt; sep; } private: ostream \u0026amp;os; // 用于写入的目的流 char sep; // 用于将不同输出隔开的字符 }; PrintString printer; // uses the defaults; prints to cout printer(s); // prints s followed by a space on cout 如果类定义了调用运算符，则该类的对象被称作函数对象（function object），函数对象常常作为泛型算法的实参。\n1 for_each(vs.begin(), vs.end(), PrintString(cerr, \u0026#39;\\n\u0026#39;)); lambda是函数对象 编写一个lambda后，编译器会将该表达式转换成一个未命名类的未命名对象，类中含有一个重载的函数调用运算符。\n1 2 3 4 5 6 7 8 9 10 11 12 13 // sort words by size, but maintain alphabetical order for words of the same size stable_sort(words.begin(), words.end(), [](const string \u0026amp;a, const string \u0026amp;b) { return a.size() \u0026lt; b.size(); }); // acts like an unnamed object of a class that would look something like class ShorterString { public: bool operator()(const string \u0026amp;s1, const string \u0026amp;s2) const { return s1.size() \u0026lt; s2.size(); } }; lambda默认不能改变它捕获的变量。因此在默认情况下，由lambda产生的类中的函数调用运算符是一个const成员函数。如果lambda被声明为可变的，则调用运算符就不再是const函数了。\nlambda通过引用捕获变量时，由程序负责确保lambda执行时该引用所绑定的对象确实存在。因此编译器可以直接使用该引用而无须在lambda产生的类中将其存储为数据成员。相反，通过值捕获的变量被拷贝到lambda中，此时lambda产生的类必须为每个值捕获的变量建立对应的数据成员，并创建构造函数，用捕获变量的值来初始化数据成员。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 // get an iterator to the first element whose size() is \u0026gt;= sz auto wc = find_if(words.begin(), words.end(), [sz](const string \u0026amp;a) { return a.size() \u0026gt;= sz; }); // would generate a class that looks something like class SizeComp { public: SizeComp(size_t n): sz(n) { } // parameter for each captured variable // call operator with the same return type, parameters, and body as the lambda bool operator()(const string \u0026amp;s) const { return s.size() \u0026gt;= sz; } private: size_t sz; // a data member for each variable captured by value }; lambda产生的类不包含默认构造函数、赋值运算符和默认析构函数，它是否包含默认拷贝/移动构造函数则通常要视捕获的变量类型而定。\n标准库定义的函数对象\n标准库在头文件functional中定义了一组表示算术运算符、关系运算符和逻辑运算符的类，每个类分别定义了一个执行命名操作的调用运算符。这些类都被定义为模板的形式，可以为其指定具体的应用类型（即调用运算符的形参类型）。\n关系运算符的函数对象类通常被用来替换算法中的默认运算符，这些类对于指针同样适用。\n1 2 3 4 5 6 vector\u0026lt;string *\u0026gt; nameTable; // vector of pointers // error: the pointers in nameTable are unrelated, so \u0026lt; is undefined sort(nameTable.begin(), nameTable.end(), [](string *a, string *b) { return a \u0026lt; b; }); // ok: library guarantees that less on pointer types is well defined sort(nameTable.begin(), nameTable.end(), less\u0026lt;string*\u0026gt;()); 可调用对象与function 调用形式指明了调用返回的类型以及传递给调用的实参类型。不同的可调用对象可能具有相同的调用形式。\n标准库function类型是一个模板，定义在头文件functional中，用来表示对象的调用形式。\n创建一个具体的function类型时必须提供其所表示的对象的调用形式。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 // ordinary function int add(int i, int j) { return i + j; } // function-object class struct div { int operator()(int denominator, int divisor) { return denominator / divisor; } }; function\u0026lt;int(int, int)\u0026gt; f1 = add; // function pointer function\u0026lt;int(int, int)\u0026gt; f2 = div(); // object of a function-object class function\u0026lt;int(int, int)\u0026gt; f3 = [](int i, int j) { return i * j; }; // lambda cout \u0026lt;\u0026lt; f1(4,2) \u0026lt;\u0026lt; endl; // prints 6 cout \u0026lt;\u0026lt; f2(4,2) \u0026lt;\u0026lt; endl; // prints 2 cout \u0026lt;\u0026lt; f3(4,2) \u0026lt;\u0026lt; endl; // prints 8 不能直接将重载函数的名字存入function类型的对象中，这样做会产生二义性错误。消除二义性的方法是使用lambda或者存储函数指针而非函数名字。\nC++11新标准库中的function类与旧版本中的unary_function和binary_function没有关系，后两个类已经被bind函数代替。\n","date":"2021-07-08T20:18:41+08:00","image":"http://localhost:1313/posts/c++%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93/C++_cover_hu_2b4e6cee0d01b242.jpg","permalink":"http://localhost:1313/posts/c++%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93/","title":"C++知识点总结"},{"content":"前言 如何评价一个算法模型的检测结果是好还是不好呢？\n检测结果的正确/错误类型 正确结果(True Positive)：算法检测到了某类物体 (Positive)，图中也确实有这个物体，检测结果正确(True)。（个人理解，这里其实成为正阳性更准确） 假阳性(False Positive)：算法检测到了某类物体 (Positive)，但图中其实没有这个物体，检测结果错误 (False)。通常我们把它也称为误检。 假阴性 (False Negative)：算法没有检测到物体 (Negative)，但图中其实有某类物体，检测结果错误(False)。通常，我们把它也称为漏检。 这里检测到的衡量标准：对于某个检测框，图中存在同类型的真值框且与之交并比大于阈值（通常取0.5） 例子： 上面检测有 7 张图像，其中绿色边界框表示 15 个真值框，红色边界框表示 24 个检测框。每个检测到的对象都有一个置信度，并由一个字母 (A,B,\u0026hellip;,Y) 标识。\n上表显示了边界框及其相应的置信度。最后一列将检测标识为 TP 或 FP。在这个例子中，如果 IOU 大于30% 则认为 TP，否则为 FP。通过查看上面的图像，我们可以大致判断检测是 TP 还是 FP\n更具体的分析，可以参考 目标检测指标\n目标检测评价指标 召回率、准确率 真值框总数与检测算法无关，因此只需将检测结果区分为TP和FP即可计算 recall 和 precision\n两种极端情况：\n检测器将所有锚框都判断为物体：召回率≈100%，但大量背景框预测为物体，FP很高，准确率很低； 检测器只输出确信度最高的1个检测框：以很大概率检测正确，准确率=100%，但因为大量物体被预测为背景，FN很高，召回率很低。 理想情况： 一个完美的检测器应该有100%召回率和100%的准确率；在算法能力有限的情况下，应该平衡二者。\n通常做法： 将检测框按置信度排序，仅输出置信度大于某个阈值的若干个框。\nAP（Average Precision） 为得到阈值无关的评分，可以遍历阈值，并对 Precision 和 Recall 求平均。\n具体做法：\n检测框按置信度排序，取前K个框计算 Precision 和 Recall。 遍历K从1至全部检测框，将得到的 Precision 和 Recall 值绘制在坐标系上，得到 PR 曲线。 定义 Average Precision = Precision 对 Recall 的平均值,即 PR 曲线下的面积,作为检测器的性能衡量指标。 笔者觉得这个指标很不科学！\n原因是：一个好的检测器只需要在某个置信度阈值下能够检测出所有真实的目标，并且没有漏检和误检，那么就可以确定该检测器非常好，而不需要在其他置信度阈值下都表现好。\nMean AP 分类别统计AP，并按类别平均即得到 Mean AP。\n部分数据集（如 COCO)还要求在不同的 loU (上面提到的IOU 大于30% )阈值下计算 Mean AP 并平均，作为最终评分；从0.5 ~ 0.05，每个0.05都会取一个IoU的阈值，计算 Mean AP，最终将这几个值进行平均，作为最终的一个评分。\n可衡量检测器在不同定位精度要求下的性能。\n","date":"2021-06-21T10:45:26+08:00","image":"http://localhost:1313/posts/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E6%A8%A1%E5%9E%8B%E7%9A%84%E8%AF%84%E4%BC%B0%E6%96%B9%E6%B3%95/target_detection_cover_hu_e1bef4f3cd1c2e13.jpg","permalink":"http://localhost:1313/posts/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E6%A8%A1%E5%9E%8B%E7%9A%84%E8%AF%84%E4%BC%B0%E6%96%B9%E6%B3%95/","title":"目标检测模型的评估方法"},{"content":"在学习机器学习和神经网络过程中，对于模型参数和模型计算量需要做出评估，这篇文章介绍几种常见操作对模型带来的参数量和计算量，更专业的表示为空间复杂度和时间复杂度，后续再补充。\n注意：下面计算的是都是单层的参数量和计算量，并且是对于一个样本的计算量，如果计算批量样本，需要给下面计算量乘以BatchSize。\n卷积层 卷积运算的参数量 计算公式：$parameter = (k_{w} \\times k_{h} \\times C_{in} + 1 )\\times filter\\ number$；\n即：$参数量\\ =（kernal_{wide} \\times kernal_{high} \\times 输入的特征图的通道数 + 偏置 ）\\times 当前层filter数量$；\n以VGG-16模型的Conv1-1卷积为例，输入$224 \\times 224 \\times 3$，有$64$个$3 \\times 3$大小filter，输出feature map为$224 \\times 224 \\times 64$，那么该层具有的参数量为：$(3 \\times 3 \\times 3 + 1)\\times 64 = 1792$\n卷积运算的计算量 FLOPs(Floating Point Operations)，浮点运算次数，用来衡量算法的时间复杂度； FLOPS(Floating Point Operations per Seconds)，单位时间浮点运算次数，用来衡量硬件计算性能。 $FLOPs=\\left[\\left(C_{i n} \\times k_{w} \\times k_{h}\\right)+\\left(C_{i n} \\times k_{w} \\times k_{h}-1\\right)+1\\right] \\times C_{o u t} \\times W_{out} \\times H_{out}$\n$k_{w}$ 和 $k_{h}$ 分别表示卷积核的宽和高，其中 $C_{i n} \\times k_{w} \\times k_{h}$ 表示乘法计算量, $C_{i n} \\times k_{w} \\times k_{h}-1$ 表示加法计算量(可以这样理解，需要把乘法计算得到的$C_{i n} \\times k_{w} \\times k_{h}$个数字加这么多次), $+1$ 表示偏置, $C_{\\text {out }} \\times W_{out} \\times H_{out}$ 表示 feature $\\operatorname{map}$ 中的所有元素， $W_{out} \\text{、} H_{out}$ 表示feature map的宽和高。\n全连接层 全连接运算的参数量 计算公式: $parameter =\\left(N_{i n}+1\\right) \\times N_{\\text {out }}$\n$N_{i n}$ 表示输入特征向量的维数, +1表示偏置, $N_{out}$ 表示输出向量的维数\n全连接运算的计算量 $FLOPs=[N_{in}+(N_{in}-1)+1] \\times N_{out}$\n$N_{in}$ 和 $N_{out}$ 分别表示输入的特征数和输出的特征数。\n其中$N_{in}$表示乘法运算量, $N_{in}-1$ 表示加法运算量，+1表示偏置。\n池化层 池化层运算的参数量 无参数。\n池化层运算的计算量 $FLOPs=C_{out} \\times H_{out} \\times W_{out} \\times k \\times k$\n$k \\times k$ 代表在原特征图区域$k \\times k$ 的 max ，sum或者avg池化操作；\n$H_{out} \\times W_{out}$代表输出特征图大小，$C_{out}$代表输出通道数。\n案例 参数量 VGG-19模型，输入图片大小为$3 \\times 224 \\times 224$，表示为$3$通道$224 \\times 224$尺寸的图像输入，模型分为五组卷积和三层全连接层。\n$(3 \\times 3 \\times 3 + 1) \\times 64 + (3 \\times 3 \\times 64 + 1) \\times 64 + (3 \\times 3 \\times 64 + 1) \\times 128 + (3 \\times 3 \\times 128 + 1) \\times 128 +$ $(3 \\times 3 \\times 128 + 1) \\times 256 + (3 \\times 3 \\times 256 + 1) \\times 256 + (3 \\times 3 \\times 256 + 1) \\times 256 + (3 \\times 3 \\times 256 + 1) \\times 256 +$ $(3 \\times 3 \\times 256 + 1) \\times 512 + (3 \\times 3 \\times 512 + 1) \\times 512 + (3 \\times 3 \\times 512 + 1) \\times 512 + (3 \\times 3 \\times 512 + 1) \\times 512 +$ $(3 \\times 3 \\times 512 + 1) \\times 512 + (3 \\times 3 \\times 512 + 1) \\times 512 + (3 \\times 3 \\times 512 + 1) \\times 512 + (3 \\times 3 \\times 512 + 1) \\times 512 +$ $(512 \\times 7 \\times 7 + 1) \\times 4096 + (4096 + 1) \\times 4096 + (4096 + 1) \\times 1000$\n计算得143667240，乘以一个浮点数占4个字节，得574668960字节，为548.04MB，和论文中的数量大致相等。\n计算量 VGG-19模型，输入图片大小为$3 \\times 224 \\times 224$，表示为$3$通道$224 \\times 224$尺寸的图像输入，模型分为五组卷积和三层全连接层。\n第一组卷积 $(3 \\times 3 \\times 3 + 3 \\times 3 \\times 3 - 1 + 1) \\times 64 \\times 224 \\times 224 = 173408256$ $(64 \\times 3 \\times 3 + 64 \\times 3 \\times 3 - 1 + 1) \\times 64 \\times 224 \\times 224 = 3699376128$ 池化 $64 \\times 112 \\times 112 \\times 2 \\times 2 = 3211264$ 第二组卷积 $(64 \\times 3 \\times 3 + 64 \\times 3 \\times 3 - 1 + 1) \\times 128 \\times 112 \\times 112 = 1849688064$ $(128 \\times 3 \\times 3 + 128 \\times 3 \\times 3 - 1 + 1) \\times 128 \\times 112 \\times 112 = 3699376128$ 池化 $128 \\times 56 \\times 56 \\times 2 \\times 2 = 1605632$ 第三组卷积 $(128 \\times 3 \\times 3 + 128 \\times 3 \\times 3 - 1 + 1) \\times 256 \\times 56 \\times 56 = 1849688064$ $(256 \\times 3 \\times 3 + 256 \\times 3 \\times 3 - 1 + 1) \\times 256 \\times 56 \\times 56 = 3699376128$ $(256 \\times 3 \\times 3 + 256 \\times 3 \\times 3 - 1 + 1) \\times 256 \\times 56 \\times 56 = 3699376128$ $(256 \\times 3 \\times 3 + 256 \\times 3 \\times 3 - 1 + 1) \\times 256 \\times 56 \\times 56 = 3699376128$ 池化 $256 \\times 28 \\times 28 \\times 2 \\times 2 = 802816$ 第四组卷积 $(256 \\times 3 \\times 3 + 256 \\times 3 \\times 3 - 1 + 1) \\times 512 \\times 28 \\times 28 = 1849688064$ $(512 \\times 3 \\times 3 + 512 \\times 3 \\times 3 - 1 + 1) \\times 512 \\times 28 \\times 28 = 3699376128$ $(512 \\times 3 \\times 3 + 512 \\times 3 \\times 3 - 1 + 1) \\times 512 \\times 28 \\times 28 = 3699376128$ $(512 \\times 3 \\times 3 + 512 \\times 3 \\times 3 - 1 + 1) \\times 512 \\times 28 \\times 28 = 3699376128$ 池化 $512 \\times 14 \\times 14 \\times 2 \\times 2 = 401408$ 第五组卷积 $(512 \\times 3 \\times 3 + 512 \\times 3 \\times 3 - 1 + 1) \\times 512 \\times 14 \\times 14 = 924844032$ $(512 \\times 3 \\times 3 + 512 \\times 3 \\times 3 - 1 + 1) \\times 512 \\times 14 \\times 14 = 924844032$ $(512 \\times 3 \\times 3 + 512 \\times 3 \\times 3 - 1 + 1) \\times 512 \\times 14 \\times 14 = 924844032$ $(512 \\times 3 \\times 3 + 512 \\times 3 \\times 3 - 1 + 1) \\times 512 \\times 14 \\times 14 = 924844032$ 池化 $512 \\times 7 \\times 7 \\times 2 \\times 2 = 100352$ 第一个全连接层 $(512 \\times 7 \\times 7 + 512 \\times 7 \\times 7 - 1 + 1) \\times 4096 = 205520896$ 第二个全连接层 $(4096 + 4096 - 1 + 1) * 4096 = 33554432$ 第三个全连接层 $(4096 + 4096 - 1 + 1) * 1000 = 8192000$ 共计：39264124928 = 39.2 bilion次运算，将这个值换算为multiply-adds运算，需要除以2，得到19.6bilion，该值与论文中的计算量一致。（此次运算忽略了ReLu激活层的计算量，该计算量较小，可以忽略） 工具 torchinfo torchinfo 该工具可以自动统计网络模型的参数量和计算量。\n例子：\n1 2 3 4 5 from torchinfo import summary model = ConvNet() batch_size = 16 summary(model, input_size=(batch_size, 1, 28, 28)) 结果：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 ========================================================================================== Layer (type:depth-idx) Output Shape Param # ========================================================================================== ├─Conv2d: 1-1 [16, 10, 24, 24] 260 ├─Conv2d: 1-2 [16, 20, 8, 8] 5,020 ├─Dropout2d: 1-3 [16, 20, 8, 8] -- ├─Linear: 1-4 [16, 50] 16,050 ├─Linear: 1-5 [16, 10] 510 ========================================================================================== Total params: 21,840 Trainable params: 21,840 Non-trainable params: 0 Total mult-adds (M): 7.69 ========================================================================================== Input size (MB): 0.05 Forward/backward pass size (MB): 0.91 Params size (MB): 0.09 Estimated Total Size (MB): 1.05 ========================================================================================== 参考： https://zhuanlan.zhihu.com/p/135861716\nhttps://zhuanlan.zhihu.com/p/49842046\nhttps://zhuanlan.zhihu.com/p/31575074\n更新记录 增加网络模型统计工具，自动进行网络参数和计算量统计。 —— 2022.07.19\n","date":"2021-04-25T21:41:56Z","image":"http://localhost:1313/posts/%E6%8B%86%E8%A7%A3%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%AE%97%E5%AD%90%E5%8F%82%E6%95%B0%E9%87%8F%E4%B8%8E%E8%AE%A1%E7%AE%97%E9%87%8F%E7%9A%84%E7%A7%98%E5%AF%86/operator_parameters_and_calculation_hu_d49272982d09bdbd.jpg","permalink":"http://localhost:1313/posts/%E6%8B%86%E8%A7%A3%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%AE%97%E5%AD%90%E5%8F%82%E6%95%B0%E9%87%8F%E4%B8%8E%E8%AE%A1%E7%AE%97%E9%87%8F%E7%9A%84%E7%A7%98%E5%AF%86/","title":"拆解神经网络算子：参数量与计算量的秘密"},{"content":"Module nn.BNReLU2d 源码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 class BNReLU2d(nnq.BatchNorm2d): r\u0026#34;\u0026#34;\u0026#34; A BNReLU2d module is a fused module of BatchNorm2d and ReLU We adopt the same interface as :class:`torch.nn.quantized.BatchNorm2d`. Attributes: Same as torch.nn.quantized.BatchNorm2d \u0026#34;\u0026#34;\u0026#34; _FLOAT_MODULE = torch.nn.intrinsic.BNReLU2d def __init__(self, num_features, eps=1e-5, momentum=0.1): super(BNReLU2d, self).__init__(num_features, eps=eps, momentum=momentum) def forward(self, input): # Temporarily using len(shape) instead of ndim due to JIT issue # https://github.com/pytorch/pytorch/issues/23890 if len(input.shape) != 4: raise ValueError(\u0026#34;Input shape must be `(N, C, H, W)`!\u0026#34;) return torch.ops.quantized.batch_norm2d_relu( input, self.weight, self.bias, self.running_mean, self.running_var, self.eps, self.scale, self.zero_point) def _get_name(self): return \u0026#39;QuantizedBNReLU2d\u0026#39; @classmethod def from_float(cls, mod): # TODO: Add qat support for BNReLU2d return super(BNReLU2d, cls).from_float(mod)) nn.BatchNorm2d 1 2 3 4 5 class BatchNorm2d(_BatchNorm): def _check_input_dim(self, input): if input.dim() != 4: raise ValueError(\u0026#39;expected 4D input (got {}D input)\u0026#39; .format(input.dim())) torch.nn.BatchNorm2类如上面源码所示，该类具体实现部分基本上都来自继承_BatchNorm这个内部类，而后者类里面具体实现不是用python实现的，而是用c++、cuda实现的，这里我就不具体分析底层源码了。\n下面分析这个类功能：\n这篇论文中Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift提出了BN层。首先该类的输入为小批量带通道的二维输入，也就是输入的大小为(N,C,H,W)。对输入的数据做如下公式的变换： $$ y = \\frac{x - \\mathrm{E}[x]}{ \\sqrt{\\mathrm{Var}[x] + \\epsilon}} * \\gamma + \\beta $$ 平均值和标准差是按小批量的每个维度计算，$\\gamma$和$\\beta$为通道维度上的可学习的参数向量，默认情况下，$\\gamma$为1，$\\beta$为0。\n","date":"2021-03-14T15:53:39Z","permalink":"http://localhost:1313/posts/pytorch%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB-%E4%B8%89/","title":"Pytorch源码阅读(三)：BatchNorm Module"},{"content":" 注：笔者阅读的pytorch版本为1.7.0，torchvision版本为0.6\n前言 在这篇博客文章中，我主要来写关于pytorch中transforms模块，该模块提供了对图像各种预处理方法，位于torchvision/transforms/transforms.py，这些方法会应用在模型训练推理前，对图像进行预处理，再将处理后的图像送进深度网络中训练与推理。我想写这篇文章对这些预处理方法，进行学习理解，尽可能从源码角度，形象直观地展示这些图像预处理是如何对图像进行转换的。\ntransforms ： 读[trænsˈfɔːm]，变换、转换、移动。 eg. Fourier transform 傅里叶变换； It was an event that would transform my life. 那是能够彻底改变我一生的一件事。\ntransforms 模块相关源码分析 transforms.Compose类 先来看下transforms.Compose在实际代码中是如何运用的，下面代码是使用pytorch中的Dataset方式定义ImageNet数据集，也就说ImageNet继承自data.Dataset。\n1 2 3 4 5 6 7 train_dataset = torchvision.datasets.ImageNet(train_path, transform=transforms.Compose([ transforms.Resize((32, 32)), # 将图片缩放到指定大小（h,w）或者保持长宽比并缩放最短的边到int大小 transforms.CenterCrop(32), transforms.ToTensor()]) ) 从上面代码可以看出来transforms模块定义的对象，作为参数传入给ImageNet，在《pytorch源码(一)》中，了解到，通过for循环可以遍历Dataset对象获取图像数据，这篇文章介绍的transforms模块定义的类，一般在遍历Dataset获取图像前对图像进行预处理，那么通过for循环得到的图像就是进行处理后的图像。\n下面来分析transforms.Compose源码。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 class Compose(object): \u0026#34;\u0026#34;\u0026#34;Composes several transforms together. Args: transforms (list of ``Transform`` objects): list of transforms to compose. Example: \u0026gt;\u0026gt;\u0026gt; transforms.Compose([ \u0026gt;\u0026gt;\u0026gt; transforms.CenterCrop(10), \u0026gt;\u0026gt;\u0026gt; transforms.ToTensor(), \u0026gt;\u0026gt;\u0026gt; ]) \u0026#34;\u0026#34;\u0026#34; def __init__(self, transforms): self.transforms = transforms def __call__(self, img): for t in self.transforms: img = t(img) return img def __repr__(self): format_string = self.__class__.__name__ + \u0026#39;(\u0026#39; for t in self.transforms: format_string += \u0026#39;\\n\u0026#39; format_string += \u0026#39; {0}\u0026#39;.format(t) format_string += \u0026#39;\\n)\u0026#39; return format_string Compose是一个容器，它是对多个transforms模块定义转换对象transform组合，本质上是对列表的包装（装饰模式？）。\n这里我将这些转换对象类定义为transform，包括transforms.CenterCrop、transforms.ToTensor等等。\n该类的构造器(constructor)函数入参为列表类型，列表里是多个transform转换对象；在__call__中，通过for循环遍历transforms列表，对图像依次进行调用t(img)，可以看到每个transform都是一个可调用对象，通过依次调用这些transform，对图像进行预处理，这些处理是按照列表顺序处理。注：list是一种有序的集合。\ntransforms.Resize类 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 class Resize(object): \u0026#34;\u0026#34;\u0026#34;Resize the input PIL Image to the given size. Args: size (sequence or int): Desired output size. If size is a sequence like (h, w), output size will be matched to this. If size is an int, smaller edge of the image will be matched to this number. i.e, if height \u0026gt; width, then image will be rescaled to (size * height / width, size) interpolation (int, optional): Desired interpolation. Default is ``PIL.Image.BILINEAR`` \u0026#34;\u0026#34;\u0026#34; def __init__(self, size, interpolation=Image.BILINEAR): assert isinstance(size, int) or (isinstance(size, Iterable) and len(size) == 2) self.size = size self.interpolation = interpolation def __call__(self, img): \u0026#34;\u0026#34;\u0026#34; Args: img (PIL Image): Image to be scaled. Returns: PIL Image: Rescaled image. \u0026#34;\u0026#34;\u0026#34; return F.resize(img, self.size, self.interpolation) def __repr__(self): interpolate_str = _pil_interpolation_to_str[self.interpolation] return self.__class__.__name__ + \u0026#39;(size={0}, interpolation={1})\u0026#39;.format(self.size, interpolate_str) 先分析Resize的构造器方法，参数size，为转换后的图像像素大小，如果size参数是这样的序列（h，w），输出大小将与此匹配。如果size是int，图像的较小边等于此数字。如果height \u0026gt; width，则图像将被重新缩放到$\\left(\\text{size} \\times \\frac{\\text{height}}{\\text{width}}, \\text{size}\\right)$。另一个参数为interpolation，翻译为插值，默认值为双线性插值，这里我猜测下，当需要将图像分辨率变大，比如300*400提高至600*500分辨率，因为分辨率乘积代表像素点的个数，分辨率增大，那么原有的图像像素点不够，需要通过插值的方式新生成一部分像素点，这个参数就是控制如何产生这部分的像素点，在后面分析源码我会详细地说明插值方法。\n分析__call__方法，它的内部的实现直接调用了torchvision/transforms/functional.py模块中的方法，functional.py模块包含了很多对图像转换的具体方法实现，比如resize(img, size, interpolation=Image.BILINEAR)方法的具体实现等等。\n下面我使用Resize通过代码将475 * 300大小图片转换为237 * 150大小的图片。\n1 2 3 4 5 6 7 8 from torchvision.transforms import transforms from PIL import Image im = Image.open(\u0026#34;resources/dog-4671215_1280.jpg\u0026#34;) resize = transforms.Resize((150, 237)) im = resize(im) im.show() im.save(\u0026#39;resources/dog-150_237.jpg\u0026#39;) 缩小为 下面我来具体分析functional.py模块中的resize方法，源码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 def resize(img, size, interpolation=Image.BILINEAR): r\u0026#34;\u0026#34;\u0026#34;Resize the input PIL Image to the given size. Args: img (PIL Image): Image to be resized. size (sequence or int): Desired output size. If size is a sequence like (h, w), the output size will be matched to this. If size is an int, the smaller edge of the image will be matched to this number maintaing the aspect ratio. i.e, if height \u0026gt; width, then image will be rescaled to :math:`\\left(\\text{size} \\times \\frac{\\text{height}}{\\text{width}}, \\text{size}\\right)` interpolation (int, optional): Desired interpolation. Default is ``PIL.Image.BILINEAR`` Returns: PIL Image: Resized image. \u0026#34;\u0026#34;\u0026#34; if not _is_pil_image(img): raise TypeError(\u0026#39;img should be PIL Image. Got {}\u0026#39;.format(type(img))) if not (isinstance(size, int) or (isinstance(size, Iterable) and len(size) == 2)): raise TypeError(\u0026#39;Got inappropriate size arg: {}\u0026#39;.format(size)) if isinstance(size, int): w, h = img.size if (w \u0026lt;= h and w == size) or (h \u0026lt;= w and h == size): return img if w \u0026lt; h: ow = size oh = int(size * h / w) return img.resize((ow, oh), interpolation) else: oh = size ow = int(size * w / h) return img.resize((ow, oh), interpolation) else: return img.resize(size[::-1], interpolation) resize函数是定义在functional.py模块中的一个函数，前两个if语句，用来做参数类型校验，主要用到python中内置的isinstance(x, A_tuple)函数，返回对象是类的实例还是子类的实例，值得注意的是，第二个参数，既可以是一个类对象，也可以是一个包含多个类对象的元组。关于Iterable的理解可以查看这篇博客理解Python的Iterable和Iterator。\n其他部分的代码也很容易理解，isinstance(size, int)为True时，size为图像较小的边的输出大小,输出图像另一边的大小根据原图的比例计算得出。\n最后的else分支也很容易理解，在这里可以学习到的一点是，如何取得一个列表倒序的结果？这里用了切片的方式size[::-1]，来将入参是传入的(h, w)逆序变成(w, h)，再传入PIL.Image对象的resize()方法，也就是说pytorch本身没有自己实现对图像的resize方法，而是在底层调用的PIL图像库的方法。\n下面先插入一些对python中切片的学习，不知道为什么我每次遇到切片表达方式都要重新查一遍各种切片具体是代表的什么含义（😖）\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 Last login: Wed Mar 10 14:19:12 on ttys001 \u0026gt;\u0026gt;\u0026gt; L = list(range(10)) \u0026gt;\u0026gt;\u0026gt; L [0, 1, 2, 3, 4, 5, 6, 7, 8, 9] \u0026gt;\u0026gt;\u0026gt; L[::-1] # 倒序排列并且每1个取一个 [9, 8, 7, 6, 5, 4, 3, 2, 1, 0] \u0026gt;\u0026gt;\u0026gt; L[::-2] # 倒序排列并且每2个取一个 [9, 7, 5, 3, 1] \u0026gt;\u0026gt;\u0026gt; L[::2] # 正序排列并且每2个取一个 [0, 2, 4, 6, 8] \u0026gt;\u0026gt;\u0026gt; L[:] # 原样复制 [0, 1, 2, 3, 4, 5, 6, 7, 8, 9] \u0026gt;\u0026gt;\u0026gt; L[1:5] # 取第一个到第五个 [1, 2, 3, 4] 参考：python切片\n至于PIL.Image对象的resize()方法具体分析，内部实现是比较复杂的，先暂时省略，后面再补(🤦)‍️。\ntransforms.CenterCrop类 CenterCrop类的功能是依据给定的size从中心裁剪，在pytorch中的实现非常简单，这里就不贴出来源码了，简单看下它的构造器方法，参数size为(h, w)，代表裁剪后的图像分辨率大小，而如果size为int型，那么裁剪为(size, size)大小的正方形中心图像。例如，下面在475 * 300大小图像的中心部分裁剪出120 * 120大小的图像： 裁剪出 transforms.ToTensor 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 class ToTensor(object): \u0026#34;\u0026#34;\u0026#34;Convert a ``PIL Image`` or ``numpy.ndarray`` to tensor. Converts a PIL Image or numpy.ndarray (H x W x C) in the range [0, 255] to a torch.FloatTensor of shape (C x H x W) in the range [0.0, 1.0] if the PIL Image belongs to one of the modes (L, LA, P, I, F, RGB, YCbCr, RGBA, CMYK, 1) or if the numpy.ndarray has dtype = np.uint8 In the other cases, tensors are returned without scaling. \u0026#34;\u0026#34;\u0026#34; def __call__(self, pic): \u0026#34;\u0026#34;\u0026#34; Args: pic (PIL Image or numpy.ndarray): Image to be converted to tensor. Returns: Tensor: Converted image. \u0026#34;\u0026#34;\u0026#34; return F.to_tensor(pic) def __repr__(self): return self.__class__.__name__ + \u0026#39;()\u0026#39; ToTensor从类名字就可以看出来这个类主要将PIL.Image对象和numpy.ndarray对象转换为torch.FloatTensor对象，值得注意的是，最终的转换得到的Tensor对象的size是(C x H x W)，通道数在前面，也就是说pytorch在处理图像时，一般情况下，将三维的图像排列是(通道数，高度，宽度)。另外，该类还会将原本的0~255的RGB三原色强度值进行归一化处理，统一除以255，使得值在0.0~1.0之间。\n","date":"2021-03-11T14:15:04Z","permalink":"http://localhost:1313/posts/pytorch%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB-%E4%BA%8C/","title":"Pytorch源码阅读(二)：transforms模块"},{"content":" vue学习记录。\n注：\n学习目录在Workplace/vueLearning。 学完要综合学过前端和后端知识，开发一个完整的应用，综合应用知识。 使用的开发IDE为WebStorm。 学习地址：Vue学习 一、邂逅Vuejs 认识Vuejs Vue在国内相比于React使用更加广泛、更火。\n三大框架：VueJs、AngularJs、React。 Vue：读音/vju:/，类似于view。 Vue是一个渐进式框架：\nVue可以作为你应用的一部分嵌入其中。（一点一点渐进式引入Vue） 也可以直接使用Vue核心库及其生态系统。（Vue全家桶） Vue的特点和高级功能：（目前不太了解，慢慢学习，慢慢体会）\n解耦视图和数据 可复用的组件 前端路由技术 状态管理 虚拟DOM 学习Vue前提：\n可以从零学习，不需要其他框架的知识为前提。 需要具备一定的HTML、CSS、JavaScript基础。 (JS※ 、ES6※。以后都会用ES6） 另： xcode 读音：叉code。 Vue不要读成v、u、e。 Vuejs安装方式 方式一：直接CDN引入 方式二：下载和引入 另： - 直接下载，拷贝到项目里面就可以使用，只有一个vue.js文件，hin方便。\n方式三：NPM安装 后续通过webpack和CLI的使用，然后再使用这种方式。 Vuejs初体验 script引入vue并使用： 修改数据：1. 界面不用改，声明式开发。 2. 响应式：当数据发生改变，界面自动改变。 创建Vue对象时候，传入参数含义：\n{}中包含了el属性：该属性决定了这个vue对象挂载到哪一个元素。 {}中包含了data属性:该属性中通常会存储一些数据。 数据可以是我们自己定义的。 也可以是来自网络，从服务器加载到的。 列表展示：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;UTF-8\u0026#34;\u0026gt; \u0026lt;title\u0026gt;Title\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;div id=\u0026#34;app\u0026#34;\u0026gt; \u0026lt;!--{{movies}} --\u0026gt; \u0026lt;!-- 这种会展示成json格式数据--\u0026gt; \u0026lt;ul\u0026gt; \u0026lt;li v-for=\u0026#34;item in movies\u0026#34;\u0026gt;{{item}}\u0026lt;/li\u0026gt; \u0026lt;/ul\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;script src=\u0026#34;../js/vue.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script\u0026gt; const app = new Vue({ el: \u0026#39;#app\u0026#39;, data: { message: \u0026#39;你好呀\u0026#39;, movies: [\u0026#39;星际穿越\u0026#39;, \u0026#39;大话西游\u0026#39;, \u0026#39;盗墓空间\u0026#39;, \u0026#39;切尔诺贝利\u0026#39;] } }) \u0026lt;/script\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; Vue计数器案例 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 \u0026lt;div id=\u0026#34;app\u0026#34;\u0026gt; \u0026lt;h2\u0026gt;当前计数：{{counter}}\u0026lt;/h2\u0026gt; \u0026lt;button v-on:click=\u0026#34;add\u0026#34;\u0026gt;+\u0026lt;/button\u0026gt; \u0026lt;button v-on:click=\u0026#34;sub\u0026#34;\u0026gt;-\u0026lt;/button\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;script src=\u0026#34;../js/vue.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script\u0026gt; const app = new Vue({ el: \u0026#34;#app\u0026#34;, data: { counter: 0 }, methods: { add: function () { console.log(\u0026#39;add被执行\u0026#39;); this.counter++ }, sub: function () { console.log(\u0026#39;sub被执行\u0026#39;); this.counter-- } } }) \u0026lt;/script\u0026gt; 另： ES6不再使用var定义变量，而是使用let，let定义变量，const定义常量。 可以在游览器console中修改数据，会自动响应式展示。 @click是 v-on:click的语法糖。 Vuejs的MVVM 什么是MVVM：维基百科MVVM。 （需要再详细阅读） Vue的MVVM：图不清楚，需要重新找。 创建Vue实例传入的options el: string | HTML Element data: Object | Function (组件中data必须是一个函数) methods: { [key: string]: Function } （后面换成ES6的语法来写） 另： 开发中什么叫方法，什么称之为函数？ 答：都是通过function定义，类里面叫方法，定义在外面叫函数。 方法：method 函数：function Vue的生命周期（简单理解下） 另： 常用的生命周期函数：created、mounted。 二、Vue基础语法 代码规范 前端开发，缩进两个空格更加合适。 重复代码建立模板 将重复输入的内容设置到模板当中，在HTML（需要设置）中直接输入vue，点击回车，就可以自动填充模板中的内容。\n插值语法 Mustache语法 （也就是双大括号，用的最多）※ 1 2 3 4 5 6 7 \u0026lt;div id=\u0026#34;app\u0026#34;\u0026gt; \u0026lt;h2\u0026gt;{{message}}\u0026lt;/h2\u0026gt; \u0026lt;!-- mustache语法中，不仅仅可以直接写变量，也可以写一些简单的表达式--\u0026gt; \u0026lt;h2\u0026gt;{{firstName + \u0026#39; \u0026#39; + lastName}}\u0026lt;/h2\u0026gt; \u0026lt;h2\u0026gt;{{firstName}} {{lastName}}\u0026lt;/h2\u0026gt; \u0026lt;h2\u0026gt;{{counter * 2}}\u0026lt;/h2\u0026gt; \u0026lt;/div\u0026gt; v-once指令的使用 只展示一次，后面网页界面内容不会随着message值的改变而改变。也就是第二个h2标签显示的内容不会随着vue的app里面数据改变。\n一般情况下不用，特殊情况下需要使用。\n1 2 3 4 \u0026lt;div id=\u0026#34;app\u0026#34;\u0026gt; \u0026lt;h2\u0026gt;{{message}}\u0026lt;/h2\u0026gt; \u0026lt;h2 v-once\u0026gt;{{message}}\u0026lt;/h2\u0026gt; \u0026lt;/div\u0026gt; v-html指令的使用 数据以HTML形式展示。 v-text指令的使用 （一般不用，没有双括号灵活） v-pre指令的使用 （很少使用） 将v-pre设置的标签内容原封不动展示，不进行解析。\n1 2 3 4 \u0026lt;div id=\u0026#34;app\u0026#34;\u0026gt; \u0026lt;h2\u0026gt;{{message}}\u0026lt;/h2\u0026gt; \u0026lt;h2 v-pre\u0026gt;{{message}}\u0026lt;/h2\u0026gt; \u0026lt;/div\u0026gt; v-cloak指令的使用 （基本不用） cloak: 斗篷。 clock: 时钟。\n和css样式结合使用，可以实现当JS脚本未执行完，不显示内容，而不是显示一些未渲染的“乱码”，对用户友好。\nv-bind v-bind之前都是将数据插到内容中，而这个是将值插到标签的属性中，比如img标签的src属性，改变这个属性值。又比如a标签的href属性。不能用双括号语法操作，双括号是在标签内容中使用的。\n作用：动态绑定标签属性。\nv-bind基本使用 v-bind语法糖 （经常用）※ 将v-bind:简写成:。\nv-bind动态绑定class属性 对象语法：class = \u0026quot;\u0026quot; 双引号里面是个对象。 （经常用）※ 数组语法 （很少用） 1 2 3 \u0026lt;h2 class=\u0026#34;title\u0026#34; :class=\u0026#34;[active, \u0026#39;line\u0026#39;]\u0026gt;{{message}}\u0026lt;/h2\u0026gt; \u0026lt;!-- active是个变量，定义在data中--\u0026gt; v-bind动态绑定style 对象语法：:style=\u0026quot;{key(属性名): value(属性值)}\u0026quot; 双引号里面是个对象。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 \u0026lt;div id=\u0026#34;app\u0026#34;\u0026gt; \u0026lt;!-- \u0026lt;h2 :style=\u0026#34;{key(属性名): value(属性值)}\u0026#34;\u0026gt;{{message}}\u0026lt;/h2\u0026gt;--\u0026gt; \u0026lt;h2 :style=\u0026#34;{fontSize: finalSize, color: finalColor}\u0026#34;\u0026gt;{{message}}\u0026lt;/h2\u0026gt; \u0026lt;!-- key不需要加单引号，但是value要加，否则20px当作成变量了 --\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;script src=\u0026#34;../js/vue.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script\u0026gt; const app = new Vue({ el: \u0026#34;#app\u0026#34;, data: { message: \u0026#39;你好呀\u0026#39;, finalSize: \u0026#39;100px\u0026#39;, finalColor: \u0026#39;red\u0026#39; } }) \u0026lt;/script\u0026gt; 数组语法：\u0026lt;div v-bind: style=\u0026quot;[basestyles, overridingstyles]\u0026quot;\u0026gt;/div\u0026gt; ，basestyles和overridingstyles为对象 （很少用） 计算属性 computed（很重要）※ 计算属性的使用 数据展示之前需要经过一定的处理，computed里面也是定义的函数，但是不要命名为动词，一般命名为名词。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 \u0026lt;div id=\u0026#34;app\u0026#34;\u0026gt; \u0026lt;!-- \u0026lt;h2\u0026gt;{{firstName + \u0026#39; \u0026#39; + lastName}}\u0026lt;/h2\u0026gt;--\u0026gt; \u0026lt;!-- \u0026lt;h2\u0026gt;{{fullName()}}\u0026lt;/h2\u0026gt;--\u0026gt; \u0026lt;h2\u0026gt;{{fullName}}\u0026lt;/h2\u0026gt; \u0026lt;!-- 不需要加函数的括号 --\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;script src=\u0026#34;../js/vue.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script\u0026gt; const app = new Vue({ el: \u0026#34;#app\u0026#34;, data: { message: \u0026#39;你好呀\u0026#39;, firstName: \u0026#39;lebron\u0026#39;, lastName: \u0026#39;James\u0026#39; }, computed: { fullName: function () { return this.firstName + \u0026#39; \u0026#39; + this.lastName + \u0026#39; 根据computed得到的\u0026#39;; } }, methods: { // fullName: function () { // return this.firstName + \u0026#39; \u0026#39; + this.lastName; // } } }) \u0026lt;/script\u0026gt; 应用场景: 购物车选中多个商品，计算总价格。\n另：计算属性只计算一次，有缓存，相比method计算速度更快。\n计算属性setter和getter 计算属性和methods的对比 ※ 计算属性内部实现缓存，如果值不改变，直接调用缓存中的内容，而methods每次都会调用，效率比计算属性差\n补充：ES6语法 let/var let有if和for块级作用域，而var没有if和for块级作用域。\nconst 标识符修饰为常量。定义时就需要赋值。对象不能修改，但是可以改变对象里面的属性。\n对象的字面量增强写法 属性的增强写法 函数的增强写法 事件监听 v-on的基本使用 v-on语法糖：@\nv-on的参数 事件监听的时候，若不需要传参数，则可以不写调用的小括号。（省略）\n如何给事件监听函数传入，游览器生成的event对象？\n传入的参数为$event就可以了。方法形参为event。\nv-on的修饰符 @click.stop防止事件冒泡。 @click.prevent阻止默认行为的执行。 @keyUp.enter监听enter键的释放。 @click.once只监听一次点击事件。 关于事件监听参考 Vue事件监听\n条件判断 v-if的使用 另：一般情况下，v-else-if、v-else不在HTML模板中使用，逻辑不放在界面代码处。\nv-show的使用 决定标签是否在界面显示：\u0026lt;h2 v-show=\u0026quot;isShow\u0026quot;\u0026gt; \u0026lt;/h2\u0026gt;\nv-if 和 v-show的区别。 （v-if经常使用）\nv-if：当条件为false时，包含v-if指令的元素，根本不会存在dom中。而v-show：当条件为false时，只是给元素添加了一个行内样式：display：none。前者dom中取掉，后者改样式。当展示切换频率很高，用v-show。\n循环遍历v-for的使用 遍历数组 ※ 1 \u0026lt;li v-for=\u0026#34;(item, index) in movies\u0026#34;\u0026gt;{{item}}\u0026lt;/li\u0026gt; 遍历对象 1 2 3 4 5 \u0026lt;!-- 获取到的是value --\u0026gt; \u0026lt;li v-for=\u0026#34;item in info\u0026#34;\u0026gt;{{item}}\u0026lt;/li\u0026gt; \u0026lt;!-- 获取到value和key --\u0026gt; \u0026lt;li v-for=\u0026#34;(value, key) in info\u0026#34;\u0026gt;{{value}} {{key}}\u0026lt;/li\u0026gt; v-for绑定key 省略。\n数组中响应式方法：数组内容改变，展示内容跟着改变。 push()、pop()、shift()、unshift()、splice()、sort()、reverse()\n另:\nsplice() ※ letters[index] = \u0026lsquo;change\u0026rsquo; 索引方式改变数组是非响应式的。 上面的方式可以改用为vue内部实现的函数vue.set()，更推荐splice()方式。 补充：三个高阶函数 ※ filter、reduce、map函数\nlet total = nums.filter(n =\u0026gt; n\u0026lt;100).map(n =\u0026gt; n * 2).reduce((pre, n) =\u0026gt; pre + n);\nv-model双向绑定 （暂时跳过） 三、组件化开发 ※ 什么是组件化？ 将复杂问题，拆分成很多个小问题。将一个页面拆分成一个个小的功能块，每个功能块完成属于自己这一部分独立的功能，那么整个页面的管理和维护就变得非常容易了。应用最后抽象为一个组件树。\n组件化思想 任何的应用都会被抽象成一颗组件树。 有了组件化的思想，我们在之后的开发中就要充分的利用它。 尽可能的将页面拆分成一个个小的、可复用的组件。 这样让我们的代码更加方便组织和管理，并且扩展性也更强。 组件使用步骤 创建组件构造器。 注册组件。 使用组件。 另：\n开发中用的最多的是局部组件。 一般只创建一个Vue实例。 全局组件和局部组件 在Vue实例创建之外，注册的组件为全局组件。\n1 2 // 注册全局组件(全局组件, 意味着可以在多个Vue的实例下面使用，app，app2) Vue.component(\u0026#39;cpn\u0026#39;, cpnC) 在Vue实例创建时，注册的组件为局部组件。 用的最多的还是局部组件。 ※ ※\n1 2 3 4 5 6 7 8 9 10 11 const app = new Vue({ el: \u0026#39;#app\u0026#39;, data: { message: \u0026#39;你好啊\u0026#39; }, // 局部组件 components: { // cpn为使用组件时的标签名，cpnC为组件实例 cpn: cpnC } }) 父组件和子组件的区别 ※ ※ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 // 1.创建第一个组件构造器(子组件)，Vue.extend()语法很少见了 const cpnC1 = Vue.extend({ template: ` \u0026lt;div\u0026gt; \u0026lt;h2\u0026gt;我是标题1\u0026lt;/h2\u0026gt; \u0026lt;p\u0026gt;我是内容, 哈哈哈哈\u0026lt;/p\u0026gt; \u0026lt;/div\u0026gt; ` }) // 2.创建第二个组件构造器(父组件) const cpnC2 = Vue.extend({ template: ` \u0026lt;div\u0026gt; \u0026lt;h2\u0026gt;我是标题2\u0026lt;/h2\u0026gt; \u0026lt;p\u0026gt;我是内容, 呵呵呵呵\u0026lt;/p\u0026gt; \u0026lt;cpn1\u0026gt;\u0026lt;/cpn1\u0026gt; \u0026lt;/div\u0026gt; `, components: { cpn1: cpnC1 } }) 注册组件的语法糖写法（推荐写法）※ ※ 省略 Vue.extend()，使用语法糖写法。 后面内容讲解，将tepmlate抽离出去，代码会更加清晰。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 Vue.component(\u0026#39;cpn1\u0026#39;, { template: ` \u0026lt;div\u0026gt; \u0026lt;h2\u0026gt;我是标题1\u0026lt;/h2\u0026gt; \u0026lt;p\u0026gt;我是内容, 哈哈哈哈\u0026lt;/p\u0026gt; \u0026lt;/div\u0026gt; ` }) // 2.注册局部组件的语法糖 const app = new Vue({ el: \u0026#39;#app\u0026#39;, data: { message: \u0026#39;你好啊\u0026#39; }, components: { \u0026#39;cpn2\u0026#39;: { template: ` \u0026lt;div\u0026gt; \u0026lt;h2\u0026gt;我是标题2\u0026lt;/h2\u0026gt; \u0026lt;p\u0026gt;我是内容, 呵呵呵\u0026lt;/p\u0026gt; \u0026lt;/div\u0026gt; ` } } }) 模板的分离写法 为什么组件data必须是函数？ ※ 1 2 3 4 5 6 7 8 9 10 // 1.注册一个全局组件 Vue.component(\u0026#39;cpn\u0026#39;, { template: \u0026#39;#cpn\u0026#39;, // 组件数据 data() { return { title: \u0026#39;abc\u0026#39; } } }) Vue组件应该有自己保存数据的地方，不能访问Vue实例中的数据。 组件对象也有一个data属性(函数)，也可以有methods等属性。 这个data属性必须是一个函数。 这个函数返回一个对象，对象内部保存着数据，多个相同组件各自使用各自的数据。 \u0026lt;script\u0026gt;标签 \u0026lt;template\u0026gt;标签 父子组件的通信 ※ ※ ※ 父组件向子组件 props (常用) ※ props : properties 属性\n通过props向子组件传递数据。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;UTF-8\u0026#34;\u0026gt; \u0026lt;title\u0026gt;Title\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;div id=\u0026#34;app\u0026#34;\u0026gt; \u0026lt;!--\u0026lt;cpn v-bind:cmovies=\u0026#34;movies\u0026#34;\u0026gt;\u0026lt;/cpn\u0026gt;--\u0026gt; \u0026lt;!--\u0026lt;cpn cmovies=\u0026#34;movies\u0026#34; cmessage=\u0026#34;message\u0026#34;\u0026gt;\u0026lt;/cpn\u0026gt;--\u0026gt; \u0026lt;!-- v-bind --\u0026gt; \u0026lt;cpn :cmessage=\u0026#34;message\u0026#34; :cmovies=\u0026#34;movies\u0026#34;\u0026gt;\u0026lt;/cpn\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;template id=\u0026#34;cpn\u0026#34;\u0026gt; \u0026lt;div\u0026gt; \u0026lt;ul\u0026gt; \u0026lt;li v-for=\u0026#34;item in cmovies\u0026#34;\u0026gt;{{item}}\u0026lt;/li\u0026gt; \u0026lt;/ul\u0026gt; \u0026lt;h2\u0026gt;{{cmessage}}\u0026lt;/h2\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/template\u0026gt; \u0026lt;script src=\u0026#34;../js/vue.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script\u0026gt; // 父传子: props const cpn = { template: \u0026#39;#cpn\u0026#39;, // props: [\u0026#39;cmovies\u0026#39;, \u0026#39;cmessage\u0026#39;], 这种有些怪，字符串居然是变量！ props: { // 1.类型限制 // cmovies: Array, // cmessage: String, // 2.提供一些默认值, 以及必传值 cmessage: { type: String, default: \u0026#39;aaaaaaaa\u0026#39;, required: true }, // 类型是对象或者数组时, 默认值必须是一个函数 js 中属性和函数的区别？？？ cmovies: { type: Array, default() { return [] } } }, data() { return {} }, methods: { } } const app = new Vue({ el: \u0026#39;#app\u0026#39;, data: { message: \u0026#39;你好啊\u0026#39;, movies: [\u0026#39;海王\u0026#39;, \u0026#39;海贼王\u0026#39;, \u0026#39;海尔兄弟\u0026#39;] }, components: { cpn // 对象字面量增强 } }) \u0026lt;/script\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 问题：\nTODO\n1 \u0026lt;cpn :cmessage=\u0026#34;message\u0026#34; :cmovies=\u0026#34;movies\u0026#34;\u0026gt;\u0026lt;/cpn\u0026gt; 子组件向父组件 $emit events ※ 通过事件events向父组件发送消息。\n看到P61\nwebpack的介绍与安装 Node, Npm 和 webpack\n从本质上来讲，webpack是一个现代的JavRScript应用的静态模块打包工具。 webpack其中一个核心就是让我们可能进行模块化开发，并且会帮助我们处理模块间的依赖关系。 不仅仅是JavaScript文件，我们的CSS、图片、json文件等等在webpack中都可以被当做模块来使用（在后续我们会看到）。 认识webpack webpack的安装 webpack的起步 webpack的配置 loader的使用 Iwebpack中配置Vue plugin的使用 搭建本地服务器 四、Vue CLI详解 （脚手架）※ 五、vue-router 六、Vuex详解 （状态管理） 七、网络封装 八、项目实战 一步步学习，没什么耐心，那就项目驱动学习吧，开干。\n创建项目 Vue CLI教程Vue CLI 1 2 sudo cnpm install -g vue-cli # 安装 vue create supermall # 创新新的项目 目录结构划分 参考：https://blog.csdn.net/weixin_42290927/article/details/94432587\n九、项目部署 十、vuejs原理相关 ","date":"2021-01-06T22:02:52Z","image":"http://localhost:1313/posts/vue%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B0/vue_cover_hu_9dd8072f0be254e2.jpg","permalink":"http://localhost:1313/posts/vue%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B0/","title":"Vue入门笔记"},{"content":"阅读开源代码是提高写代码能力最好的方式之一，现在入坑机器学习领域，在众多框架中选择pytorch框架作为自己基本的深度学习框架，现在开始从最简单的pytorch代码部分阅读，学习下python技巧顺便深入学习下神经网络的代码实践。\n关于阅读源码，我一开始在项目中调用pytorch模块和类，通过pycharm追踪源码，在pycharm中可以直接查看依赖包torch中源码，但是这样也不方便阅读torch源码，一个原因是pycharm中查看依赖包的源码内容，查看源码文件的方式是只读模式，没法在里面注释一些自己理解的东西，另一个原因是通过单步调试阅读代码是最容易理解代码的方式，想了想pytorch源码里面应该有对源码的测试代码可以直接跑起来，然后一步步运行，这样看着更方便。\n从github上下载pytorch代码，通过CONTRIBUTING.md文件中指导编译源码，注意使用：python setup.py develop 以开发模式构建代码。这个过程在我的电脑上要跑将近两小时。。。忘了什么原因导致我跑了两次。。。四个小时没了(呜呜\u0026hellip;)\n先从加载和处理数据源码了解。\n注：笔者阅读的pytorch版本为1.7.0，torchvision版本为0.6\nDataset 相关源码 MNIST类 类继承图：\n先来看看最常用的mnist数据集的使用，下面两行使用torchvision中提供的MNIST数据集类定义了两个数据集类，分别为训练数据集和测试数据集，那么为什么需要定义两个同样的数据集呢？其中一个因为是训练和测试使用的数据集不一样；另一个原因是训练和测试时候对应的batch_size大小不一样。下面进一步分析datasets.MNIST代码。\n1 2 3 4 5 6 dataset1 = datasets.MNIST(\u0026#39;../data\u0026#39;, train=True, download=True, transform=transform) dataset2 = datasets.MNIST(\u0026#39;../data\u0026#39;, train=False, transform=transform) train_loader = torch.utils.data.DataLoader(dataset1,**train_kwargs) test_loader = torch.utils.data.DataLoader(dataset2, **test_kwargs) 下面的代码来自torchvision.datasets.mnist模块\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 from .vision import VisionDataset import warnings from PIL import Image import os import os.path import numpy as np import torch import codecs import string from .utils import download_url, download_and_extract_archive, extract_archive, \\ verify_str_arg class MNIST(VisionDataset): resources = [ (\u0026#34;http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\u0026#34;, \u0026#34;f68b3c2dcbeaaa9fbdd348bbdeb94873\u0026#34;), (\u0026#34;http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\u0026#34;, \u0026#34;d53e105ee54ea40749a09fcbcd1e9432\u0026#34;), (\u0026#34;http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\u0026#34;, \u0026#34;9fb629c4189551a2d022fa330f9573f3\u0026#34;), (\u0026#34;http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\u0026#34;, \u0026#34;ec29112dd5afa0611ce80d1b7f02629c\u0026#34;) ] training_file = \u0026#39;training.pt\u0026#39; test_file = \u0026#39;test.pt\u0026#39; classes = [\u0026#39;0 - zero\u0026#39;, \u0026#39;1 - one\u0026#39;, \u0026#39;2 - two\u0026#39;, \u0026#39;3 - three\u0026#39;, \u0026#39;4 - four\u0026#39;, \u0026#39;5 - five\u0026#39;, \u0026#39;6 - six\u0026#39;, \u0026#39;7 - seven\u0026#39;, \u0026#39;8 - eight\u0026#39;, \u0026#39;9 - nine\u0026#39;] @property def train_labels(self): warnings.warn(\u0026#34;train_labels has been renamed targets\u0026#34;) return self.targets @property def test_labels(self): warnings.warn(\u0026#34;test_labels has been renamed targets\u0026#34;) return self.targets @property def train_data(self): warnings.warn(\u0026#34;train_data has been renamed data\u0026#34;) return self.data @property def test_data(self): warnings.warn(\u0026#34;test_data has been renamed data\u0026#34;) return self.data 类MNIST继承自VisionDataset，从名称可以知道VisionDataset是对流行的视觉数据集的抽象类，我从子类开始分析，后面再阅读分析VisionDataset类。MNIST类前面定义了四个属性，其中training_file、test_file保存将原始Minst数据处理之后的tensor格式的训练和测试数据的文件名。另外有四个方法分别是train_labels、test_labels、train_data、test_data，它们都被@property注解所修饰，@property这种注解装饰器来创建只读属性，@property装饰器会将方法转换为相同名称的只读属性，可以与所定义的属性配合使用，这样可以防止属性被修改。那么我们就可以通过mnist.train_labels得到实例的私有属性，而实际上该过程调用的是train_labels()函数。上面部分除了@property其他的都很好理解了。下面来看这个类的其余部分：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 def __init__(self, root, train=True, transform=None, target_transform=None, download=False): super(MNIST, self).__init__(root, transform=transform, target_transform=target_transform) self.train = train # training set or test set if download: self.download() if not self._check_exists(): raise RuntimeError(\u0026#39;Dataset not found.\u0026#39; + \u0026#39; You can use download=True to download it\u0026#39;) if self.train: data_file = self.training_file else: data_file = self.test_file self.data, self.targets = torch.load(os.path.join(self.processed_folder, data_file)) def __getitem__(self, index): \u0026#34;\u0026#34;\u0026#34; Args: index (int): Index Returns: tuple: (image, target) where target is index of the target class. \u0026#34;\u0026#34;\u0026#34; img, target = self.data[index], int(self.targets[index]) # doing this so that it is consistent with all other datasets # to return a PIL Image img = Image.fromarray(img.numpy(), mode=\u0026#39;L\u0026#39;) # @3 if self.transform is not None: img = self.transform(img) # @1 if self.target_transform is not None: target = self.target_transform(target) # @2 return img, target def __len__(self): return len(self.data) __init__该类的构造器(constructor)函数入参transform和target_transform分别传入对数据图像和标签的预处理，在@1和@2处可以看到在每一张图像返回前分别对图像和标签进行用户自定义预处理。传入的train参数来决定该MNIST的dataset会返回训练集or测试集中的数据。\n__getitem__根据python3中定义，如果在类中定义了__getitem__()方法，那么它的实例对象（假设为P）就可以以P[key]形式取值，当实例对象做P[key]运算时，就会调用类中的__getitem__()方法，这是一个很有意思也很有用的特性。具体到这个类的key为训练样本的idex为int类型代表第几个数据样本。在**@3**处将图像转成PIL图像对象，该PIL对象最终会通过transform预处理为tonsor对象。类MNIST剩余部分最主要就是下载download函数，如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 @property def raw_folder(self): return os.path.join(self.root, self.__class__.__name__, \u0026#39;raw\u0026#39;) @property def processed_folder(self): return os.path.join(self.root, self.__class__.__name__, \u0026#39;processed\u0026#39;) @property def class_to_idx(self): return {_class: i for i, _class in enumerate(self.classes)} def _check_exists(self): return (os.path.exists(os.path.join(self.processed_folder, self.training_file)) and os.path.exists(os.path.join(self.processed_folder, self.test_file))) def download(self): \u0026#34;\u0026#34;\u0026#34;Download the MNIST data if it doesn\u0026#39;t exist in processed_folder already.\u0026#34;\u0026#34;\u0026#34; if self._check_exists(): # @4 return os.makedirs(self.raw_folder, exist_ok=True) os.makedirs(self.processed_folder, exist_ok=True) # download files for url, md5 in self.resources: filename = url.rpartition(\u0026#39;/\u0026#39;)[2] download_and_extract_archive(url, download_root=self.raw_folder, filename=filename, md5=md5) # process and save as torch files print(\u0026#39;Processing...\u0026#39;) training_set = ( read_image_file(os.path.join(self.raw_folder, \u0026#39;train-images-idx3-ubyte\u0026#39;)), read_label_file(os.path.join(self.raw_folder, \u0026#39;train-labels-idx1-ubyte\u0026#39;)) ) test_set = ( read_image_file(os.path.join(self.raw_folder, \u0026#39;t10k-images-idx3-ubyte\u0026#39;)), read_label_file(os.path.join(self.raw_folder, \u0026#39;t10k-labels-idx1-ubyte\u0026#39;)) ) with open(os.path.join(self.processed_folder, self.training_file), \u0026#39;wb\u0026#39;) as f: torch.save(training_set, f) with open(os.path.join(self.processed_folder, self.test_file), \u0026#39;wb\u0026#39;) as f: torch.save(test_set, f) print(\u0026#39;Done!\u0026#39;) def extra_repr(self): return \u0026#34;Split: {}\u0026#34;.format(\u0026#34;Train\u0026#34; if self.train is True else \u0026#34;Test\u0026#34;) download函数下载原始mnist数据并将训练图像数据、训练标签数据存储在一个training_file文件中，将测试图像数据、测试标签数据存在test_file文件中，@4处可以看到当processed_folder目录下存在这两个文件，那么就不会通过网络下载，直接读取本地训练测试数据文件。另外，像download_and_extract_archive函数的具体实现，并没有在上面给出，这个就是更加细节的代码实现，此次代码阅读会忽略很多具体细节实现，专注于大的框架实现。\nMNIST类继承自VisionDataset类，下面我们看看这个类中抽象出了哪些功能。\nVisionDataset类 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 class VisionDataset(data.Dataset): _repr_indent = 4 def __init__(self, root, transforms=None, transform=None, target_transform=None): if isinstance(root, torch._six.string_classes): root = os.path.expanduser(root) self.root = root has_transforms = transforms is not None has_separate_transform = transform is not None or target_transform is not None if has_transforms and has_separate_transform: raise ValueError(\u0026#34;Only transforms or transform/target_transform can \u0026#34; \u0026#34;be passed as argument\u0026#34;) # for backwards-compatibility @5 self.transform = transform self.target_transform = target_transform if has_separate_transform: transforms = StandardTransform(transform, target_transform) # @6 self.transforms = transforms def __getitem__(self, index): raise NotImplementedError def __len__(self): raise NotImplementedError def __repr__(self): head = \u0026#34;Dataset \u0026#34; + self.__class__.__name__ body = [\u0026#34;Number of datapoints: {}\u0026#34;.format(self.__len__())] if self.root is not None: body.append(\u0026#34;Root location: {}\u0026#34;.format(self.root)) body += self.extra_repr().splitlines() if hasattr(self, \u0026#34;transforms\u0026#34;) and self.transforms is not None: body += [repr(self.transforms)] lines = [head] + [\u0026#34; \u0026#34; * self._repr_indent + line for line in body] return \u0026#39;\\n\u0026#39;.join(lines) def _format_transform_repr(self, transform, head): lines = transform.__repr__().splitlines() return ([\u0026#34;{}{}\u0026#34;.format(head, lines[0])] + [\u0026#34;{}{}\u0026#34;.format(\u0026#34; \u0026#34; * len(head), line) for line in lines[1:]]) def extra_repr(self): return \u0026#34;\u0026#34; VisionDataset类中在**@5处注释向后兼容，可以看到在构造器（constructor）的入参有transforms、transform、target_transform三个预处理变量，那么哪一种是方式是重构后新引入的预处理方式呢？其实从@6**处就可以知道，为了兼容transform、target_transform传入方式，将它们两个构造为StandardTransform，也就是说重构后，希望用transforms(注意有个s)入参取代原有的方式。并且，机智的我（嘿嘿）通过查看该文件的修改历史，如下图，就可以看到源码作者的重构的意图。\n再来看看VisionDataset类中__repr__()的作用，简单理解就是，python中定义当输出print(instance)时，等同于执行print(instance.__repr__())，这样用户就可以通过实现自己的__repr__函数来控制我们想要的信息。默认情况下，__repr__() 会返回和调用者有关的 “类名+object at+内存地址”信息。另外，若调用repr(instance)也会执行__repr__()函数。\nVisionDataset类继承自data.Dataset类，下面我们看看这个类中有哪些属性和方法。\nDataset torch.utils.data.dataset模块中定义了几个数据类，是对pytorch搭建神经网络训练和测试所需要的数据集的封装和抽象。其中Dataset类是所有数据集类的父类，那么来看看这个类中定义了什么内容吧~\n下面代码是我从pytorch源代码中拷贝过来的，省略了一些模块和类的导入。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 T_co = TypeVar(\u0026#39;T_co\u0026#39;, covariant=True) T = TypeVar(\u0026#39;T\u0026#39;) class Dataset(Generic[T_co]): r\u0026#34;\u0026#34;\u0026#34;An abstract class representing a :class:`Dataset`. All datasets that represent a map from keys to data samples should subclass it. All subclasses should overwrite :meth:`__getitem__`, supporting fetching a data sample for a given key. Subclasses could also optionally overwrite :meth:`__len__`, which is expected to return the size of the dataset by many :class:`~torch.utils.data.Sampler` implementations and the default options of :class:`~torch.utils.data.DataLoader`. .. note:: :class:`~torch.utils.data.DataLoader` by default constructs a index sampler that yields integral indices. To make it work with a map-style dataset with non-integral indices/keys, a custom sampler must be provided. \u0026#34;\u0026#34;\u0026#34; def __getitem__(self, index) -\u0026gt; T_co: raise NotImplementedError def __add__(self, other: \u0026#39;Dataset[T_co]\u0026#39;) -\u0026gt; \u0026#39;ConcatDataset[T_co]\u0026#39;: return ConcatDataset([self, other]) 前两行定义两个用户自定义泛型，这种泛型编程自python3.5起开始引入到python中，有点类似于c++中泛型编程（不怎么用，忘得差不多了），c++中泛型会在编译器做类型检查和替换，属于强制类型检查，而在python中因为python类型都是弱类型，所以这种泛型编程更多的是给静态类型检测工具提供说明，帮助我们在代码编写阶段正确使用和传递python变量。目前，先忽略这些泛型类型。\n在Dataset类中定义了两个基本函数，__getitem__实现key-value结构，__add__定义两个数据集叠加的操作。\n下来我们来看看torchvision中其他的dataset。\n类继承图：\nImageFolder 下面源码摘抄自torchvision.datasets.folder模块。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 class ImageFolder(DatasetFolder): \u0026#34;\u0026#34;\u0026#34;A generic data loader where the images are arranged in this way: :: root/dog/xxx.png root/dog/xxy.png root/dog/xxz.png root/cat/123.png root/cat/nsdf3.png root/cat/asd932_.png Args: root (string): Root directory path. transform (callable, optional): A function/transform that takes in an PIL image and returns a transformed version. E.g, ``transforms.RandomCrop`` target_transform (callable, optional): A function/transform that takes in the target and transforms it. loader (callable, optional): A function to load an image given its path. is_valid_file (callable, optional): A function that takes path of an Image file and check if the file is a valid file (used to check of corrupt files) Attributes: classes (list): List of the class names. class_to_idx (dict): Dict with items (class_name, class_index). imgs (list): List of (image path, class_index) tuples \u0026#34;\u0026#34;\u0026#34; def __init__(self, root, transform=None, target_transform=None, loader=default_loader, is_valid_file=None): super(ImageFolder, self).__init__(root, loader, IMG_EXTENSIONS if is_valid_file is None else None, transform=transform, target_transform=target_transform, is_valid_file=is_valid_file) self.imgs = self.samples ImageFolder是一个通用的图像数据集类，它要求数据按照：\nroot/label01/xxx.png\nroot/label01/xxy.png\nroot/label01/xxz.png\nroot/label02/123.png\nroot/label02/nsdf3.png\nroot/label02/asd932_.png\n的格式存放。这是分类数据集的数据和标签表示的另一种方式，通过目录名当作标签来存放图像数据，对于制作自定义数据集还是挺方便的。\nImageFolder继承自DatasetFolder，从名称就可以知道ImageFolder是类DatasetFolder的具体化，它只用来处理图像数据集，一般处理IMG_EXTENSIONS = ('.jpg', '.jpeg', '.png', '.ppm', '.bmp', '.pgm', '.tif', '.tiff', '.webp') 中的图像格式。ImageFolder读取数据集后，得到三个属性：classes、class_to_idx、imgs。\nSampler 相关源码 源码位于 torch/utils/data/sampler.py，那么为什么要有Sampler相关类呢？我觉得可以这样理解：Dataset是为数据的总体，每次训练或者测试要从总体中随机或顺序抽取一个样本或者一批样本，那么不同的Sampler子类就表示从数据集中不同的抽取方式。\nSampler：所有Sampler的父类。 SequentialSampler：顺序依次获取下标。 RandomSampler：乱序获取下标。 SubsetRandomSampler：某个子集内乱序获取下标。 WeightedRandomSampler：为每个样本设置权重，权重大表示获取概率高。 BatchSampler：即将若干个样本形成一个batch。 Sampler 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 class Sampler(Generic[T_co]): r\u0026#34;\u0026#34;\u0026#34;Base class for all Samplers. Every Sampler subclass has to provide an :meth:`__iter__` method, providing a way to iterate over indices of dataset elements, and a :meth:`__len__` method that returns the length of the returned iterators. .. note:: The :meth:`__len__` method isn\u0026#39;t strictly required by :class:`~torch.utils.data.DataLoader`, but is expected in any calculation involving the length of a :class:`~torch.utils.data.DataLoader`. \u0026#34;\u0026#34;\u0026#34; def __init__(self, data_source: Optional[Sized]) -\u0026gt; None: pass def __iter__(self) -\u0026gt; Iterator[T_co]: raise NotImplementedError # NOTE [ Lack of Default `__len__` in Python Abstract Base Classes ] # # Many times we have an abstract class representing a collection/iterable of # data, e.g., `torch.utils.data.Sampler`, with its subclasses optionally # implementing a `__len__` method. In such cases, we must make sure to not # provide a default implementation, because both straightforward default # implementations have their issues: # # + `return NotImplemented`: # Calling `len(subclass_instance)` raises: # TypeError: \u0026#39;NotImplementedType\u0026#39; object cannot be interpreted as an integer # # + `raise NotImplementedError()`: # This prevents triggering some fallback behavior. E.g., the built-in # `list(X)` tries to call `len(X)` first, and executes a different code # path if the method is not found or `NotImplemented` is returned, while # raising an `NotImplementedError` will propagate and and make the call # fail where it could have use `__iter__` to complete the call. # # Thus, the only two sensible things to do are # # + **not** provide a default `__len__`. # # + raise a `TypeError` instead, which is what Python uses when users call # a method that is not defined on an object. # (@ssnl verifies that this works on at least Python 3.7.) Sampler类是所有Sampler的父类，类中__init__该类的构造器(constructor)函数，__iter__提供迭代数据集元素索引的方法。\nDataLoader相关源码 源码位于pytorch源码目录的torch/utils/data/dataloader.py，DataLoader类非常重要，它是我们作为深度学习模型训练与开发过程中直接用到的类，也就是说我们一般情况下，通过它来将我们的数据集数据加载到程序中，通常是用一个for循环遍历它，DataLoader类依赖Dataset类和Sampler类在内部为我们实现了很多数据集遍历的方式，方便于多种场景下使用。\n分析DataLoader类之前，我先在之前学习pytorch的学习材料中，摘抄了一部分使用DataLoader的代码，先看看具体如何使用。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 trainset = torchvision.datasets.CIFAR10(root=\u0026#39;./data\u0026#39;, train=True, download=True, transform=transform) trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True, num_workers=2) # ... 省略部分代码 # 训练网络 for epoch in range(2): # loop over the dataset multiple times running_loss = 0.0 for i, data in enumerate(trainloader, 0): # get the inputs inputs, labels = data # zero the parameter gradients optimizer.zero_grad() # forward + backward + optimize outputs = net(inputs) loss = criterion(outputs, labels) loss.backward() optimizer.step() # print statistics running_loss += loss.item() if i % 2000 == 1999: # print every 2000 mini-batches print(\u0026#39;[%d, %5d] loss: %.3f\u0026#39; % (epoch + 1, i + 1, running_loss / 2000)) running_loss = 0.0 print(\u0026#39;Finished Training\u0026#39;) 上面代码是一个简单的训练过程，我们可以看到使用Dataset和DataLoader很方便地为模型训练提供数据加载、打乱、预处理、甚至是多进程加载。作为pytorch的使用者，准确详细的了解pytorch各种包，可以熟练快速开发我们自己的训练程序，下面先具体分析下DataLoader的接口。\n源码比较长，我分析这样比较长的源码，将比较简单部分的代码解释直接写在源码里，作为注释；将复杂部分通过@符号标注，然后在源码后面部分分析。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 class DataLoader(Generic[T_co]): r\u0026#34;\u0026#34;\u0026#34; 原注释省略。 \u0026#34;\u0026#34;\u0026#34; dataset: Dataset[T_co] batch_size: Optional[int] num_workers: int pin_memory: bool drop_last: bool timeout: float sampler: Sampler prefetch_factor: int _iterator : Optional[\u0026#39;_BaseDataLoaderIter\u0026#39;] __initialized = False def __init__(self, dataset: Dataset[T_co], batch_size: Optional[int] = 1, shuffle: bool = False, sampler: Optional[Sampler[int]] = None, batch_sampler: Optional[Sampler[Sequence[int]]] = None, num_workers: int = 0, collate_fn: _collate_fn_t = None, pin_memory: bool = False, drop_last: bool = False, timeout: float = 0, worker_init_fn: _worker_init_fn_t = None, multiprocessing_context=None, generator=None, *, prefetch_factor: int = 2, persistent_workers: bool = False): torch._C._log_api_usage_once(\u0026#34;python.data_loader\u0026#34;) # type: ignore if num_workers \u0026lt; 0: raise ValueError(\u0026#39;num_workers option should be non-negative; \u0026#39; \u0026#39;use num_workers=0 to disable multiprocessing.\u0026#39;) if timeout \u0026lt; 0: raise ValueError(\u0026#39;timeout option should be non-negative\u0026#39;) if num_workers == 0 and prefetch_factor != 2: raise ValueError(\u0026#39;prefetch_factor option could only be specified in multiprocessing.\u0026#39; \u0026#39;let num_workers \u0026gt; 0 to enable multiprocessing.\u0026#39;) assert prefetch_factor \u0026gt; 0 if persistent_workers and num_workers == 0: raise ValueError(\u0026#39;persistent_workers option needs num_workers \u0026gt; 0\u0026#39;) self.dataset = dataset self.num_workers = num_workers self.prefetch_factor = prefetch_factor self.pin_memory = pin_memory self.timeout = timeout self.worker_init_fn = worker_init_fn self.multiprocessing_context = multiprocessing_context # Arg-check dataset related before checking samplers because we want to # tell users that iterable-style datasets are incompatible with custom # samplers first, so that they don\u0026#39;t learn that this combo doesn\u0026#39;t work # after spending time fixing the custom sampler errors. if isinstance(dataset, IterableDataset): self._dataset_kind = _DatasetKind.Iterable # NOTE [ Custom Samplers and IterableDataset ] # # `IterableDataset` does not support custom `batch_sampler` or # `sampler` since the key is irrelevant (unless we support # generator-style dataset one day...). # # For `sampler`, we always create a dummy sampler. This is an # infinite sampler even when the dataset may have an implemented # finite `__len__` because in multi-process data loading, naive # settings will return duplicated data (which may be desired), and # thus using a sampler with length matching that of dataset will # cause data lost (you may have duplicates of the first couple # batches, but never see anything afterwards). Therefore, # `Iterabledataset` always uses an infinite sampler, an instance of # `_InfiniteConstantSampler` defined above. # # A custom `batch_sampler` essentially only controls the batch size. # However, it is unclear how useful it would be since an iterable-style # dataset can handle that within itself. Moreover, it is pointless # in multi-process data loading as the assignment order of batches # to workers is an implementation detail so users can not control # how to batchify each worker\u0026#39;s iterable. Thus, we disable this # option. If this turns out to be useful in future, we can re-enable # this, and support custom samplers that specify the assignments to # specific workers. if shuffle is not False: raise ValueError( \u0026#34;DataLoader with IterableDataset: expected unspecified \u0026#34; \u0026#34;shuffle option, but got shuffle={}\u0026#34;.format(shuffle)) elif sampler is not None: # See NOTE [ Custom Samplers and IterableDataset ] raise ValueError( \u0026#34;DataLoader with IterableDataset: expected unspecified \u0026#34; \u0026#34;sampler option, but got sampler={}\u0026#34;.format(sampler)) elif batch_sampler is not None: # See NOTE [ Custom Samplers and IterableDataset ] raise ValueError( \u0026#34;DataLoader with IterableDataset: expected unspecified \u0026#34; \u0026#34;batch_sampler option, but got batch_sampler={}\u0026#34;.format(batch_sampler)) else: self._dataset_kind = _DatasetKind.Map if sampler is not None and shuffle: raise ValueError(\u0026#39;sampler option is mutually exclusive with \u0026#39; \u0026#39;shuffle\u0026#39;) if batch_sampler is not None: # auto_collation with custom batch_sampler if batch_size != 1 or shuffle or sampler is not None or drop_last: raise ValueError(\u0026#39;batch_sampler option is mutually exclusive \u0026#39; \u0026#39;with batch_size, shuffle, sampler, and \u0026#39; \u0026#39;drop_last\u0026#39;) batch_size = None drop_last = False elif batch_size is None: # no auto_collation if drop_last: raise ValueError(\u0026#39;batch_size=None option disables auto-batching \u0026#39; \u0026#39;and is mutually exclusive with drop_last\u0026#39;) if sampler is None: # give default samplers if self._dataset_kind == _DatasetKind.Iterable: # See NOTE [ Custom Samplers and IterableDataset ] sampler = _InfiniteConstantSampler() else: # map-style if shuffle: # Cannot statically verify that dataset is Sized # Somewhat related: see NOTE [ Lack of Default `__len__` in Python Abstract Base Classes ] sampler = RandomSampler(dataset, generator=generator) # type: ignore else: sampler = SequentialSampler(dataset) if batch_size is not None and batch_sampler is None: # auto_collation without custom batch_sampler batch_sampler = BatchSampler(sampler, batch_size, drop_last) self.batch_size = batch_size self.drop_last = drop_last self.sampler = sampler self.batch_sampler = batch_sampler self.generator = generator if collate_fn is None: if self._auto_collation: collate_fn = _utils.collate.default_collate else: collate_fn = _utils.collate.default_convert self.collate_fn = collate_fn self.persistent_workers = persistent_workers self.__initialized = True self._IterableDataset_len_called = None # See NOTE [ IterableDataset and __len__ ] self._iterator = None def _get_iterator(self) -\u0026gt; \u0026#39;_BaseDataLoaderIter\u0026#39;: if self.num_workers == 0: return _SingleProcessDataLoaderIter(self) else: return _MultiProcessingDataLoaderIter(self) @property def multiprocessing_context(self): return self.__multiprocessing_context @multiprocessing_context.setter def multiprocessing_context(self, multiprocessing_context): if multiprocessing_context is not None: if self.num_workers \u0026gt; 0: if not multiprocessing._supports_context: raise ValueError(\u0026#39;multiprocessing_context relies on Python \u0026gt;= 3.4, with \u0026#39; \u0026#39;support for different start methods\u0026#39;) if isinstance(multiprocessing_context, string_classes): valid_start_methods = multiprocessing.get_all_start_methods() if multiprocessing_context not in valid_start_methods: raise ValueError( (\u0026#39;multiprocessing_context option \u0026#39; \u0026#39;should specify a valid start method in {!r}, but got \u0026#39; \u0026#39;multiprocessing_context={!r}\u0026#39;).format(valid_start_methods, multiprocessing_context)) # error: Argument 1 to \u0026#34;get_context\u0026#34; has incompatible type \u0026#34;Union[str, bytes]\u0026#34;; expected \u0026#34;str\u0026#34; [arg-type] multiprocessing_context = multiprocessing.get_context(multiprocessing_context) # type: ignore if not isinstance(multiprocessing_context, python_multiprocessing.context.BaseContext): raise TypeError((\u0026#39;multiprocessing_context option should be a valid context \u0026#39; \u0026#39;object or a string specifying the start method, but got \u0026#39; \u0026#39;multiprocessing_context={}\u0026#39;).format(multiprocessing_context)) else: raise ValueError((\u0026#39;multiprocessing_context can only be used with \u0026#39; \u0026#39;multi-process loading (num_workers \u0026gt; 0), but got \u0026#39; \u0026#39;num_workers={}\u0026#39;).format(self.num_workers)) self.__multiprocessing_context = multiprocessing_context def __setattr__(self, attr, val): if self.__initialized and attr in ( \u0026#39;batch_size\u0026#39;, \u0026#39;batch_sampler\u0026#39;, \u0026#39;sampler\u0026#39;, \u0026#39;drop_last\u0026#39;, \u0026#39;dataset\u0026#39;, \u0026#39;persistent_workers\u0026#39;): raise ValueError(\u0026#39;{} attribute should not be set after {} is \u0026#39; \u0026#39;initialized\u0026#39;.format(attr, self.__class__.__name__)) super(DataLoader, self).__setattr__(attr, val) # We quote \u0026#39;_BaseDataLoaderIter\u0026#39; since it isn\u0026#39;t defined yet and the definition can\u0026#39;t be moved up # since \u0026#39;_BaseDataLoaderIter\u0026#39; references \u0026#39;DataLoader\u0026#39;. def __iter__(self) -\u0026gt; \u0026#39;_BaseDataLoaderIter\u0026#39;: # When using a single worker the returned iterator should be # created everytime to avoid reseting its state # However, in the case of a multiple workers iterator # the iterator is only created once in the lifetime of the # DataLoader object so that workers can be reused if self.persistent_workers and self.num_workers \u0026gt; 0: if self._iterator is None: self._iterator = self._get_iterator() else: self._iterator._reset(self) return self._iterator else: return self._get_iterator() @property def _auto_collation(self): return self.batch_sampler is not None @property def _index_sampler(self): # The actual sampler used for generating indices for `_DatasetFetcher` # (see _utils/fetch.py) to read data at each time. This would be # `.batch_sampler` if in auto-collation mode, and `.sampler` otherwise. # We can\u0026#39;t change `.sampler` and `.batch_sampler` attributes for BC # reasons. if self._auto_collation: return self.batch_sampler else: return self.sampler def __len__(self) -\u0026gt; int: if self._dataset_kind == _DatasetKind.Iterable: # NOTE [ IterableDataset and __len__ ] # # For `IterableDataset`, `__len__` could be inaccurate when one naively # does multi-processing data loading, since the samples will be duplicated. # However, no real use case should be actually using that behavior, so # it should count as a user error. We should generally trust user # code to do the proper thing (e.g., configure each replica differently # in `__iter__`), and give us the correct `__len__` if they choose to # implement it (this will still throw if the dataset does not implement # a `__len__`). # # To provide a further warning, we track if `__len__` was called on the # `DataLoader`, save the returned value in `self._len_called`, and warn # if the iterator ends up yielding more than this number of samples. # Cannot statically verify that dataset is Sized length = self._IterableDataset_len_called = len(self.dataset) # type: ignore if self.batch_size is not None: # IterableDataset doesn\u0026#39;t allow custom sampler or batch_sampler from math import ceil if self.drop_last: length = length // self.batch_size else: length = ceil(length / self.batch_size) return length else: return len(self._index_sampler) ","date":"2020-12-05T23:21:34Z","permalink":"http://localhost:1313/posts/pytorch%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB%E4%B8%80dataset%E5%92%8Cdataloader/pytorch%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB-%E4%B8%80/","title":"Pytorch源码阅读(一)：Dataset和DataLoader"},{"content":"前言 支持向量机即Support Vector Machine，简称SVM。我最开始听说这个机器的时候，一头雾水，“支持”，“向量”，“机”，这三个词组合在一起让我在一开始觉得这个东西好抽象。首先，SVM实际上是一个二分类模型，也可以用来解决回归问题。了解过一些原理后，我觉得这种模型（方法）被称为Vector Support Machine更好一些，简单且不严谨的理解是: 这种模型通过某些向量（高维空间中的点）支持（支撑）而形成的一种机器（方法），或者称之为模型。\n引用Free Mind在介绍SVM中一句话：“SVM 一直被认为是效果最好的现成可用的分类算法之一（其实有很多人都相信，“之一”是可以去掉的）”。刚开始接触机器学习（大半年🤦‍♂️），目前没有做太多实践，并不清楚SVM的效果有多好，后面应该多了解些SVM的实际应用。\n支持向量机原理 现在有一些数据$\\mathbf{x}={\\boldsymbol{x_1}, \\boldsymbol{x_2}, \\boldsymbol{x_3}, \u0026hellip;, \\boldsymbol{x_n}}$，这些数据的标签也已知$\\mathbf{y}={y_1, y_2, y_3, \u0026hellip;, y_n}$。其中每个数据$\\boldsymbol{x_i}$为有两个特征值，即$\\boldsymbol{x_i} = (x_{i1}, x_{i2})$，为二维空间上的一点，标签$y_i\\in{-1, +1}$，一般我们将$+1$称作正类，将$-1$称为负类。这里假设$\\boldsymbol{x_i}$只有两个特征值是为了能够在二维坐标中将数据表示出来，方便理解。更一般地，$\\boldsymbol{x}_{i} \\in \\mathbb{R}^{n}$，即每个数据有$n$个特征值，每个数据都是$n$维空间中的一个点。\n下图在二维坐标系中将这些数据表示出来，其中红色代表正类，蓝色代表负类。\n可能有人要问了：为什么这些点分布的很有规律（特点）？即正类的这些红色点都分布在一边，而蓝色的这些数据点分布在另外一边。的确，现实中的数据往往不会这么理想，可能会是两部分数据交叉在一起，并不是直观上那么明显的分为两边，这里我们从最简单的原数据线性可分的问题入手，所以先假设数据比较理想。之后我们会慢慢介绍一些复杂数据的情况是如何处理的。\n那么如果有上图一些较为理想的数据，需要寻找到一个线性边界将它们划分开来，如何找到这个线性边界呢？这个问题大概小学生也能做到。如下图，我们在红色数据点和蓝色数据点之间画一条直线，使得两类点分割到直线的两边，这条直线显然就是一个线性边界，并且可以正确地将所给的数据集分为两类。\n然而，或许你想说你画出来的直线和上图不一样，它或许是下图中的某一条。\n这里，我们很容易想到这样的直线有无数条。用这些直线对于已知的上图数据分类，它们的确都可以产生正确的分类结果。然而，机器学习建模的目的并不是对于已知点（标签已知）成功分类即可，学习的目的是需要对于未知情况也能够适用，即对于一个未知分类的数据点，我们的建立的模型需要告诉我们这个数据点它是属于哪一类的，正类或者是负类。机器学习建立的模型试图去寻找数据中一般的规律，而不是对于已有数据正确的表示。\n假如对于一个新的未知分类的数据，它在二维坐标位置为X所在的位置如下图。\n这里，我们用上面得到的这些直线对新的数据X分类，$l_1$直线和其他直线分类的结果并不一样，它处在$l_1$右侧，将它标记为负类；它处在其他直线的左侧，将它标记为正类。不同的线性模型对于新的数据的分类结果不一样，那么，如何衡量这些直线的好坏，哪一个直线最好，更能代表这些数据中的一般规律呢？\nSVM给出的答案是：求解能够正确划分训练数据集并且几何间隔最大的分离超平面。 这也是SVM学习的基本想法。\n这里的几何间隔最大含义是：在无数正确划分数据集的分离超平面中，找到这样的超平面，该超平面离最近的数据点的距离最大。用数学语言描述为下面的约束最优化问题： $$ \\begin{array}{ll} \\max \\limits_{\\boldsymbol{w}, \\boldsymbol{b}} \u0026amp; \\gamma \\ \\text { s.t. } \u0026amp; y_{i}\\left(\\frac{\\boldsymbol{w}}{|\\boldsymbol{w}|} \\cdot \\boldsymbol{x_{i}}+\\frac{b}{|\\boldsymbol{w}|}\\right) \\geqslant \\gamma, \\quad i=1,2, \\cdots, N \\end{array} $$ 其中，第一行代表优化问题中目标函数，第二行代表约束条件，$s.t.$指的是subject to ，受限于。\n要理解上面的式子，让我们先来回顾下超平面的公式以及点到超平面的距离公式，可以参考这篇文章的推导超平面公式及点到超平面距离，超平面的公式为： $$ \\boldsymbol{w}^{T} \\boldsymbol{x}+b=0 $$ 其中，$w$是超平面的法向量，此处为列向量，简单的理解为：$w^{T} x$为法向量和超平面中的点向量（原点到超平面点形成的向量）的内积，该内积代表点向量在法向量上投影的距离；如果对超空间中的自由点施加一个法向量投影距离为$-b$时的拘束条件，那么所有满足约束条件的所有点处于超平面内。\n超空间中，点到超平面的距离公式为： $$ d=\\frac{|\\boldsymbol{w}^{T} \\boldsymbol{x}+b|}{|\\boldsymbol{w}|} $$ 其中$|\\boldsymbol{w}|$代表$\\boldsymbol{w}$向量的第二范数，也称欧几里得范数（距离）；其严格表示应该为$|\\boldsymbol{w}|_2$，因为比较常用常常省略右下角标2。\n让我们回到上面的SVM约束最优化问题： $$ \\begin{array}{ll} \\max \\limits_{\\boldsymbol{w}, \\boldsymbol{b}} \u0026amp; \\gamma \u0026amp;\u0026amp; (1) \\\\ \\text { s.t. } \u0026amp; y_{i}\\left(\\frac{\\boldsymbol{w}}{|\\boldsymbol{w}|} \\cdot \\boldsymbol{x_{i}}+\\frac{b}{|\\boldsymbol{w}|}\\right) \\geqslant \\gamma, \\quad i=1,2, \\cdots, N \u0026amp;\u0026amp; (2) \\end{array} $$ $\\gamma$代表的是数据点到超平面的几何距离，$(2)$式括号内代表的是每个点到超平面的几何距离，然而，不同于上面的距离公式，该公式没有加绝对值，括号部分的值可正可负，显然，正负对应于超平面的两侧，一开始我们有约定标签$y_i\\in{-1, +1}$，那么当我们约定括号部分值为负的那一侧代表负类，即$y_i=-1$；为正的那一侧代表正类，即$y_i=+1$，这里更多的是一种约定的问题，这种约定方便我们建模求解问题。\n我们可以试着理解下$(1) (2)$两式，当有某些数据点被分错时，$(2)$左侧结果为负值，那么$\\gamma$也为负值，此时$\\gamma$肯定不是最大值，只有当所有的数据点都被正确分类时（$\\gamma$为正），而且超平面距离最近的点的距离最远时，$\\gamma$达到最大。也就是说，如果我们的求解方法是对参数逐步迭代达到$\\gamma$最大时，那么一开始是由误分类点驱动，之后根据几何间隔最大驱动参数更新。 上面最优化建模完美得到了正确划分训练数据集并且几何间隔最大的目的。\n后续讨论：\n数据并不是线性可分的。 数据存在误差，软间隔。 SVM优缺点 优点 有严格的数学理论支持，可解释性强，不依靠统计方法，从而简化了通常的分类和回归问题； 能找出对任务至关重要的关键样本（即：支持向量）； 采用核技巧之后，可以处理非线性分类/回归任务； 最终决策函数只由少数的支持向量所确定，计算的复杂性取决于支持向量的数目，而不是样本空间的维数，这在某种意义上避免了“维数灾难”。 缺点 训练时间长。当采用 SMO 算法时，由于每次都需要挑选一对参数，因此时间复杂度为$O\\left(N^{2}\\right)$，其中 N 为训练样本的数量； 当采用核技巧时，如果需要存储核矩阵，则空间复杂度为$O\\left(N^{2}\\right)$； 模型预测时，预测时间与支持向量的个数成正比。当支持向量的数量较大时，预测计算复杂度较高。 目前只适合小批量样本的任务，无法适应百万甚至上亿样本的任务。 SVM使用场景 现有的一些支持向量机软件包 LIBSVM \u0026ndash; A Library for Support Vector Machines\n一些废话 参考：\nsupport-vector-machines\n理解SVM的三层境界\n(https://zhuanlan.zhihu.com/p/77750026)\n","date":"2020-07-14T17:46:32Z","image":"https://cdn.jsdelivr.net/gh/qiyueliuhuo/blogimages/img/20201203171952.png","permalink":"http://localhost:1313/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B9%8B%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/","title":"机器学习之支持向量机"},{"content":"前言 人工神经网络（Artificial Neural Network，ANN）是一门重要的机器学习技术。它是目前最为火热的研究方向\u0026ndash;深度学习（Deep Learning）的基础。学习神经网络不仅可以让你掌握一门强大的机器学习方法，同时也可以更好地帮助你理解深度学习技术。\n四年前，韩国围棋九段棋手李世石与谷歌人工智能 AlphaGo 之间的围棋比赛，最终 AlphaGo 以四比一取胜，这让人工智能 AlphaGo 背后的技术——深度学习算法大火，笔者也是从这个时候开始关注深度学习，对计算机领域产生了兴趣。此后一年，谷歌又推出 AlphaGo 围棋升级版，并邀请世界围棋冠军、中国棋手柯洁于 2017 年 5 月份与之进行围棋大战，笔者全程直播观看了 AlphaGo 与柯洁人机围棋大战，在看到作为人类智慧的顶峰柯洁含泪认输后，笔者被 AlphaGo 背后的技术神经网络所深深震撼（还包括另一种技术：蒙特卡洛树搜索）。围棋不同于其他棋，计算机目前无法遍历围棋的所有可能的下法，所以算法必须尝试模拟人类大脑的下棋，根据以往学习到的经验判断落棋点，而不是暴力遍历所有可能性后选择最佳的下棋点，从而取胜。\n这篇文章试图介绍深度学习中很重要的技术——神经网络，并重点介绍神经网络中运用到反向传播算法。\n在笔者大学期间，除了两场围棋人机大战外，还有一场比较有意思的大型实验：大贝尔实验——关于验证基础物理量子力学中非常有名且重要的贝尔不等式的实验。所谓“遇事不决，量子力学”，这个梗就表示了量子力学中存在一些无法解释（宏观世界难以理解）的现象，若有兴趣可以再了解下。\n感知机 感知机介绍 首先让我们先来了解下神经网络中最简单也是最基础的一种结构——感知机（Perceptron），如下图：\n研究者模拟生物神经网络中的一个简单的神经元的行为——神经元兴奋过程，与之对应的感知机基础概念被提出，这里我们可以把权重当作突触、把偏置当作阈值以及把激活函数当作细胞体，当经过突触的信号总和超过了某个阈值（偏置项），细胞体就会兴奋（激活函数），产生电脉冲（输出 1），而当信号量总和未超过阈值，不产生电脉冲（输出 0）。它可以被视为一种最简单形式的前馈神经网络，是一种二元线性分类器。感知机（单个神经元）代表了从输入空间到输出空间的如下函数： $$ y = f(\\sum_{i=1}^{n}w_ix_i + b) $$ 理想中的激活函数$f(·)$是下图 a 所示的阶跃函数，输出“1”对应神经元兴奋，输出“0”对应神经元抑制，然而阶跃函数具有不连续、不光滑等不太好的数学性质，因此实际常用 Sigmoid 函数作为激活函数，如下图 b 所示，该函数将实域范围的输出挤压到（0，1）范围输出，也被称为“挤压函数”。 对于感知机模型的理解：感知机模型的假设空间（容量）是定义在特征空间中的所有线性分类模型或线性分类器。感知机对应函数值为 0，即$w·x + b = 0$，对应于特征空间$R^n$中的一个超平面$S$，其中$w$是超平面的法向量，$b$是超平面的截距，这个超平面将特征空间划分为两个部分，位于两部分空间中的点分别被分为正、负两类。\n感知机学习策略 感知机学习以最小化误分类点到超平面$S$的总距离为目标，因此感知机学习算法是误分类驱动的，具体使用时采用随机梯度下降法。 误分类点到超平面的总距离为 $$ -\\frac{1}{||w||}\\sum_{x_i\\in M}y_i(w·x_i + b) $$ 其中$(x_i, y_i)$为样本点，$M$为误分类点的集合，对于误分类点来说$-y_i(w·x_i + b) \u0026gt; 0$成立，且当$(w·x_i + b) \u0026gt; 0$时，$y_i = -1$，当$(w·x_i + b) \u0026lt; 0$时，$y_i = +1$。 不考虑$\\frac{1}{||w||}$，就得到感知机学习的损失函数为 $$ L(w, b) = -\\sum_{x_i\\in M}y_i(w·x_i + b) $$ 损失函数的梯度为 $$ \\nabla_w L(w, b) = - \\sum_{x_i\\in M}y_ix_i$$ $$ \\nabla_b L(w, b) = - \\sum_{x_i\\in M}y_i$$\n采用随机梯度下降法，随机选取一个误分类点$(x_i, y_i)$，对$w, b$进性更新： $$ w \\leftarrow w + \\eta y_ix_i $$ $$ b \\leftarrow b + \\eta y_i $$\n具体推导过程及算法迭代过程参见李航《统计学习方法》，代码实现参见此 github。\n感知机模型存在的问题 感知机的学习能力非常有限，与、或、非问题都是线性可分的，所以感知机可以处理，但是感知机却不能解决异或简单的非线性可分问题。 异或问题暴露出这样一个问题，即在现实任务中，原始样本空间内也许并不存在一个能正确划分两类样本的超平面，对于这样的问题，一种方法，1) 可将样本从原始空间映射到一个更高维的特征空间（或者不用更高维也可以），所谓的核函数$\\phi$，使得样本在这个特征空间内线性可分，幸运的是，如果原始空间是有限维，那么一定存在一个高维特征空间使得样本线性可分。2) 另一种方法，通过增加感知机的层数，使得形成一个神经网络，其中输入层神经元接受外界输入，隐层与输出层神经元对信号进行加工，最终结果由输出层神经元输出。（花书理解：深层神经网络中的隐藏层即代表输入经过了一个核函数$\\phi$变换，那么以上两种方式都是在寻找一个恰当的核函数$\\phi$，神经网络的方式是通过网络自主学习学到恰当的核函数）\n神经网络 神经网络介绍 考虑到感知机模型存在的问题，即只能解决线性可分问题，我们将感知机进行连接，形成多层感知机——神经网络，如下图\n神经网络其实就是按照一定规则连接起来的多个神经元。上图展示了一个全连接(full connected, FC)神经网络，通过观察上面的图，我们可以发现它的规则包括：\n神经元按照层来布局。最左边的层叫做输入层，负责接收输入数据；最右边的层叫输出层，我们可以从这层获取神经网络输出数据。输入层和输出层之间的层叫做隐藏层，因为它们对于外部来说是不可见的。 同一层的神经元之间没有连接。 第N层的每个神经元和第N-1层的所有神经元相连(这就是full connected的含义)，第N-1层神经元的输出就是第N层神经元的输入。 每个连接都有一个权值。 上面这些规则定义了全连接神经网络的结构。事实上还存在很多其它结构的神经网络，比如卷积神经网络(CNN)、循环神经网络(RNN)，他们都具有不同的连接规则。\n用矩阵形式表示神经网络运算过程，如下： 第一层加权和为 $$ A^{(1)} = XW^{(1)} + B^{(1)} $$ 其中，$X$为$N\\times2$大小矩阵，$N$代表输入神经网络的数据有$N$个样本，$2$代表每个样本有两个特征值；$W$为$2\\times3$大小的矩阵代表输入层到中间层的线性变换权重矩阵；$B$为偏置项。 第一层激活后为 $$ Z^{(1)} = sigmoid(A^{(1)}) $$ 其中 sigmoid 函数作用于$A^{(1)}$中的每一个元素。将第一层的输出$Z^{(1)}$作为第二层的输入，同理得： $$ A^{(2)} = Z^{(1)}W^{(2)} + B^{(2)} $$ 注意： 因为单隐层神经网络只经过两层传播，那么第二层的输出就是网络的输出，这里一般（1）回归问题使用恒等函数作为激活函数，（2）分类问题可以使用 softmax 函数。我们把此神经网络看作是分类采用 softmax 函数： $$ y_k = \\frac{exp(a_k)}{\\sum_{i=1}^{n}exp(a_i)} $$ 那么神经网络的输出为 $$ Y = softmax(A^{(2)}) $$ 其中$Y$为$N\\times2$矩阵，形如：\n$$ \\left[ \\begin{array}{ccc} 0.2650877\u0026amp; 0.7349123\\\\ \\vdots \u0026amp; \\vdots\\\\ 0.8987211 \u0026amp; 0.1012788\\\\ \\end{array} \\right] $$\n代表第一个样本预测为第二个分类概率为 0.7349123，大于 0.5，可以认为预测为第二个分类；最后一个样本预测为第一个分类概率为 0.8987211，可以认为预测为第一个分类。（当然只有两个样本的情况下一般看作正类和负类，只需要一个输出神经元，使用 sigmoid 函数激活即可。）该模型使用 softmax 函数作为激活函数，可以推广到多分类情况下。\n神经网络学习策略 神经网络的学习中使用的指标为损失函数（loss function），即以最小化损失函数为目标，理论上，损失函数可以使用任意函数，但实际中一般用均方误差和交叉熵误差等。 均方误差为 $$ E = \\frac{1}{2}\\sum_{k}(y_k - t_k)^2 $$ 交叉熵误差为 $$ E = -\\sum_{k}t_k\\log_e{y_k} $$ 其中$y_k$表示神经网络的输出，$t_k$表示监督数据，k 表示数据的维度，如在手写数字识别例子中，$y_k$、$t_k$如下 10 个元素构成的数据：\n1 2 y = [0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0] t = [0, 0, 1, 0, 0, 0, 0, 0, 0, 0] 在批量样本学习中，可以将对所有的样本的单个误差求和，然后再除以样本数 N，求得单个数据的“平均损失函数”，将它作为损失函数。 神经网络学习的策略和感知机学习策略都是一个最优化问题，神经网络学习中也是采用随机梯度下降法，与感知机学习策略更新参数类似，对于神经网络任意参数（线性权重、线性偏置等需要学习参数）更新估计式如下 $$ v \\leftarrow v + \\Delta v $$ 更新参数为线性连接权重参数时 $$ w_{hj} \\leftarrow w_{hj} + \\Delta w_{hj} $$ 采用梯度下降法，有 $$ w_{hj} \\leftarrow w_{hj} - \\eta \\frac{\\partial E}{\\partial w_{hj}} $$ 对于梯度求解，一般有解析法和数值法两种方法，随着神经网络神经元增加和层数增加，直接求上万，甚至上亿个参数的解析导数变得不现实，计算量非常大。下面将介绍两种数值方式计算梯度方法：导数定义法和反向传播法。\n梯度计算 梯度在直角坐标系下计算公式为 $$ \\nabla f(x) = (\\frac{\\partial f(x)}{\\partial x_1}, \\frac{\\partial f(x)}{\\partial x_2}, \u0026hellip;) $$ 梯度计算的结果是一个向量，并且可以看到计算梯度需要求函数对于各个自变量的偏导数。 对于多元函数，偏导表示自变量某个瞬间的变化量。定义为如下： $$ \\frac{\\partial f(x_1, x_2, x_3\u0026hellip;x_i\u0026hellip;)}{\\partial x_i} = \\lim_{h \\to 0} \\frac{f(x_1, x_2, x_3\u0026hellip;x_i + h, \u0026hellip;)}{h} $$ 偏导的定义和导数的定义类似，表示自变量上“微小的变化”将导致函数$f(x)$的值在多大程度上发生变化。我们可以直接用程序实现上面的计算方式，程序中无法表示 h 趋近 0，我们使用一个微小值代替，计算近似解。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 # 数值梯度 def numerical_gradient(f, x): h = 1e-4 # 0.0001 grad = np.zeros_like(x) # 生成和x形状相同的数组 for idx in range(x.size): tmp_val = x[idx] # 计算f(x+h) x[idx] = tmp_val + h fxh1 = f(x) # 计算f(x-h) x[idx] = tmp_val - h fxh2 = f(x) grad[idx] = (fxh1 - fxh2) / (2*h) x[idx] = tmp_val # 还原x的值 return grad 上面程序实现的偏导数方式和上面公式稍有不同，使用中心差分，误差比前向差分小，学过微积分的同学应该能够明白。虽然上面求偏导数看着很方便很简单，但是根据上面的方式计算梯度在面对神经网络这种具有很大规模输入和很大规模参数时，计算效率相当慢。下面将重点介绍反向传播算法计算梯度。（介绍完反向传播算法后，还会再介绍两者求解方式差异，为什么上面方式求解梯度速度在神经网络应用上效率太慢）\n计算图 为了更精确地描述反向传播算法，我们使用计算图（computational graph）语言来描述一系列操作。《深度学习》花书和斯坦福李飞飞 cs231n 课程对于计算图表示上有些区别，但都表示同一个含义，即用图的方式形式化地将操作次序表示出来，方便理解。这里我们介绍 cs231n 课程对于计算图的画法。 使用圆圈代表操作节点，指向节点的箭头代表输入变量，从节点指出的箭头代表操作完后输出的变量。上面计算图即表示了$f(x,y,z) = (x + y)z$。\n反向传播算法 简单标量反向传播算法 上面计算图真实值计算线路展示了计算的视觉化过程。前向传播从输入计算到输出（绿色），反向传播从尾部开始，根据链式法则递归地向前计算梯度（显示为红色），一直到网络的输入端。可以认为，梯度是从计算链路中回流。 如上图计算过程，可以用下面几个中间过程合成： $$ q = x + y $$ $$ f = q \\times z $$ 在输入$x = -2, y = 5, z = -4$情况下，箭头下面红色数字代表 f 对该处变量的偏导，即 $$ \\frac{\\partial f}{\\partial f} = 1 $$ $$ \\frac{\\partial f}{\\partial q} = \\frac{\\partial (q \\times z)}{\\partial q} = z\\vert_{z=-4}=-4 $$ $$ \\frac{\\partial f}{\\partial z} = \\frac{\\partial (q \\times z)}{\\partial z} = q\\vert_{q=3}=3 $$ 根据求导的链式法则得 $$ \\frac{\\partial f}{\\partial x} = \\frac{\\partial f}{\\partial q}\\frac{\\partial q}{\\partial x}=1 \\cdot (-4) \\cdot 1 = -4 $$ $$ \\frac{\\partial f}{\\partial y} = \\frac{\\partial f}{\\partial q}\\frac{\\partial q}{\\partial y}=1 \\cdot (-4) \\cdot 1 = -4 $$ 结合上面计算图和求导的链式法则可以有以下结论： “$输出结果对某一变量的偏导 = 反向传播时上游传递下来的偏导数 \\times 本地偏导数（该变量输入的计算节点偏导数）$” 下面介绍稍微复杂的计算图，如下图。 利用上面得到的结论就可以得到每个遍历的偏导数，这个计算图和上面计算图区别之处在于：在乘法节点的结果输出到两个节点，分别是除法节点和减法节点，导数反向传播时，需要将上游传递的两个导数相加，即-0.25 + 1 = 0.75 这是基于下面的定理：\n定理：若函数$u=\\varphi(t), v=\\psi(t)$在点 t 可导，$z=f(u,v)$在点(u,v)处偏导连续，则复合函数$z=f(\\varphi(t),\\psi(t))$在点 t 可导，则有链式法则 $$ \\frac{\\mathrm{d} z }{\\mathrm{d} t} = \\frac{\\partial z}{\\partial u} \\cdot \\frac{\\mathrm{d} u }{\\mathrm{d} t} + \\frac{\\partial z}{\\partial v} \\cdot \\frac{\\mathrm{d} v }{\\mathrm{d} t} $$\n矩阵形式反向传播算法 下面介绍矩阵形式计算图及反向传播公式，如下图神经网络 Affine 层。 Affine 层：神经网络在正向传播中进行的矩阵的乘积运算在几何学领域被称为“仿射变换”。因此，这里将进行的仿射变换的处理称为“Affine 层”。\n神经网络中还有其他比较复杂的层，梯度推导比上面 Affine 层线性偏导数推导更为复杂，在此略过介绍及推导，但运用到的知识与上面方式类似，强烈建议自己手动推导下 Affine 层反向传播，对自己理解有帮助。\n前面介绍神经网络学习策略也是一个最优化问题，即 $$ loss \\ function = E = \\varphi(y, t) $$ 损失函数/目标函数为预测值$y$和监督数据$t$的函数，其中$y$是经过神经网络正向传播得到的预测值，所以$y$是神经网络所有参数$W$的函数，那么目标函数是关于参数$W$的函数（凸函数），即 $$ loss \\ function = \\psi(\\textbf{W}) $$ 根据梯度下降法，需要求得 $$ \\frac{\\partial L}{\\partial \\textbf{W}} $$ 这里的$L$表示$loss function$，也即是$E$。根据上面的神经网络反向传播算法逐层传播梯度，即可以高效地求解损失函数对参数的梯度，再根据随机梯度下降法，不断更新权重参数$W$，最小化目标函数，完成简单神经网络的训练学习。\n反向传播算法特别之处 现代的神经网络规模和层数不断增加，一个复杂的深度学习模型，可能每一层有成百量级神经元，有上百层深度，下图显示一个较复杂的神经网络。 如果采用导数定义方式，即$\\frac{\\partial L(w)}{\\partial w} = \\lim_{w \\to 0} \\frac{f(w + h)}{w}$求解，那么在求解每一个权重（即一条连接边）参数的偏导数时神经网络都需要向前传递一次，可以看到因为越靠后的神经元被重复计算的次数就越多，随着神经元个数和层数的增加，这将会是个指数增加的时间复杂度。然而，利用了函数求导的链式法则，从输出层到输入层逐层计算模型参数的梯度值，可以看到按照这个方向计算梯度，各个神经单元只计算了一次，没有重复计算。这个计算方向能够高效的根本原因是：在计算梯度时前面的单元是依赖后面的单元的计算，而“从后向前”的计算顺序正好“解耦”了这种依赖关系，先算后面的单元，并且记住后面单元的梯度值，计算前面单元的梯度时就可以充分利用已经计算出来的结果，避免了重复计算。\n总结与思考 如今人工智能领域中最重要的算法——反向传播算法其主要思想本质也是利用了动态规划，这种方法结合了解析法计算梯度和数值法计算梯度，利用空间换取时间，缩短求解大量参数梯度的时间，从而加速神经网络的训练。反向传播算法看上去高大上，但也不见得是用了多高级的方法和高深的知识。\n参考资料：\n维基百度-感知器\n维基百度-人工神经网络\n计算机的潜意识\n《Deep Learning form Scratch》\n《深度学习》\n周志华《机器学习》\n《深度学习[花书]》\n李航《统计学习方法》\n零基础入门深度学习(3) - 神经网络和反向传播算法(牛逼)\n","date":"2020-06-13T13:47:01Z","image":"http://localhost:1313/posts/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%B9%8B%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%E7%AE%97%E6%B3%95/back-propagation_hu_1102cc6b87bdd607.png","permalink":"http://localhost:1313/posts/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%B9%8B%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%E7%AE%97%E6%B3%95/","title":"神经网络之反向传播算法"}]