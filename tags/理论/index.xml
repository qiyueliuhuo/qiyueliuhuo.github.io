<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>理论 on 七月流火</title>
        <link>http://localhost:1313/tags/%E7%90%86%E8%AE%BA/</link>
        <description>Recent content in 理论 on 七月流火</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>zh-cn</language>
        <lastBuildDate>Fri, 29 Oct 2021 11:20:28 +0000</lastBuildDate><atom:link href="http://localhost:1313/tags/%E7%90%86%E8%AE%BA/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>神经网络矩阵分析</title>
        <link>http://localhost:1313/posts/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9F%A9%E9%98%B5%E5%88%86%E6%9E%90/</link>
        <pubDate>Fri, 29 Oct 2021 11:20:28 +0000</pubDate>
        
        <guid>http://localhost:1313/posts/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9F%A9%E9%98%B5%E5%88%86%E6%9E%90/</guid>
        <description>&lt;p&gt;用矩阵推导网络。 &lt;!-- more --&gt;&lt;/p&gt;
&lt;h2 id=&#34;符号定义&#34;&gt;符号定义&lt;/h2&gt;
&lt;ol type=&#34;1&#34;&gt;
&lt;li&gt;使用小写字母&lt;span
class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;表示标量，粗体小写字母&lt;span
class=&#34;math inline&#34;&gt;\(\boldsymbol{x}\)&lt;/span&gt;表示向量，&lt;strong&gt;注意&lt;/strong&gt;向量可能为&lt;strong&gt;行向量&lt;/strong&gt;或者&lt;strong&gt;列向量&lt;/strong&gt;，大写字母&lt;span
class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt;表示矩阵。&lt;/li&gt;
&lt;li&gt;&lt;span
class=&#34;math inline&#34;&gt;\(\sigma\)&lt;/span&gt;为&lt;strong&gt;逐元素&lt;/strong&gt;sigmoid函数：&lt;span
class=&#34;math inline&#34;&gt;\(\sigma(z)=\frac{1}{1+\mathrm{e}^{-z}}\)&lt;/span&gt;。&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol{1}\)&lt;/span&gt;为列向量，&lt;span
class=&#34;math inline&#34;&gt;\(\boldsymbol{1}=(1, 1, 1 \cdots 1, 1,
1)^{T}\)&lt;/span&gt;，非指示函数。&lt;/li&gt;
&lt;li&gt;&lt;span
class=&#34;math inline&#34;&gt;\(exp(\boldsymbol{a})\)&lt;/span&gt;表示&lt;strong&gt;逐元素&lt;/strong&gt;求指数。&lt;/li&gt;
&lt;li&gt;&lt;span
class=&#34;math inline&#34;&gt;\(log(\boldsymbol{a})\)&lt;/span&gt;表示&lt;strong&gt;逐元素&lt;/strong&gt;求自然对数。&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;符号含义&#34;&gt;符号含义&lt;/h2&gt;
&lt;ol type=&#34;1&#34;&gt;
&lt;li&gt;列向量&lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol{x}=\left(x_{1}, x_{2},
x_{3} \cdots x_{n-2}, x_{n-1},
x_{n}\right)^{T}\)&lt;/span&gt;代表一个输入样本，具有&lt;span
class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt;个特征值。&lt;/li&gt;
&lt;li&gt;设列向量&lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol{z}=\left(z_{1},
z_{2}, z_{3} \cdots z_{n-2}, z_{n-1}, z_{n}\right)^{T}\)&lt;/span&gt;，&lt;br /&gt;
&lt;span class=&#34;math inline&#34;&gt;\(\sigma(\boldsymbol{z}) =
\left(\sigma(z_{1}), \sigma(z_{2}), \sigma(z_{3}) \cdots
\sigma(z_{n-2}), \sigma(z_{n-1}), \sigma(z_{n})\right)\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;设列向量&lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol{a}=\left(a_{1},
a_{2}, a_{3} \cdots a_{n-2}, a_{n-1}, a_{n}\right)^{T}\)&lt;/span&gt;，&lt;span
class=&#34;math inline&#34;&gt;\(\operatorname{softmax}(\boldsymbol{a})=\frac{\exp
(\boldsymbol{a})}{\mathbf{1}^{T} \exp
(\boldsymbol{a})}\)&lt;/span&gt;，分母为&lt;strong&gt;行向量&lt;/strong&gt;乘以&lt;strong&gt;列向量&lt;/strong&gt;为标量，分子为列向量，所以结果仍为&lt;strong&gt;列向量&lt;/strong&gt;。&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;运算法则&#34;&gt;运算法则&lt;/h2&gt;
&lt;h3 id=&#34;矩阵运算法则&#34;&gt;矩阵运算法则&lt;/h3&gt;
&lt;ol type=&#34;1&#34;&gt;
&lt;li&gt;对尺寸相同的矩阵&lt;span class=&#34;math inline&#34;&gt;\(A, B\)&lt;/span&gt;，&lt;span
class=&#34;math inline&#34;&gt;\(\operatorname{tr}\left(A^{T} B\right)=\sum_{i, j}
A_{i j} B_{i j}\)&lt;/span&gt;。&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;矩阵微分运算符法则&#34;&gt;矩阵微分运算符法则&lt;/h3&gt;
&lt;ol type=&#34;1&#34;&gt;
&lt;li&gt;加减法、矩阵乘法、转置、求迹。 &lt;span class=&#34;math display&#34;&gt;\[
d(X \pm Y)=d X \pm d Y
\]&lt;/span&gt; &lt;span class=&#34;math display&#34;&gt;\[
d(X Y)=(d X) Y+X d Y
\]&lt;/span&gt; &lt;span class=&#34;math display&#34;&gt;\[
d\left(X^{T}\right)=(d X)^{T}
\]&lt;/span&gt; &lt;span class=&#34;math display&#34;&gt;\[
d \operatorname{tr}(X)=\operatorname{tr}(d X)
\]&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;求逆。 &lt;span class=&#34;math display&#34;&gt;\[
d X^{-1}=-X^{-1} d X X^{-1}
\]&lt;/span&gt; 此式可以在 $ X X^{-1}=I $ 两侧求微分来证明。&lt;/li&gt;
&lt;li&gt;行列式。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img
src=&#34;https://cdn.jsdelivr.net/gh/qiyueliuhuo/blogimages/img/20211029145157.png#center&#34; /&gt;&lt;/p&gt;
&lt;h3 id=&#34;理解&#34;&gt;理解&lt;/h3&gt;
&lt;ol type=&#34;1&#34;&gt;
&lt;li&gt;&lt;p&gt;定义：标量f对矩阵 &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; 的导数,
定义为 &lt;span class=&#34;math inline&#34;&gt;\(\frac{\partial f}{\partial
X}=\left[\frac{\partial f}{\partial X_{i
j}}\right]\)&lt;/span&gt;，即f对X逐元素求导排成与X尺寸相同的矩阵。&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;将矩阵导数与微分建立联系：&lt;span class=&#34;math inline&#34;&gt;\(d
f=\sum_{i=1}^{m} \sum_{j=1}^{n} \frac{\partial f}{\partial X_{i j}} d
X_{i j}=\operatorname{tr}\left(\frac{\partial f^{T}}{\partial X} d
X\right)\)&lt;/span&gt;。&lt;/p&gt;
&lt;blockquote&gt;
理解：
&lt;ol type=&#34;1&#34;&gt;
&lt;li&gt;微分算子&lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt;作用于矩阵&lt;span
class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt;，表示为&lt;strong&gt;逐元素&lt;/strong&gt;作用。&lt;/li&gt;
&lt;li&gt;第一个等号是全微分公式，第二个等号表达了矩阵导数与微分的联系。&lt;/li&gt;
&lt;li&gt;&lt;span
class=&#34;math inline&#34;&gt;\(tr()\)&lt;/span&gt;代表迹(trace)是方阵对角线元素之和。&lt;/li&gt;
&lt;li&gt;举例：设&lt;span class=&#34;math inline&#34;&gt;\(X=\left[\begin{array}{l}X_{0_0},
X_{01} \\\\ X_{10}, X_{11}\end{array}\right]\)&lt;/span&gt;, &lt;span
class=&#34;math inline&#34;&gt;\(d X=\left[\begin{array}{l}dX_{00}, dX_{01} \\\\
dX_{10}, dX_{11}\end{array}\right]\)&lt;/span&gt;，&lt;span
class=&#34;math inline&#34;&gt;\(\frac{d f}{d
X}=\left[\begin{array}{ll}\frac{\partial f}{\partial X_{00}},
\frac{\partial f}{\partial X_{01}} \\\\ \frac{\partial f}{\partial
X_{10}}, \frac{\partial f}{\partial
X_{11}}\end{array}\right]\)&lt;/span&gt;，&lt;span
class=&#34;math inline&#34;&gt;\(\operatorname{tr}\left(\frac{\partial
f^{T}}{\partial X} d
X\right)=\operatorname{tr}\left(\left[\begin{array}{ll}\frac{\partial
f}{\partial X_{00}}, \frac{\partial f}{\partial X_{10}} \\\\
\frac{\partial f}{\partial X_{01}}, \frac{\partial f}{\partial
X_{11}}\end{array}\right]\left[\begin{array}{l}dX_{00}, dX_{01} \\\\
dX_{10}, dX_{11}\end{array}\right]\right)\)&lt;/span&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/blockquote&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;思考&#34;&gt;思考&lt;/h2&gt;
&lt;ol type=&#34;1&#34;&gt;
&lt;li&gt;样本特征值排列为列向量，方便统一形式为权重参数&lt;span
class=&#34;math inline&#34;&gt;\(W\)&lt;/span&gt;放在&lt;span
class=&#34;math inline&#34;&gt;\(\boldsymbol{x}\)&lt;/span&gt;前，进行乘积。&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;全连接网络&#34;&gt;全连接网络&lt;/h2&gt;
&lt;p&gt;&lt;img
src=&#34;https://cdn.jsdelivr.net/gh/qiyueliuhuo/blogimages/img/20211029133900.png#center&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
l=-\boldsymbol{y}^{T} \log \operatorname{softmax}\left(W_{2}
\sigma\left(W_{1} \boldsymbol{x}\right)\right)
\]&lt;/span&gt;&lt;/p&gt;
&lt;h3 id=&#34;符号说明&#34;&gt;符号说明&lt;/h3&gt;
&lt;ol type=&#34;1&#34;&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(l\)&lt;/span&gt;为损失函数。&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol{x}\)&lt;/span&gt;为单样本，则&lt;span
class=&#34;math inline&#34;&gt;\(l\)&lt;/span&gt;只包含一个样本的损失函数。&lt;/li&gt;
&lt;li&gt;分类网络类别数为&lt;span class=&#34;math inline&#34;&gt;\(m\)&lt;/span&gt;，&lt;span
class=&#34;math inline&#34;&gt;\(\boldsymbol{y}\)&lt;/span&gt;
是除一个元素为1外其它元素为 0 的的 &lt;span class=&#34;math inline&#34;&gt;\(m \times
1\)&lt;/span&gt; 列向量, &lt;span class=&#34;math inline&#34;&gt;\(W_{2}\)&lt;/span&gt; 是 &lt;span
class=&#34;math inline&#34;&gt;\(m \times p\)&lt;/span&gt; 矩阵, &lt;span
class=&#34;math inline&#34;&gt;\(W_{1}\)&lt;/span&gt; 是 &lt;span class=&#34;math inline&#34;&gt;\(p
\times n\)&lt;/span&gt; 矩阵, &lt;span
class=&#34;math inline&#34;&gt;\(\boldsymbol{x}\)&lt;/span&gt; 是 &lt;span
class=&#34;math inline&#34;&gt;\(n \times 1\)&lt;/span&gt; 列向量, &lt;span
class=&#34;math inline&#34;&gt;\(l\)&lt;/span&gt; 是标量&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;推导-fracpartial-lpartial-w_1-和-fracpartial-lpartial-w_2&#34;&gt;推导
&lt;span class=&#34;math inline&#34;&gt;\(\frac{\partial l}{\partial W_{1}}\)&lt;/span&gt;
和 &lt;span class=&#34;math inline&#34;&gt;\(\frac{\partial l}{\partial
W_{2}}\)&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;定义：&lt;span
class=&#34;math inline&#34;&gt;\(\boldsymbol{a_{1}}=W_{1}\boldsymbol{x}\)&lt;/span&gt;，&lt;span
class=&#34;math inline&#34;&gt;\(\boldsymbol{h_{1}}=\sigma\left(\boldsymbol{a_{1}}\right)\)&lt;/span&gt;，&lt;span
class=&#34;math inline&#34;&gt;\(\boldsymbol{a_{2}}=W_{2}\boldsymbol{h_{1}}\)&lt;/span&gt;，则
&lt;span class=&#34;math inline&#34;&gt;\(l=-\boldsymbol{y}^{T} \log
\operatorname{softmax}\left(\boldsymbol{a}_{2}\right)\)&lt;/span&gt;。&lt;/p&gt;
&lt;p&gt;已知 &lt;span class=&#34;math inline&#34;&gt;\(\frac{\partial l}{\partial
\boldsymbol{a_{2}}}=\operatorname{softmax}\left(\boldsymbol{a}_{2}\right)-\boldsymbol{y}\)&lt;/span&gt;
。&lt;/p&gt;
&lt;p&gt;推导结果： &lt;span class=&#34;math display&#34;&gt;\[
\frac{\partial l}{\partial W_{2}}=\frac{\partial l}{\partial
\boldsymbol{a_{2}}} \boldsymbol{h_{1}}^{T}
\]&lt;/span&gt; &lt;span class=&#34;math display&#34;&gt;\[
\frac{\partial l}{\partial W_{1}}=\frac{\partial l}{\partial
\boldsymbol{a}_{1}} \boldsymbol{x}^{T}
\]&lt;/span&gt;&lt;/p&gt;
&lt;h3 id=&#34;推广到多个样本&#34;&gt;推广到多个样本&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;使用矩阵来表示N个样本，以简化形式。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;定义：&lt;span class=&#34;math inline&#34;&gt;\(X=\left[\boldsymbol{x_{1}}, \cdots,
\boldsymbol{x_{N}}\right]\)&lt;/span&gt;，&lt;span
class=&#34;math inline&#34;&gt;\(A_{1}=\left[\boldsymbol{a_{1,1}}, \cdots
\boldsymbol{a_{1, N}}\right]=W_{1} X+\boldsymbol{b_{1}} \mathbf{1}^{T},
\quad H_{1}=\left[\boldsymbol{h_{1,1}}, \cdots, \boldsymbol{h}_{1,
N}\right]=\sigma\left(A_{1}\right) \text {, }\)&lt;/span&gt;，&lt;span
class=&#34;math inline&#34;&gt;\(A_{2}=\left[\boldsymbol{a_{2,1}}, \cdots,
\boldsymbol{a_{2, N}}\right]=W_{2} H_{1}+\boldsymbol{b_{2}}
\mathbf{1}^{T}\)&lt;/span&gt;, 注意这里使用全1向量来扩展维度。&lt;/p&gt;
&lt;p&gt;推导结果： &lt;span class=&#34;math display&#34;&gt;\[
\frac{\partial l}{\partial W_{1}}=\frac{\partial l}{\partial A_{1}}
X^{T}, \quad \frac{\partial l}{\partial
\boldsymbol{b}_{1}}=\frac{\partial l}{\partial A_{1}} \mathbf{1}
\]&lt;/span&gt; &lt;span class=&#34;math display&#34;&gt;\[
\frac{\partial l}{\partial W_{2}}=\frac{\partial l}{\partial A_{2}}
H_{1}^{T}, \quad \frac{\partial l}{\partial
\boldsymbol{b}_{2}}=\frac{\partial l}{\partial A_{2}} \mathbf{1}
\]&lt;/span&gt;&lt;/p&gt;
&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;
&lt;p&gt;&lt;a
href=&#34;https://zhuanlan.zhihu.com/p/94805436&#34;&gt;神经网络的一些公式总结&lt;/a&gt;&lt;br /&gt;
&lt;a
href=&#34;https://zhuanlan.zhihu.com/p/24709748&#34;&gt;矩阵求导术（上）&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://zhuanlan.zhihu.com/p/24863977&#34;&gt;矩阵求导术（下）&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;更新记录&#34;&gt;更新记录&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;调整格式和排版。 —— 2022.07.19&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;使用 pandoc 渲染，对公式展示更友好。 —— 2022.08.27&lt;/p&gt;
&lt;/blockquote&gt;
</description>
        </item>
        
    </channel>
</rss>
